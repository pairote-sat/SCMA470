% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={SCMA 470 : Risk Analysis and Credibility Tutorial 3},
  pdfauthor={Pairote Satiracoo},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\usepackage{LectureNoteMacro}
\usepackage{bbm}
\usepackage{mathtools}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{\textbf{SCMA 470 : Risk Analysis and Credibility} \textbf{Tutorial 3}}
\author{Pairote Satiracoo}
\date{2021-10-14}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{basic-probability-concepts}{%
\chapter{Basic Probability Concepts}\label{basic-probability-concepts}}

\hypertarget{random-variables}{%
\section{Random Variables}\label{random-variables}}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-1}{}\label{def:unlabeled-div-1}

\emph{Let \(S\) be the sample space of an experiment. A
real-valued function \(X : S \rightarrow \mathbb{R}\) is called a \textbf{random
variable} of the experiment if, for each interval
\(I \subset \mathbb{R}, \, \{s : X(s) \in I \}\) is an event. }

\end{definition}

Random variables are often used for the calculation of the probabilities
of events. The real-valued function \(P(X \le t)\) characterizes \(X\), it
tells us almost everything about \(X\). This function is called the
\textbf{cumulative distribution function} of \(X\). The cumulative distribution
function describes how the probabilities accumulate.

\begin{definition}
\protect\hypertarget{def:unlabeled-div-2}{}\label{def:unlabeled-div-2}

\emph{If \(X\) is a random variable, then the function \(F\)
defined on \(\mathbb{R}\) by \[F(x) = P(X \le x)\] is called the
\textbf{cumulative distribution function} or simply \textbf{distribution function
(c.d.f)} of \(X\).}

\end{definition}

Functions that define the probability measure for discrete and
continuous random variables are the probability mass function and the
probability density function.

\begin{definition}
\protect\hypertarget{def:unlabeled-div-3}{}\label{def:unlabeled-div-3}

\emph{Suppose \(X\) is a discrete random variable. Then the
function \[f(x) = P(X = x)\] that is defined for each \(x\) in the range
of \(X\) is called the \textbf{probability mass function} (p.m.f) of a random
variable \(X\).}

\end{definition}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-4}{}\label{def:unlabeled-div-4}

\emph{Suppose \(X\) is a continuous random variable with
c.d.f \(F\) and there exists a nonnegative, integrable function \(f\),
\(f: \mathbb{R} \rightarrow [0, \infty)\) such that
\[F(x) = \int_{-\infty}^x f(y)\, dy\] Then the function \(f\) is called
the \textbf{probability density function} (p.d.f) of a random variable \(X\).}

\end{definition}

\hypertarget{r-functions-for-probability-distributions}{%
\subsection{R Functions for Probability Distributions}\label{r-functions-for-probability-distributions}}

In R, density, distribution function, for the Poisson distribution with parameter \(\lambda\) is shown as follows:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.12}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.21}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.22}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.21}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.22}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Distribution
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Density function: \(P(X = x)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Distribution function: \(P(X â‰¤ x)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Quantile function (inverse c.d.f.)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
random generation
\end{minipage} \\
\midrule
\endhead
Poisson & \texttt{dpois(x,\ lambda,\ log\ =\ FALSE)} & \texttt{ppois(q,\ lambda,\ lower.tail\ =\ TRUE,\ log.p\ =\ FALSE)} & \texttt{qpois(p,\ lambda,\ lower.tail\ =\ TRUE,\ log.p\ =\ FALSE)} & \texttt{rpois(n,\ lambda)} \\
\bottomrule
\end{longtable}

For the binomial distribution, these functions are pbinom, qbinom, dbinom, and rbinom. For the normal distribution, these functions are pnorm, qnorm, dnorm, and rnorm. And so forth.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\DecValTok{20}
\NormalTok{myData }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{( }\AttributeTok{k =} \FunctionTok{factor}\NormalTok{(x), }\AttributeTok{pK =} \FunctionTok{dbinom}\NormalTok{(x, }\DecValTok{20}\NormalTok{, .}\DecValTok{5}\NormalTok{))}
\FunctionTok{ggplot}\NormalTok{(myData,}\FunctionTok{aes}\NormalTok{(k,}\AttributeTok{ymin=}\DecValTok{0}\NormalTok{,}\AttributeTok{ymax=}\NormalTok{pK)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_linerange}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{ylab}\NormalTok{(}\StringTok{"p(k)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_discrete}\NormalTok{(}\AttributeTok{breaks=}\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{5}\NormalTok{)) }\SpecialCharTok{+}   
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"p.m.f of binomial distribution"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{SCMA470Bookdownproj_files/figure-latex/unnamed-chunk-1-1.pdf}

To plot continuous probability distribution in R, we use stat\_function to add the density function as its arguement. To specify a different mean or standard deviation, we use the \texttt{args} parameter to supply new values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x=}\FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{,}\AttributeTok{by=}\FloatTok{0.1}\NormalTok{))}
\FunctionTok{ggplot}\NormalTok{(df) }\SpecialCharTok{+} 
    \FunctionTok{stat\_function}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x),}\AttributeTok{fun=}\NormalTok{dnorm, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{))  }\SpecialCharTok{+} 
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"x"}\NormalTok{, }\AttributeTok{y =} \StringTok{"f(x)"}\NormalTok{, }
       \AttributeTok{title =} \StringTok{"Normal Distribution With Mean = 0 \& SD = 1"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{SCMA470Bookdownproj_files/figure-latex/unnamed-chunk-2-1.pdf}

\hypertarget{expectation}{%
\section{Expectation}\label{expectation}}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-5}{}\label{def:unlabeled-div-5}

\emph{The \textbf{expected value} of a discrete random variable
\(X\) with the set of possible values \(A\) and probability mass function
\(f(x)\) is defined by \[\mathrm{E}(X) = \sum_{x \in A} x f(x)\]}

\end{definition}

The \textbf{expected value} of a random variable \(X\) is also called the mean,
or the mathematical expectation, or simply the expectation of \(X\). It is
also occasionally denoted by \(\mathrm{E}[X]\), \(\mu_X\), or \(\mu\).

Note that if each value \(x\) of \(X\) is weighted by \(f(x) = P(X = x)\),
then \(\displaystyle \sum_{x \in A} x f(x)\) is nothing but the weighted
average of \(X\).

\begin{theorem}
\protect\hypertarget{thm:unlabeled-div-6}{}\label{thm:unlabeled-div-6}

\emph{Let \(X\) be a discrete random variable with set of
possible values \(A\) and probability mass function \(f(x)\), and let \(g\) be
a real-valued function. Then \(g(X)\) is a random variable with
\[\mathrm{E}[g(X)] = \sum_{x \in A} g(x) f(x)\] }

\end{theorem}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-7}{}\label{def:unlabeled-div-7}

\emph{If \(X\) is a continuous random variable with
probability density function \(f\) , the \textbf{expected value} of \(X\) is
defined by \[\mathrm{E}(X) = \int_{-\infty}^\infty x f(x)\, dx\] }

\end{definition}

\begin{theorem}
\protect\hypertarget{thm:unlabeled-div-8}{}\label{thm:unlabeled-div-8}

\begin{itemize}
\tightlist
\item
  Let \(X\) be a continuous random variable with
  probability density function \(f (x)\); then for any function
  \(h: \mathbb{R} \rightarrow \mathbb{R}\),
  \[\mathrm{E}[h(X)] = \int_{-\infty}^\infty h(x)\, f(x)\, dx\] *
\end{itemize}

\end{theorem}

\begin{theorem}
\protect\hypertarget{thm:unlabeled-div-9}{}\label{thm:unlabeled-div-9}

\emph{Let \(X\) be a random variable. Let
\(h_1, h_2, . . . , h_n\) be real-valued functions, and
\(a_1, a_2, \ldots, a_n\) be real numbers. Then
\[\mathrm{E}[a_1 h_1(X) + a_2 h_2(X) + \cdots + a_n h_n(X)] = a_1 \mathrm{E}[h_1(X)] + a_2 \mathrm{E}[h_2(X)] + \ldots +
    a_n \mathrm{E}[h_n(X)]\]}

\end{theorem}

Moreover, if \(a\) and \(b\) are constants, then
\[\mathrm{E}(aX +b) = a\mathrm{E}(x) + b\]

\hypertarget{variances-of-random-variables}{%
\section{Variances of Random Variables}\label{variances-of-random-variables}}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-10}{}\label{def:unlabeled-div-10}

\emph{Let \(X\) be a discrete random variable with a set of
possible values \(A\), probability mass function \(f(x)\), and
\(\mathrm{E}(X) = \mu\). then \(\mathrm{Var}(X)\) and \(\sigma_X\), called the
\textbf{variance} and \textbf{standard deviation} of \(X\), respectively, are
defined by
\[\mathrm{Var}(X) = \mathrm{E}[(X- \mu)^2] = \sum_{x \in A} (x - \mu)^2 f(x),\]
\[\sigma_X = \sqrt{\mathrm{E}[(X- \mu)^2]}\]}

\end{definition}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-11}{}\label{def:unlabeled-div-11}

\emph{If \(X\) is a continuous random variable with
\(\mathrm{E}(X) = \mu\), then \(\mathrm{Var}(X)\) and \(\sigma_X\), called the
\textbf{variance} and \textbf{standard deviation} of \(X\), respectively, are
defined by
\[\mathrm{Var}(X) = \mathrm{E}[(X- \mu)^2] =  \int_{-\infty}^\infty (x - \mu)^2\, f(x)\, dx ,\]
\[\sigma_X = \sqrt{\mathrm{E}[(X- \mu)^2]}\]}

\end{definition}

We have the following important relations
\[\mathrm{Var}(x) = \mathrm{E}(X^2) - (\mathrm{E}(x))^2 ,\]
\[\mathrm{Var}(aX + b) = a^2\ Var(X), \quad   \sigma_{aX + b}= |a|\sigma_X\]
where \(a\) and \(b\) are constants.

\hypertarget{moments-and-moment-generating-function}{%
\section{Moments and Moment Generating Function}\label{moments-and-moment-generating-function}}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-12}{}\label{def:unlabeled-div-12}

\emph{For \(r > 0\), the \(r\)th moment of \(X\) (the \(r\)th
moment about the origin) is \(\mathrm{E}[X^r]\), when it is defined. The
\(r\)th central moment of a random variable \(X\) (the \(r\)th moment about
the mean) is \(\mathrm{E}[(X - \mathrm{E}[X])^r].\) }

\end{definition}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-13}{}\label{def:unlabeled-div-13}

\emph{The skewness of \(X\) is defined to be the third
central moment, \[\mathrm{E}[(X - \mathrm{E}[X])^3],\] and the
coefficient of skewness to be given by
\[\frac{\mathrm{E}[(X - \mathrm{E}[X])^3]}{(\mathrm{Var}[X])^{3/2}}.\] }

\end{definition}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-14}{}\label{def:unlabeled-div-14}

\emph{The coefficient of kurtosis of \(X\) is defined by
\[\frac{\mathrm{E}[(X - \mathrm{E}[X])^4]}{(\mathrm{Var}[X])^{4/2}}.\] }

\end{definition}

\textbf{Note} In the formula, subtract from the mean and normalise or divide by the standard deviation center and scale to the standard values. Odd-order moments are increased if there is a long tail to the right and decreased if there is a long tail to the left, while even-order moments are increased if either tail is long. A negative value of the coefficient of skewness that the distribution is skewed to the left, or negatively skewed, meaning that the deviations above the mean tend to be smaller than the deviations below the mean, and vice versa. If the coefficent of skewness is close to zero, this could mean symmetry,

\textbf{Note} The fourth moment measures the fatness in the tails, which is always positive. The kurtosis of the standard normal distribution is 3. Using the standard normal distribution as a benchmark, the excess kurtosis of a random variable is defined as the kurtosis minus 3. A higher kurtosis corresponds to a larger extremity of deviations (or outliers), which is called excess kurtosis.

The following diagram compares the shape between the normal distribution and Student's t-distribution. Note that to use the legend with the \texttt{stat\_function} in ggplot2, we use \texttt{scale\_colour\_manual} along with \texttt{colour\ =} inside the \texttt{aes()} as shown below and give names for specific density plots.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x=}\FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{,}\AttributeTok{by=}\FloatTok{0.1}\NormalTok{))}
\FunctionTok{ggplot}\NormalTok{(df) }\SpecialCharTok{+} 
    \FunctionTok{stat\_function}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, }\AttributeTok{colour =} \StringTok{"dnorm"}\NormalTok{),}\AttributeTok{fun =}\NormalTok{ dnorm, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{))  }\SpecialCharTok{+} 
    \FunctionTok{stat\_function}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, }\AttributeTok{colour =}\StringTok{"dt"}\NormalTok{),}\AttributeTok{fun =}\NormalTok{ dt, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{df =} \DecValTok{4}\NormalTok{)) }\SpecialCharTok{+}
     \FunctionTok{scale\_colour\_manual}\NormalTok{(}\StringTok{"Legend title"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{)) }\SpecialCharTok{+} 
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"x"}\NormalTok{, }\AttributeTok{y =} \StringTok{"f(x)"}\NormalTok{, }
       \AttributeTok{title =} \StringTok{"Normal Distribution With Mean = 0 \& SD = 1"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{SCMA470Bookdownproj_files/figure-latex/unnamed-chunk-3-1.pdf}

Next we will simulate 10000 samples from a normal distribution with mean 0, and standard deviation 1, then compute and interpret for the skewness and kurtosis, and plot the histogram. Here we also use
the function \texttt{set.seed()} to set the seed of R's random number generator, this is useful for creating simulations or random objects that can be reproduced.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{15}\NormalTok{) }\CommentTok{\# Set the seed of R\textquotesingle{}s random number generator}

\CommentTok{\#Simulation}
\NormalTok{n.sample }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{10000}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}

\CommentTok{\#Skewness and Kurtosis}
\FunctionTok{library}\NormalTok{(moments)}
\FunctionTok{skewness}\NormalTok{(n.sample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.03585812
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kurtosis}\NormalTok{(n.sample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.963189
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =}\NormalTok{ n.sample),}\FunctionTok{aes}\NormalTok{(x)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{SCMA470Bookdownproj_files/figure-latex/unnamed-chunk-4-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{15}\NormalTok{)}

\CommentTok{\#Simulation}
\NormalTok{t.sample }\OtherTok{\textless{}{-}} \FunctionTok{rt}\NormalTok{(}\AttributeTok{n =} \DecValTok{10000}\NormalTok{, }\AttributeTok{df =} \DecValTok{5}\NormalTok{)}

\CommentTok{\#Skewness and Kurtosis}
\FunctionTok{library}\NormalTok{(moments)}
\FunctionTok{skewness}\NormalTok{(t.sample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.06196269
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kurtosis}\NormalTok{(t.sample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7.646659
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =}\NormalTok{ t.sample),}\FunctionTok{aes}\NormalTok{(x)) }\SpecialCharTok{+} \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{SCMA470Bookdownproj_files/figure-latex/unnamed-chunk-5-1.pdf}

\textbf{Example} Let us count the number of samples greater than 5 from the samples of the normal and Student's t distributions. Comment on your results

eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFdyaXRlIHlvdXIgY29kZSBoZXJlXG5zZXQuc2VlZCgxNSlcbm4uc2FtcGxlIDwtIHJub3JtKG4gPSAxMDAwMCwgbWVhbiA9IDAsIHNkID0gMSlcbnQuc2FtcGxlIDwtIHJ0KG4gPSAxMDAwMCwgZGYgPSA1KSJ9

\begin{definition}
\protect\hypertarget{def:unlabeled-div-15}{}\label{def:unlabeled-div-15}

\emph{The moment generating function (mgf) of a random
variable \(X\) is defined to be \[M_X(t) = E[e^{tX}],\] if the expectation
exists.}

\end{definition}

\textbf{Note} The moment generating function of \(X\) may not defined (may not
be finite) for all \(t\) in \(\mathbb{R}\).

If \(M_X(t)\) is finite for \(|t| < h\) for some \(h > 0\), then, for any
\(k = 1, 2, \ldots,\) the function \(M_X(t)\) is k-times differentiable at
\(t = 0\), with \[M^{(k)}_X (0) = \mathrm{E}[X^k],\] with
\(\mathrm{E}[|X|^k]\) finite. We can obtain the moments by succesive
differentiation of \(M_X(t)\) and letting \(t = 0\).

\begin{example}
\protect\hypertarget{exm:unlabeled-div-16}{}\label{exm:unlabeled-div-16}

Derive the formula for the mgf of the standard normal distribution.
Hint: its mgf is \(e^{\frac{1}{2} t^2}\).

\end{example}

\hypertarget{probability-generating-function}{%
\section{Probability generating function}\label{probability-generating-function}}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-17}{}\label{def:unlabeled-div-17}

\emph{For a counting variable \(N\) (a variable which
assumes some or all of the values \(0, 1, 2, \ldots,\) but no others), The
probability generating function of \(N\) is \[G_N(t) = E[t^N],\] for those
\(t\) in \(\mathbb{R}\) for which the series converges absolutely. }

\end{definition}

Let \(p_k = P(N = k)\). Then
\[G_N(t) = E[t^N] = \sum_{k=0}^\infty t^k p_k.\] It can be shown that if
\(E[N] < \infty\) then \[\mathrm{E}[N] = G'_N(1),\] and if
\(E[N^2] < \infty\) then
\[\mathrm{Var}[N] = G''_N(1) + G'_N(1) - (G'_N(1))^2.\] Moreover, when
both pgf and mgf of \(N\) are defined, we have
\[G_N(t) = M_N(\log(t)) \quad \text{ and } M_N(t) = G_N(e^t).\]

\hypertarget{multivariate-distributions}{%
\section{Multivariate Distributions}\label{multivariate-distributions}}

When \(X_1,X_2,\ldots ,X_n\) be random variables defined on the same
sample space, a multivariate probability density function or probability
mass function\\
\(f(x_1, x_2, \ldots x_n)\) can be defined. The following definitions can
be extended to more than two random variables and the case of discrete
random variables.

\begin{definition}
\protect\hypertarget{def:unlabeled-div-18}{}\label{def:unlabeled-div-18}

\emph{Two random variables \(X\) and \(Y\), defined on the
same sample space, have a continuous joint distribution if there exists
a nonnegative function of two variables, \(f(x, y)\) on
\(\mathbb{R} \times \mathbb{R}\) , such that for any region \(R\) in the
\(xy\)-plane that can be formed from rectangles by a countable number of
set operations, \[P((X, Y)  \in R) = \iint_R f(x,y) \, dx\, dy\] }

\end{definition}

The function \(f (x, y)\) is called the \textbf{joint probability density
function} of \(X\) and \(Y\).

Let \(X\) and \(Y\) have joint probability density function \(f (x, y)\). Let
\(f_Y\) be the probability density function of \(Y\) . To find \(f_Y\) in
terms of \(f\) , note that, on the one hand, for any subset \(B\) of \(R\),
\[P(Y \in B) = \int_B f_Y(y) \, dy,\] and on the other hand, we also
have
\[P(Y \in B) = P(X \in (-\infty, \infty), Y \in B) = \int_B \left(    \int_{-\infty}^\infty f(x,y)\, dx  \right) \, dy.\]

We have
\begin{equation} 
\label{eq:label} f_Y(y) =   \int_{-\infty}^\infty f(x,y)\, dx
\end{equation}
and
\begin{equation} 
\label{eq:label2}  f_X(x) =   \int_{-\infty}^\infty f(x,y)\, dy
\end{equation}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-19}{}\label{def:unlabeled-div-19}

\emph{Let \(X\) and \(Y\) have joint probability density
function \(f (x, y)\); then the functions \(f_X\) and \(f_Y\) in} \eqref{eq:label} and \eqref{eq:label2}
\emph{are called,
respectively, the \textbf{marginal probability density functions} of \(X\) and
\(Y\) .}

\end{definition}

Let \(X\) and \(Y\) be two random variables (discrete, continuous, or
mixed). The \textbf{joint probability distribution function}, or \textbf{joint
cumulative probability distribution function}, or simply the joint
distribution of \(X\) and \(Y\), is defined by
\[F(t, u) = P(X \le t, Y \le u)\] for all \(t, u \in (-\infty, \infty)\).

The marginal probability distribution function of \(X\), \(F_X\), can be
found from \(F\) as follows:
\[F_X(t) = \lim_{n \rightarrow \infty} F(t,u)  = F(t, \infty)\] and
\[F_Y(u) = \lim_{n \rightarrow \infty}F(t,u)  = F( \infty, u)\]

The following relationship between \(f(x,y)\) and \(F(t,u)\) is as follows:
\[F(t,u) = \int_{-\infty}^{u}\int_{-\infty}^{t} f(x,y)\, dx\, dy.\]

We also have
\[\mathrm{E}(X) =   \int_{-\infty}^\infty x f_X(x)\, dx , \quad \mathrm{E}(Y) =   \int_{-\infty}^\infty y f_Y(y)\, dy\]

\begin{theorem}
\protect\hypertarget{thm:unlabeled-div-20}{}\label{thm:unlabeled-div-20}

\emph{Let \(f (x, y)\) be the joint probability density function
of random variables \(X\) and \(Y\). If \(h\) is a function of two variables
from \(\mathbb{R}^2\) to \(\mathbb{R}\), then \(h(X, Y )\) is a random
variable with the expected value given by
\[\mathrm{E}[h(X,Y)] = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty} h(x,y) \, f(x,y)\, dx\, dy\]
provided that the integral is absolutely convergent.}

\end{theorem}

As a consequence of the above theorem, for random variables \(X\) and \(Y\),
\[\mathrm{E}(X + Y) = \mathrm{E}(X) + \mathrm{E}(Y)\]

\hypertarget{independent-random-variables}{%
\section{Independent random variables}\label{independent-random-variables}}

\begin{definition}
\protect\hypertarget{def:unlabeled-div-21}{}\label{def:unlabeled-div-21}

\emph{Two random variables \(X\) and \(Y\) are called
independent if, for arbitrary subsets \(A\) and \(B\) of real numbers, the
events \(\{X \in A\}\) and \(\{Y \in B\}\) are \textbf{independent}, that is, if
\[P(X \in A, Y \in B) = P(X \in A) P(Y \in B).\]}

\end{definition}

\begin{theorem}
\protect\hypertarget{thm:unlabeled-div-22}{}\label{thm:unlabeled-div-22}

\emph{Let \(X\) and \(Y\) be two random variables defined on the
same sample space. If \(F\) is the joint probability distribution function
of \(X\) and \(Y\), then \(X\) and \(Y\) are independent if and only if for all
real numbers \(t\) and \(u\), \[F(t,u)  = F_X(t) F_Y(u).\]}

\end{theorem}

\begin{theorem}
\protect\hypertarget{thm:unlabeled-div-23}{}\label{thm:unlabeled-div-23}

\emph{Let \(X\) and \(Y\) be jointly continuous random variables
with joint probability density function \(f (x, y)\). Then \(X\) and \(Y\) are
independent if and only if \[f (x, y) = f_X(x) f_Y (y).\]}

\end{theorem}

\begin{theorem}
\protect\hypertarget{thm:unlabeled-div-24}{}\label{thm:unlabeled-div-24}

\emph{Let \(X\) and \(Y\) be independent random variables and
\(g : \mathbb{R} \rightarrow\mathbb{R}\) and
\(h : \mathbb{R} \rightarrow\mathbb{R}\) be real-valued functions; then
\(g(X)\) and \(h(Y )\) are also independent random variables.}

\end{theorem}

As a consequence of the above theorem, we obtain

\begin{theorem}
\protect\hypertarget{thm:unlabeled-div-25}{}\label{thm:unlabeled-div-25}

\emph{Let \(X\) and \(Y\) be independent random variables. Then
for all real-value functions \(g : \mathbb{R} \rightarrow\mathbb{R}\) and
\(h : \mathbb{R} \rightarrow\mathbb{R}\),
\[\mathrm{E}[g(X)h(Y)] = \mathrm{E}[g(X)]\mathrm{E}[h(Y)]\] }

\end{theorem}

\hypertarget{conditional-distributions}{%
\section{Conditional Distributions}\label{conditional-distributions}}

Let \(X\) and \(Y\) be two continuous random variables with the joint
probability density function \(f (x, y)\). Note that the case of discrete
random variables can be considered in the same way. When no information
is given about the value of \(Y\), the marginal probability density
function of \(X\), \(f_X(x)\) is used to calculate the probabilities of
events concerning \(X\). However, when the value of \(Y\) is known, to find
such probabilities, \(f_{X|Y} (x|y)\), the conditional probability density
function of \(X\) given that \(Y = y\) is used and is defined as follows:
\[f_{X|Y} (x|y)  = \frac{f(x,y)}{f_Y(y)}\] provided that \(f_Y (y) > 0\).
Note also that the conditional probability density function of \(X\) given
that \(Y = y\) is itseof a probability density function, i.e.
\[\int_{-\infty}^\infty f_{X|Y}(x|y)\, dx  =  1.\]

Note that the conditional probability distribution function of \(X\) given
that \(Y = y\), the conditional expectation of \(X\) given that \(Y = y\) can
be as follows:
\[F_{Y|X}(x|y) = P(X \le x | Y = y) = \int_ {-\infty}^x f_{X|Y}(t|y) \, dt\]
and
\[\mathrm{E}(X|Y = y) =  \int_{-\infty}^{\infty} x  f_{X|Y}(x|y) \, dx,\]
where \(f_Y(y) > 0\).

Note that if \(X\) and \(Y\) are independent, then \(f_{X|Y}\) coincides with
\(f_X\) because
\[f_{X|Y}(x|y) = \frac{f(x,y)}{f_Y(y)} =\frac{f_X(x)f_Y(y)}{f_Y(y)} = f_X(x).\]

\hypertarget{covariance}{%
\section{Covariance}\label{covariance}}

The notion of the variance of a random variable \(X\),
\(\mathrm{Var}(X) = \mathrm{E}[ ( X - \mathrm{E}(X))^2]\) measures the
average magnitude of the fluctuations of the random variable \(X\) from
its expectation, \(\mathrm{E}(X)\). This quantity measures the dispersion,
or spread, of the distribution of \(X\) about its expectation. Now suppose
that \(X\) and \(Y\) are two jointly distributed random variables.
Covariance is a measure of how much two random variables vary together.

Let us calculuate \(\mathrm{Var}(aX + bY)\) the joint spread, or
dispersion, of \(X\) and \(Y\) along the \((ax + by)\)-direction for arbitrary
real numbers \(a\) and \(b\):
\[\mathrm{Var}(aX + bY) = a^2 \mathrm{Var}(X) + b^2 \mathrm{Var}(Y) + 2 a b \mathrm{E}[(X - \mathrm{E}(X))(Y - \mathrm{E}(Y))].\]
However, \(\mathrm{Var}(X)\) and \(\mathrm{Var}(Y )\) determine the
dispersions of \(X\) and \(Y\) independently; therefore,
\(\mathrm{E}[(X - \mathrm{E}(X))(Y - \mathrm{E}(Y))]\) is the quantity
that gives information about the joint spread, or dispersion, \(X\) and
\(Y\) .

\begin{definition}
\protect\hypertarget{def:unlabeled-div-26}{}\label{def:unlabeled-div-26}

\emph{Let \(X\) and \(Y\) be jointly distributed random
variables; then the \textbf{covariance} of \(X\) and \(Y\) is defined by
\[\mathrm{Cov}(X,Y) =  \mathrm{E}[(X - \mathrm{E}(X))(Y - \mathrm{E}(Y))].\]}

\end{definition}

Note that for random variables \(X, Y\) and \(Z\), and \(ab > 0\), then the
joint dispersion of \(X\) and \(Y\) along the \((ax + by)\)-direction is
greater than the joint dispersion of \(X\) and \(Z\) along the
\((ax + bz)\)-direction if and only if
\(\mathrm{Cov}(X, Y) > \mathrm{Cov}(X,Z).\)

Note that \[\mathrm{Cov}(X, X) = \mathrm{Var}(X).\] Moreover,
\[\mathrm{Cov}(X,Y) = \mathrm{E}(XY) - \mathrm{E}(X)\mathrm{E}(Y).\]

Properties of covariance are as follows: for arbitrary real numbers
\(a, b, c, d\) and random variables \(X\) and \(Y\),
\[\mathrm{Var}(aX + bY) = a^2 \mathrm{Var}(X) + b^2 \mathrm{Var}(Y) + 2 a b \mathrm{Cov}(X,Y).\]
\[\mathrm{Cov}(aX + b, cY + d) = acCov(X, Y)\] For random variables
\(X_1, X_2, . . . , X_n\) and \(Y_1, Y_2, . . . , Y_m\),
\[\mathrm{Cov}(\sum_{i=1}^n a_i X_i, \sum_{j=1}^m b_j Y_j) = \sum_{i=1}^n\sum_{j=1}^m a_i\,b_j\, \mathrm{Cov}(X_i,Y_j).\]

If \(\mathrm{Cov}(X, Y) > 0\), we say that \(X\) and \(Y\) are positively
correlated. If \(\mathrm{Cov}(X, Y) < 0\), we say that they are negatively
correlated. If \(\mathrm{Cov}(X, Y) = 0\), we say that \(X\) and \(Y\) are
uncorrelated.

If \(X\) and \(Y\) are independent, then \[\mathrm{Cov}(X,Y) = 0.\] However,
the converse of this is not true; that is, two dependent random
variables might be uncorrelated.

\hypertarget{correlation}{%
\section{Correlation}\label{correlation}}

A large covariance can mean a strong relationship between variables.
However, we cannot compare variances over data sets with different
scales. A weak covariance in one data set may be a strong one in a
different data set with different scales. The problem can be fixed by
dividing the covariance by the standard deviation to get the correlation
coefficient.

\begin{definition}
\protect\hypertarget{def:unlabeled-div-27}{}\label{def:unlabeled-div-27}

\emph{Let \(X\) and \(Y\) be two random variables with
\(0< \sigma^2_X, \sigma^2_Y < \infty\). The covariance between the
standardized \(X\) and the standardized \(Y\) is called the correlation
coefficient between \(X\) and \(Y\) and is denoted \(\rho = \rho(X,Y)\),
\[\rho(X,Y) = \frac{\mathrm{Cov}(X,Y)}{\sigma_X \sigma_Y}.\] }

\end{definition}

Note that

\begin{itemize}
\item
  \(\rho(X, Y ) > 0\) if and only if \(X\) and \(Y\) are positively
  correlated;
\item
  \(\rho(X, Y ) < 0\) if and only if \(X\) and \(Y\) are negatively
  correlated; and
\item
  \(\rho(X, Y ) = 0\) if and only if \(X\) and \(Y\) are uncorrelated.
\item
  \(\rho(X, Y )\) roughly measures the amount and the sign of linear
  relationship between \(X\) and \(Y\).
\end{itemize}

In the case of perfect linear relationship, we have
\(\rho(X, Y ) = \pm1\). A correlation of 0, i.e.~\(\rho(X, Y ) = 0\) does
not mean zero relationship between two variables; rather, it means zero
linear relationship.

Some importants properties of correlation are
\[-1 \le \rho(X, Y ) \le 1\]
\[\rho(a X + b, cY +d) = \text{sign}(ac) \rho(X, Y )\]

\hypertarget{model-fitting}{%
\section{Model Fitting}\label{model-fitting}}

The contents in this section are taken from Gray and Pitts.

To fit a parametric model, we have to calculate estimates of the unknown
parameters of the probability distribution. Various criteria are
available, including the method of moments, the method of maximum
likelihood, etc.

\hypertarget{the-method-of-moments}{%
\section{The method of moments}\label{the-method-of-moments}}

The method of moments leads to parameter estimates by simply matching
the moments of the model,
\(\mathrm{E}[X], \mathrm{E}[X^2], \mathrm{E}[X^3], \ldots ,\) in turn to
the required number of corresponding sample moments calculated from the
data \(x_1, x_2, \ldots , x_n\), where \(n\) is the number of observations
available. The sample moments are simply
\[\frac{1}{n}\sum_{i=1}^n x_i, \quad  \frac{1}{n}\sum_{i=1}^n  x^2_i, \quad \frac{1}{n}\sum_{i=1}^n x^3_i, \ldots.\]
It is often more convenient to match the mean and central moments, in
particular matching \(\mathrm{E}[X]\) to the sample mean \(\bar{x}\) and
\(\mathrm{Var}[X]\) to the sample variance
\[s^2 = \frac{1}{n-1}\sum_{i=1}^n (x_i - \bar{x})^2.\]

An estimate produced using the method of moments is called an MME, and
the MME of a parameter \(\theta\), say, is usually denoted
\(\tilde{\theta}\).

\hypertarget{the-method-of-maximum-likelihood}{%
\section{The method of maximum likelihood}\label{the-method-of-maximum-likelihood}}

The method of maximum likelihood is the most widely used method for
parameter estimation. The estimates it produces are those values of the
parameters which give the maximum value attainable by the likelihood
function, denoted \(L\), which is the joint probability mass or density
function for the data we have (under the chosen parametric
distribution), regarded as a function of the unknown parameters.

In practice, it is often easier to maximise the loglikelihood function,
which is the logarithm of the likelihood function, rather than the
likelihood itself. An estimate produced using the method of maximum
likelihood is called an MLE, and the MLE of a parameter \(\theta\), say,
is denoted \(\hat{\theta}\). MLEs have many desirable theoretical
properties, especially in the case of large samples.

In some simple cases we can derive MLE(s) analytically as explicit
functions of summaries of the data. Thus, suppose our data consist of a
random sample \(x_1, x_2, \ldots , x_n\), from a parametric distribution
whose parameter(s) we want to estimate. Some straightforward cases
include the following:

\begin{itemize}
\item
  the MLE of \(\lambda\) for a \(Poi(\lambda)\) distribution is the sample
  mean, that is \(\hat{\lambda} = \bar{x}\)
\item
  the MLE of \(\lambda\) for an \(Exp(\lambda)\) distribution is the
  reciprocal of the sample mean, that is \(\hat{\lambda} = 1/\bar{x}\)
\end{itemize}

\hypertarget{goodness-of-fit-tests}{%
\section{Goodness of fit tests}\label{goodness-of-fit-tests}}

We can assess how well the fitted distributions reflect the distribution
of the data in various ways. We should, of course, examine and compare
the tables of frequencies and, if appropriate, plot and compare
empirical distribution functions. More formally, we can perform certain
statistical tests. Here we will use the Pearson chi-square
goodness-of-fit criterion.

\hypertarget{the-pearson-chi-square-goodness-of-fit-criterion}{%
\section{the Pearson chi-square goodness-of-fit criterion}\label{the-pearson-chi-square-goodness-of-fit-criterion}}

We construct the test statistic \[\chi^2 = \frac{\sum(O - E)^2}{E},\]
where \(O\) is the observed frequency in a cell in the frequency table and
\(E\) is the fitted or expected frequency (the frequency expected in that
cell under the fitted model), and where we sum over all usable cells.

\textbf{The null hypothesis} is that the sample comes from a specified
distribution.

The value of the test statistic is then evaluated in one of two ways.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  We convert it to a \(P\)-value, which is a measure of the strength of
  the evidence against the hypothesis that the data do follow the
  fitted distribution. \textbf{If the \(P\)-value is small enough, we conclude
  that the data do not follow the fitted distribution -- we say ``the
  fitted distribution does not provide a good fit to the data'' (and
  quote the \(P\)-value in support of this conclusion)}.
\item
  We compare it with values in published tables of the distribution
  function of the appropriate \(\chi^2\) distribution, and if the value
  of the statistic is high enough to be in a tail of specified size of
  this reference distribution, we conclude that the fitted
  distribution does not provide a good fit to the data.
\end{enumerate}

\hypertarget{kolmogorov-smirnov-k-s-test.}{%
\section{Kolmogorov-Smirnov (K-S) test.}\label{kolmogorov-smirnov-k-s-test.}}

The K-S test statistic is the maximum difference between the values of
the ecdf of the sample and the cdf of the fully specified fitted
distribution.

The course does not emphasis on the Goodness of Fit Test. Please refer
to the reference text for more details.

\hypertarget{loss-distributions}{%
\chapter{Loss distributions}\label{loss-distributions}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

The aim of the course is to provide a fundamental basis which applies
mainly in general insurance. General insurance companies' products are
short-term policies that can be purchased for a short period of time.
Examples of insurance products are

\begin{itemize}
\item
  motor insurance;
\item
  home insurance;
\item
  health insurance; and
\item
  travel insurance.
\end{itemize}

In case of an occurrence of an insured event, two important components
of financial losses which are of importance for management of an
insurance company are

\begin{itemize}
\item
  the number of claims; and
\item
  the amounts of those claims.
\end{itemize}

Mathematical and statistical techniques used to model these sources of
uncertainty will be discussed. This will enable insurance companies to

\begin{itemize}
\item
  calculate premium rates to charge policy holders; and
\item
  decide how much reserve should be set aside for the future payment
  of incurred claims.
\end{itemize}

In the chapter, statistical distributions and their properties which are
suitable for modelling claim sizes are reviewed. These distribution are
also known as loss distributions. In practice, the shape of loss
distributions are positive skew with a long right tail. The main
features of loss distributions include:

\begin{itemize}
\item
  having a few small claims;
\item
  rising to a peak;
\item
  tailing off gradually with a few very large claims.
\end{itemize}

\hypertarget{exponential-distribution}{%
\section{Exponential Distribution}\label{exponential-distribution}}

A random variable \(X\) has an exponential distribution with a parameter
\(\lambda > 0\), denoted by \(X \sim \text{Exp}(\lambda)\) if its
probability density function is given by
\[f_X(x) = \lambda e^{-\lambda x}, \quad x > 0.\]

\begin{example}
\protect\hypertarget{exm:unlabeled-div-28}{}\label{exm:unlabeled-div-28}

\emph{Let \(X \sim \text{Exp}(\lambda)\) and \(0 < a < b\).}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Find the distribution \(F_X(x)\).}
\item
  \emph{Express \(P(a < X < B)\) in terms of \(f_X(x)\) and \(F_X(x)\).}
\item
  \emph{Show that the moment generating function of \(X\) is
  \[M_X(t) = \left(1 -  \frac{t}{\lambda}\right)^{-1}, \quad t < \lambda.\]}
\item
  \emph{Derive the \(r\)-th moment about the origin \(\mathrm{E}[X^r].\)}
\item
  \emph{Derive the coefficient of skewness for \(X\).}
\item
  \emph{Simulate a random sample of size n = 200 from
  \(X \sim \text{Exp}(0.5)\) using the command
  \texttt{sample\ =\ rexp(n,\ rate\ =\ lambda)} where \(n\) and \(\lambda\) are the chosen
  parameter values.}
\item
  \emph{Plot a histogram of the random sample using the command
  \texttt{hist(sample)} (use help for available options for \texttt{hist} function
  in R).}
\end{enumerate}

\end{example}

\textbf{Solution:}
The code for questions 6 and 7 is given below. The histogram can be generated from the code below.

\begin{verbatim}
# set.seed is used so that random number generated from different simulations are the same. 
# The number 5353 can be set arbitrarily. 
set.seed(5353)

nsample <- 200
data_exp <- rexp(nsample, rate = 0.5)

dataset <- data_exp
hist(dataset, breaks=100,probability = TRUE, xlab = "claim sizes" 
     , ylab = "density", main = paste("Histogram of claim sizes" ))

hist(dataset, breaks=100, xlab = "claim sizes" 
     , ylab = "count", main = paste("Histogram of claim sizes" ))
\end{verbatim}

Copy and paste the code above and run it.

eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJzZXQuc2VlZCg1MzUzKVxuXG5uc2FtcGxlIDwtIDIwMFxuZGF0YV9leHAgPC0gcmV4cChuc2FtcGxlLCByYXRlID0gMC41KVxuXG5kYXRhc2V0IDwtIGRhdGFfZXhwXG5oaXN0KGRhdGFzZXQsIGJyZWFrcz0xMDAscHJvYmFiaWxpdHkgPSBUUlVFLCB4bGFiID0gXCJjbGFpbSBzaXplc1wiIFxuICAgICAsIHlsYWIgPSBcImRlbnNpdHlcIiwgbWFpbiA9IHBhc3RlKFwiSGlzdG9ncmFtIG9mIGNsYWltIHNpemVzXCIgKSkifQ==

eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJzZXQuc2VlZCg1MzUzKVxuXG5uc2FtcGxlIDwtIDIwMFxuZGF0YV9leHAgPC0gcmV4cChuc2FtcGxlLCByYXRlID0gMC41KVxuXG5kYXRhc2V0IDwtIGRhdGFfZXhwXG5cblxuaGlzdChkYXRhc2V0LCBicmVha3M9MTAwLCB4bGFiID0gXCJjbGFpbSBzaXplc1wiIFxuICAgICAsIHlsYWIgPSBcImNvdW50XCIsIG1haW4gPSBwYXN0ZShcIkhpc3RvZ3JhbSBvZiBjbGFpbSBzaXplc1wiICkpIn0=

\textbf{Notes}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The exponential distribution can used to model the inter-arrival
  time of an event.
\item
  The exponential distribution has an important property called \textbf{lack
  of memory}: if \(X \sim \text{Exp}(\lambda)\), then the random
  variable \(X-w\) conditional on \(X > w\) has the same distribution as
  \(X\), i.e.
  \[X \sim \text{Exp}(\lambda)\Rightarrow  X - w | X > w \sim \text{Exp}(\lambda).\]
\end{enumerate}

We can use R to plot the probability density functions (pdf) of exponential distributions with various parameters \(\lambda\), which are shown in Figure \ref{fig:FigExp}. Here we use \texttt{scale\_colour\_manual} to override defaults with scales package (see cheat sheet for details).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{)), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x)) }\SpecialCharTok{+} 
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\StringTok{"Probability density"}\NormalTok{, }\AttributeTok{x =} \StringTok{"x"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Exponential distributions"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dexp,}\AttributeTok{geom =}\StringTok{"line"}\NormalTok{, }\AttributeTok{args =}\NormalTok{ (}\AttributeTok{mean=}\FloatTok{0.5}\NormalTok{), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"0.5"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dexp,}\AttributeTok{geom =}\StringTok{"line"}\NormalTok{, }\AttributeTok{args =}\NormalTok{ (}\AttributeTok{mean=}\DecValTok{1}\NormalTok{), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"1"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dexp,}\AttributeTok{geom =}\StringTok{"line"}\NormalTok{, }\AttributeTok{args =}\NormalTok{ (}\AttributeTok{mean=}\FloatTok{1.5}\NormalTok{), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"1.5"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dexp,}\AttributeTok{geom =}\StringTok{"line"}\NormalTok{, }\AttributeTok{args =}\NormalTok{ (}\AttributeTok{mean=}\DecValTok{2}\NormalTok{), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"2"}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{scale\_colour\_manual}\NormalTok{(}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(lambda, }\StringTok{" = "}\NormalTok{)), }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"orange"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{SCMA470Bookdownproj_files/figure-latex/FigExp-1.pdf}
\caption{\label{fig:FigExp}The probability density functions (pdf) of exponential distributions with various parameters lambda.}
\end{figure}

\hypertarget{gamma-distribution}{%
\section{Gamma distribution}\label{gamma-distribution}}

A random variable \(X\) has a gamma distribution with parameters
\(\alpha > 0\) and \(\lambda > 0\), denoted by
\(X \sim \mathcal{G}(\alpha, \lambda)\) or
\(X \sim \text{gamma}(\alpha, \lambda)\) if its probability density
function is given by
\[f_X(x) = \frac{\lambda^\alpha}{\Gamma(\alpha)} x^{\alpha -1} e^{-\lambda x}, \quad x > 0.\]
The symbol \(\Gamma\) denotes the gamma function, which is defined as
\[\Gamma(\alpha) = \int_{0}^\infty x^{\alpha - 1} e^{-x} \mathop{}\!dx, \quad \text{for } \alpha > 0.\]
It follows that \(\Gamma(\alpha + 1) = \alpha \Gamma(\alpha)\) and that
for a positive integer \(n\), \(\Gamma(n) = (n-1)!\).

The properties of the gamma distribution are summarised.

\begin{itemize}
\item
  The mean and variance of \(X\) are
  \[\mathrm{E}[X] = \frac{\alpha}{\lambda} \text{ and } \mathrm{Var}[X] =\frac{\alpha}{\lambda^2}\]
\item
  The \(r\)-th moment about the origin is
  \[\mathrm{E}[X^r] = \frac{1}{\lambda^r} \frac{\Gamma(\alpha + r)}{\Gamma(\alpha )}, \quad r > 0.\]
\item
  The moment generating function (mgf) of \(X\) is
  \[M_X(t) = \left(1 -  \frac{t}{\lambda}\right)^{-\alpha}, \quad t < \lambda.\]
\item
  The coefficient of skewness is \[\frac{2}{\sqrt{\alpha}}.\]
\end{itemize}

\textbf{Notes}
1. The exponential function is a special case of the gamma
distribution, i.e.~\(\text{Exp}(\lambda)= \mathcal{G}(1,\lambda)\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  If \(\alpha\) is a positive integer, the sum of \(\alpha\) independent,
  identically distributed as \(\text{Exp}(\lambda)\), is
  \(\mathcal{G}(\alpha, \lambda)\).
\item
  If \(X_1, X_2, \ldots, X_n\) are independent, identically distributed,
  each with a \(\mathcal{G}(\alpha, \lambda)\) distribution, then
  \[\sum_{i = 1}^n X_i \sim \mathcal{G}(n\alpha, \lambda).\]
\item
  The exponential and gamma distributions are not fat-tailed, and
  \textbf{may not provide a good fit} to claim amounts.
\end{enumerate}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-29}{}\label{exm:unlabeled-div-29}

\emph{Using the moment generating function of a gamma
distribution, show that the sum of independent gamma random variables
with the same scale parameter \(\lambda\),
\(X \sim \mathcal{G}(\alpha_1, \lambda)\) and
\(Y \sim \mathcal{G}(\alpha_2, \lambda)\), is
\(S = X+ Y \sim \mathcal{G}(\alpha_1 + \alpha_2, \lambda).\)}

\end{example}

\textbf{Solution:}
Because \(X\) and \(Y\) are independent, \[\begin{aligned}
    M_S(t) &= M_{X+Y}(t) = M_X(t) \cdot M_Y(t)\\
        &= (1 - \frac{t}{\lambda})^{-\alpha_1} \cdot (1 - \frac{t}{\lambda})^{-\alpha_2}     \\
        &=  (1 - \frac{t}{\lambda})^{-(\alpha_1 + \alpha_2)}. \end{aligned}\]
Hence \(S = X + Y \sim \mathcal{G}(\alpha_1 + \alpha_2, \lambda).\)

The probability density functions (pdf) of gamma distributions with
various shape parameters \(\alpha\) and rate parameter \(\lambda\) = 1 are shown in Figure \ref{fig:FigGamma}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{20}\NormalTok{)), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\StringTok{"Probability density"}\NormalTok{, }\AttributeTok{x =} \StringTok{"x"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Gamma distribution"}\NormalTok{)  }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dgamma, }\AttributeTok{args=}\FunctionTok{list}\NormalTok{(}\AttributeTok{shape=}\DecValTok{2}\NormalTok{, }\AttributeTok{rate=}\DecValTok{1}\NormalTok{), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"2"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dgamma, }\AttributeTok{args=}\FunctionTok{list}\NormalTok{(}\AttributeTok{shape=}\DecValTok{6}\NormalTok{, }\AttributeTok{rate=}\DecValTok{1}\NormalTok{) , }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"6"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_colour\_manual}\NormalTok{(}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(lambda, }\StringTok{" = 1 and "}\NormalTok{, alpha ,}\StringTok{" = "}\NormalTok{)), }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{SCMA470Bookdownproj_files/figure-latex/FigGamma-1.pdf}
\caption{\label{fig:FigGamma}The probability density functions (pdf) of gamma distributions with various shape alpha and rate parameter lambda = 1.}
\end{figure}

\hypertarget{lognormal-distribution}{%
\section{Lognormal distribution}\label{lognormal-distribution}}

A random variable \(X\) has a lognormal distribution with parameters \(\mu\)
and \(\sigma^2\), denoted by \(X \sim \mathcal{LN}(\mu, \sigma^2)\) if its
probability density function is given by
\[f_X(x) = \frac{1}{\sigma x \sqrt{2 \pi}} \exp\left(-\frac{1}{2} \left( \frac{\log(x) - \mu}{\sigma} \right)^2 \right) , \quad x > 0.\]

The following relation holds:
\[X \sim \mathcal{LN}(\mu, \sigma^2)\Leftrightarrow Y = \log X \sim \mathcal{N}(\mu, \sigma^2).\]

The properties of the lognormal distribution are summarised.

\begin{itemize}
\item
  The mean and variance of \(X\) are
  \[\mathrm{E}[X] = \exp\left(\mu + \frac{1}{2} \sigma^2 \right) \text{ and } \mathrm{Var}[X] =\exp\left(2\mu +  \sigma^2 \right) (\exp(\sigma^2) - 1).\]
\item
  The \(r\)-th moment about the origin is
  \[\mathrm{E}[X^r] =\exp\left(r\mu +  \frac{1}{2}r^2 \sigma^2 \right).\]
\item
  The moment generating function (mgf) of \(X\) is not finite for any
  positive value of \(t\).
\item
  The coefficient of skewness is
  \[(\exp(\sigma^2)  + 2) \left(\exp(\sigma^2)  -1 \right)^{1/2} .\]
\end{itemize}

The probability density functions (pdf) of gamma distributions with
various shape parameters \(\alpha\) and rate parameter \(\lambda = 1\) is shown in Figure \ref{fig:FigLognormal}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{)), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\StringTok{"Probability density"}\NormalTok{, }\AttributeTok{x =} \StringTok{"x"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"lognormal distribution"}\NormalTok{)  }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dlnorm, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{meanlog =} \DecValTok{0}\NormalTok{, }\AttributeTok{sdlog =} \FloatTok{0.25}\NormalTok{), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"0.25"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dlnorm, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{meanlog =} \DecValTok{0}\NormalTok{, }\AttributeTok{sdlog =} \DecValTok{1}\NormalTok{), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"1"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_colour\_manual}\NormalTok{(}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(mu, }\StringTok{" = 0 and "}\NormalTok{, sigma, }\StringTok{"= "}\NormalTok{)), }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{SCMA470Bookdownproj_files/figure-latex/FigLognormal-1.pdf}
\caption{\label{fig:FigLognormal}The probability density functions (pdf) of lognormal distributions with mu = 0 and sigma = 0.25 or 1.}
\end{figure}

\hypertarget{pareto-distribution}{%
\section{Pareto distribution}\label{pareto-distribution}}

A random variable \(X\) has a Pareto distribution with parameters
\(\alpha > 0\) and \(\lambda > 0\), denoted by
\(X \sim \text{Pa}(\alpha, \lambda)\) if its probability density function
is given by
\[f_X(x) = \frac{\alpha \lambda^\alpha}{(\lambda + x)^{\alpha + 1}}, \quad x > 0.\]
The distribution function is given by
\[F_X(x) = 1 - \left(  \frac{\lambda}{\lambda + \alpha} \right)^\alpha, \quad x > 0.\]

The properties of the Pareto distribution are summarized.

\begin{itemize}
\item
  The mean and variance of \(X\) are
  \[\mathrm{E}[X] = \frac{\lambda}{\alpha - 1}, \alpha > 1 \text{ and } \mathrm{Var}[X] = \frac{\alpha \lambda^2}{(\alpha - 1)^2(\alpha - 2)}, \alpha > 2.\]
\item
  The \(r\)-th moment about the origin is
  \[\mathrm{E}[X^r] =\frac{\Gamma(\alpha-r) \Gamma(1+ r)}{\Gamma(\alpha)} \lambda^r, \quad 0 < r < \alpha.\]
\item
  The moment generating function (mgf) of \(X\) is not finite for any
  positive value of \(t\).
\item
  The coefficient of skewness is
  \[\frac{2(\alpha + 1)}{\alpha - 3} \sqrt{\frac{\alpha-2}{\alpha}} , \quad \alpha > 3.\]
\end{itemize}

\textbf{Note}
1. The following conditional tail property for a Pareto distribution is
useful for reinsurance calculation. Let
\(X \sim \text{Pa}(\alpha, \lambda)\). Then the random variable
\(X - w\) conditional on \(X > w\) has a Pareto distribution with
parameters \(\alpha\) and \(\lambda + w\), i.e.
\[X \sim \text{Pa}(\alpha, \lambda)\Rightarrow  X - w | X > w \sim \text{Pa}(\alpha,\lambda + w).\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  The lognormal and Pareto distributions, in practice, provide a
  better fit to claim amounts than exponential and gamma
  distributions.
\item
  Other loss distribution are useful in practice including \textbf{Burr,
  Weibull and loggamma distributions}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(actuar)}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{60}\NormalTok{)), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\StringTok{"Probability density"}\NormalTok{, }\AttributeTok{x =} \StringTok{"x"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Pareto distribution"}\NormalTok{)  }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dpareto, }\AttributeTok{args=}\FunctionTok{list}\NormalTok{(}\AttributeTok{shape=}\DecValTok{3}\NormalTok{, }\AttributeTok{scale=}\DecValTok{20}\NormalTok{), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"alpha = 3, lambda = 20"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dpareto, }\AttributeTok{args=}\FunctionTok{list}\NormalTok{(}\AttributeTok{shape=}\DecValTok{6}\NormalTok{, }\AttributeTok{scale=}\DecValTok{50}\NormalTok{), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"alpha = 6, lambda = 50"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_colour\_manual}\NormalTok{(}\StringTok{"Parameters"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(alpha, }\StringTok{" = 3 and "}\NormalTok{, lambda, }\StringTok{"= 20"}\NormalTok{)),  }\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(alpha, }\StringTok{" = 6 and "}\NormalTok{, lambda, }\StringTok{"= 50"}\NormalTok{)))) }
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{SCMA470Bookdownproj_files/figure-latex/FigPareto-1.pdf}
\caption{\label{fig:FigPareto}The probability density functions (pdf) of Pareto distributions with various shape alpha and rate parameter lambda = 1.}
\end{figure}

\begin{example}
\protect\hypertarget{exm:exampleFittingClaimSizes}{}\label{exm:exampleFittingClaimSizes}

\emph{Consider a data set consisting of 200 claim amounts in
one year from a general insurance portfolio.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Calculate the sample mean and sample standard deviation.}
\item
  \emph{Use the method of moments to fit these data with both exponential
  and gamma distributions.}
\item
  \emph{Calculate the boundaries for groups or bins so that the expected
  number of claims in each bin is 20 under the fitted exponential
  distribution.}
\item
  \emph{Count the values of the observed claim amounts in each bin.}
\item
  \emph{With these bin boundaries, find the expected number of claims when
  the data are fitted with the gamma, lognormal and Pareto distributions.}
\item
  \emph{Plot a histogram for the data set along with fitted exponential
  distribution and fitted gamma distribution. In addition, plot another histogram for the data set along with fitted lognormal
  and fitted Pareto distribution.}
\item
  \emph{Comment on the goodness of fit of the fitted distributions.}
\end{enumerate}

\end{example}

\textbf{Solution:}
1. Given that \(\sum_{i=1}^n x_i = 206046.4\) and
\(\sum_{i=1}^n x_i^2 = 1,472,400,135\), we have
\[\bar{x} = \frac{\sum_{i=1}^n x_i}{n} = \frac{206046.4}{200} = 1030.232.\]
The sample variance and standard deviation are
\[s^2 = \frac{1}{n-1} \left( \sum_{i=1}^n x_i^2 - \frac{(\sum_{i=1}^n x_i)^2}{n} \right) = 6332284,\]
and \[s = 2516.403.\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  We calculate estimates of
  unknown parameters of both exponential and gamma distributions by
  the method of moments. We simply match the mean and central moments,
  i.e.~matching \(\mathrm{E}[X]\) to the sample mean \(\bar{x}\) and
  \(\mathrm{Var}[X]\) to the sample variance.

  The MME (moment matching estimation) of the required distributions
  are as follows:

  \begin{itemize}
  \item
    the MME of \(\lambda\) for an \(\text{Exp}(\lambda)\) distribution
    is the reciprocal of the sample mean,
    \[\tilde{\lambda} = \frac{1}{\bar{x}} = 0.000971.\]
  \item
    the MMEs of \(\alpha\) and \(\lambda\) for a
    \(\mathcal{G}(\alpha, \lambda)\) distribution are
    \[\begin{aligned}
    \tilde{\alpha} &= \left(\frac{\bar{x}}{s}\right)^2 = 0.167614, \\
    \tilde{\lambda} &= \frac{\tilde{\alpha}}{\bar{x}} = 0.000163.\end{aligned}\]
  \item
    the MMEs of \(\mu\) and \(\sigma\) for a
    \(\mathcal{LN}(\mu, \sigma^2)\) distribution are \[\begin{aligned}
    \tilde{\sigma} &= \sqrt{ \ln \left(  \frac{s^2}{\bar{x}^2} + 1 \right)  }  = 1.393218, \\
    \tilde{\mu} &= \ln(\bar{x}) - \frac{\tilde{\sigma}^2 }{2} = 5.967012.\end{aligned}\]
  \item
    the MMEs of \(\alpha\) and \(\lambda\) for a
    \(\text{Pa}(\alpha, \lambda)\) distribution are \[\begin{aligned}
    \tilde{\alpha} &= \displaystyle{ 2 \left(  \frac{s^2}{\bar{x}^2} \right) \frac{1}{(\frac{s^2}{\bar{x}^2} - 1)}   } = 2.402731,\\
    \tilde{\lambda} &= \bar{x} (\tilde{\alpha} - 1) = 1445.138.\end{aligned}\]
  \end{itemize}
\item
  The upper boundaries for the 10 groups or bins so that the expected
  number of claims in each bin is 20 under the fitted exponential
  distribution are determined by
  \[\Pr(X \le \text{upbd}_j) = \frac{j}{10}, \quad j = 1,2,3, \ldots, 9.\]
  With \(\tilde{\lambda}\) from the MME for an \(\text{Exp}(\lambda)\) from the previous,
  \[\Pr(X \le x)  = 1 - \exp(-\tilde{\lambda} x).\] We obtain
  \[\text{upbd}_j = -\frac{1}{\tilde{\lambda}} \ln\left( 1 - \frac{j}{10}\right).\]
  The results are given in Table \ref{tab:tableFitted}.
\item
  The following table shows frequency distributions for observed and
  fitted claims sizes for exponential, gamma, and also lognormal and Pareto fits.
\end{enumerate}

\begin{longtable}[]{@{}rrrrrr@{}}
\caption{\label{tab:tableFitted} Frequency distributions for observed and fitted claims sizes.}\tabularnewline
\toprule
Range & Observation & Exp & Gamma & Lognormal & Pareto \\
\midrule
\endfirsthead
\toprule
Range & Observation & Exp & Gamma & Lognormal & Pareto \\
\midrule
\endhead
(0,109{]} & 60 & 20 & 109.4 & 36 & 31.9 \\
(109,230{]} & 31 & 20 & 14.3 & 34.4 & 27.8 \\
(230,367{]} & 25 & 20 & 9.7 & 26 & 24.2 \\
(367,526{]} & 17 & 20 & 7.8 & 20.5 & 21.2 \\
(526,714{]} & 14 & 20 & 6.8 & 16.6 & 18.6 \\
(714,944{]} & 13 & 20 & 6.3 & 13.9 & 16.4 \\
(944,1240{]} & 6 & 20 & 6.2 & 11.9 & 14.6 \\
(1240,1658{]} & 7 & 20 & 6.5 & 10.8 & 13.2 \\
(1658,2372{]} & 10 & 20 & 7.7 & 10.4 & 12.5 \\
(2372,\(\infty\)) & 17 & 20 & 25.4 & 19.5 & 19.4 \\
\bottomrule
\end{longtable}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  Let \(X\) be the claim size.

  \begin{itemize}
  \item
    The expected number of claims for the fitted exponential
    distribution in the range \((a,b]\) is
    \[200 \cdot \Pr( a < X \le b) = 200( e^{-\tilde{\lambda} a} - e^{-\tilde{\lambda} b} ).\]
    In our case, the expected frequencies under the fitted
    exponential distribution are given in the third column of Table \ref{tab:tableFitted}.
  \item
    (Excel) The expected number of claims for the fitted gamma distribution
    in the range \((a,b]\) is
    \[200 \cdot\left(  \text{GAMMADIST}\left(b, \tilde{\alpha}, \frac{1}{\tilde{\lambda}}, \text{TRUE}\right)  - \text{GAMMADIST}\left(a, \tilde{\alpha}, \frac{1}{\tilde{\lambda}}, \text{TRUE}\right) \right).\]
    The expected frequencies under the fitted gamma distribution are
    given in the fourth column of Table \ref{tab:tableFitted}.
  \item
    (Excel) For the fitted lognormal, the expected number of claims in the
    range \((a,b]\) can be obtained from
    \[200 \cdot\left(  \text{NORMDIST} \left(\frac{LN(b) - 
            \tilde{\mu}}{\tilde{\sigma}}\right)  - \text{NORMDIST}\left(\frac{LN(a) - 
            \tilde{\mu}}{\tilde{\sigma}}\right) \right).\]
  \item
    For the fitted Pareto distribution, the expected number of
    claims in the range \((a,b]\) can be obtained from
    \[200 \left[    \left(\frac{\tilde{\lambda}}{\tilde{\lambda} + a} \right)^{\tilde{\alpha}}  - \left(\frac{\tilde{\lambda}}{\tilde{\lambda} + b} \right)^{\tilde{\alpha}}   \right].\]
  \end{itemize}
\item
  The histograms for the data set with fitted distributions
  are shown in Figures \ref{fig:FittedExpGamma} and \ref{fig:FittedLognormalPareto}.
\item
  Comments:

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    The high positive skewness of the sample reflects the fact that
    SD is large when compared to the mean. Consequently, the
    exponential distribution may not fit the data well.
  \item
    Five claims (2.5\%) are greater than 10,000, which is one of the
    main features of the loss distribution.
  \item
    The fit is poor for the exponential distribution, as we see that
    the model under-fits the data for small claims up to 367 and
    over-fits for large claims between 944 to 2372. The gamma fit is
    again poor. We see that the model over-fits for small claims
    between 0-109 and under-fits for claims 230 and 944.
  \item
    Which one of the lognormal and Pareto distributions provides a
    better fit to the observed claim data?
  \end{enumerate}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(stats)}
\FunctionTok{library}\NormalTok{(MASS)}
\FunctionTok{library}\NormalTok{(ggplot2)}

\NormalTok{xbar }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)}
\NormalTok{s }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)}

\CommentTok{\# MME of alpha and lambda for Gamma distribution}
\NormalTok{alpha\_tilde }\OtherTok{\textless{}{-}}\NormalTok{ (xbar}\SpecialCharTok{/}\NormalTok{s)}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{lambda\_tilde }\OtherTok{\textless{}{-}}\NormalTok{ alpha\_tilde}\SpecialCharTok{/}\NormalTok{xbar}

\FunctionTok{ggplot}\NormalTok{(dat) }\SpecialCharTok{+} \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ claims, }\AttributeTok{y =}\NormalTok{ ..density..), }\AttributeTok{bins =} \DecValTok{90}\NormalTok{ , }\AttributeTok{fill =} \StringTok{"grey"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dexp, }\AttributeTok{geom =}\StringTok{"line"}\NormalTok{, }\AttributeTok{args =}\NormalTok{ (}\AttributeTok{rate =} \DecValTok{1}\SpecialCharTok{/}\FunctionTok{mean}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"Exponential"}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dgamma, }\AttributeTok{geom =}\StringTok{"line"}\NormalTok{, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{shape =}\NormalTok{ alpha\_tilde ,}\AttributeTok{rate =}\NormalTok{ lambda\_tilde), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"Gamma"}\NormalTok{)) }\SpecialCharTok{+} \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.0015}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{scale\_color\_discrete}\NormalTok{(}\AttributeTok{name=}\StringTok{"Fitted Distributions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{SCMA470Bookdownproj_files/figure-latex/FittedExpGamma-1.pdf}
\caption{\label{fig:FittedExpGamma}Histogram of claim sizes with fitted exponential and gamma distributions.}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(actuar)}
\CommentTok{\# MME of mu and sigma for lognormal distribution}

\NormalTok{sigma\_tilda }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{log}\NormalTok{(  }\FunctionTok{var}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)}\SpecialCharTok{/}\FunctionTok{mean}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\DecValTok{1}\NormalTok{  ))  }\CommentTok{\# gives \textbackslash{}tilde\textbackslash{}sigma}
\NormalTok{mu\_tilda }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(}\FunctionTok{mean}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)) }\SpecialCharTok{{-}}\NormalTok{ sigma\_tilda}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{/}\DecValTok{2}      \CommentTok{\# gives \textbackslash{}tilde\textbackslash{}mu}

\CommentTok{\# MME of alpha and lambda for Pareto distribution}
\NormalTok{alpha\_tilda }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{*}\FunctionTok{var}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)}\SpecialCharTok{/}\FunctionTok{mean}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{var}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)}\SpecialCharTok{/}\FunctionTok{mean}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\CommentTok{\#/tilde/alpha}
\NormalTok{lambda\_tilda }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{claims)}\SpecialCharTok{*}\NormalTok{(alpha\_tilda }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}


\FunctionTok{ggplot}\NormalTok{(dat) }\SpecialCharTok{+} \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ claims, }\AttributeTok{y =}\NormalTok{ ..density..), }\AttributeTok{bins =} \DecValTok{90}\NormalTok{ , }\AttributeTok{fill =} \StringTok{"grey"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dlnorm, }\AttributeTok{geom =}\StringTok{"line"}\NormalTok{, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{meanlog =}\NormalTok{ mu\_tilda, }\AttributeTok{sdlog =}\NormalTok{ sigma\_tilda), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"Lognormal"}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun=}\NormalTok{dpareto, }\AttributeTok{geom =}\StringTok{"line"}\NormalTok{, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{shape =}\NormalTok{ alpha\_tilda, }\AttributeTok{scale =}\NormalTok{ lambda\_tilda), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour =} \StringTok{"Pareto"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_discrete}\NormalTok{(}\AttributeTok{name=}\StringTok{"Fitted Distributions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{SCMA470Bookdownproj_files/figure-latex/FittedLognormalPareto-1.pdf}
\caption{\label{fig:FittedLognormalPareto}Histogram of claim sizes with fitted lognormal and pareto distributions.}
\end{figure}

Let us plot the histogram of claim sizes with fitted exponential and gamma distributions in this interaction area. Note that the data set is stored in the variable \texttt{dat}.

eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoc3RhdHMpXG5saWJyYXJ5KE1BU1MpXG5saWJyYXJ5KGdncGxvdDIpXG5kYXQgPC0gYygzMS4wODk0MjE1Niw5MTUuMDI1OTM2MiwzMi4wMjM3OTU2Miw4ODUuODc1NDUxLDkzMTQuMTAwNzk3LDcwNy4xNzM4ODY2LDIxMTQuMzYyNDg2LDYwMS41ODI3ODY2LDQzNS4zNzg4MTM1LDQ5LjgwMTc5NjE5LDE4MDIuMzgzODIsMjExLjYzNjQzOSwxNTMuNTk4NDcxOSw2MC4wNTk2Njk5Miw0OC4xNzE1NzY5Nyw5NDguNzIzNDYyNiwxMzIuNDI3MzEwOSwxNTEuNzEwODE1LDI5NjcuOTYxMDM2LDczNS40MTQ5MzMyLDMwNC41ODA3NTg3LDUwLjUzMzExMDY5LDIyNC43NjY1NTQ2LDM1Ni4xODA5NDM4LDQ3NS43NjY4NDQxLDMwNDQuMTQ5NTEzLDEzLjUwNjY0ODk0LDY3Ljk4Mjc0NDQ5LDMwNC4xNDM5OTY2LDIzOC4wMDAxMDUsMzk5LjA3OTgyNjMsMTQ5LjI4MDc4LDEyOC4yODQ4Mzc5LDIxLjQyMDI3NzE4LDczLjMxNDI2NzMyLDQ5LjQ2ODgyNzkxLDY2Ny41MzI3Mjc1LDQ0LjY3MzYwMTg1LDE0ODk0LjA3ODM5LDY2MC43NjE0MzA3LDEwMC43NjI4NjI4LDYzMi4yODEyMzkxLDQyLjkwODg0Nzc3LDY2LjE3NjkzMTM1LDUwLjY5NDU0MTMyLDE4Ni44NzgxNjY3LDE2OC41NDA4NjE1LDE1MS43Mzk5NzgsMjQxOS41MzIzNTQsNDM0LjQ1NjQwMzIsNjkuMDM0NjAyMzIsMTYyLjY2OTg1OTMsMjI2LjYxMTAzOTUsMzMuNjE1MDM0OTUsMjMzLjAyNzk5NiwzMjQ0Ljk0NTg5MywzNTQuMjUzNDgxMyw3OC42MTA1Mjc0NCwyMzEuNTY2NjE0LDI4My4wMjA2NDkxLDQ1Ny42Nzg1NDI2LDEzNC4yOTMzMDU4LDYxLjM0MjY1MDYzLDM4LjI1NjkxOTEyLDE1NzguOTA5MDQ4LDQ0MS42MTk5ODI2LDc2MS40MTc3Nzc3LDI3NS42OTc4NTg4LDUyMS4wMzU1OTE2LDIxODkuNjI3ODMsMTE3LjI2Njc4ODUsMjQwLjM0MDMxNTMsNjcyLjQ1MTI5MzgsNzUzLjg5NTgwMTksODQuOTg4ODMwNzksMzY2NS40MTc5NzYsNjAuMzU5Nzc1MTUsNC4wMTkzMzMwOSwxNC45NTk1MTM2NiwxOTYuNzE0NjQwMywxNTMuNzEzMzE2NSw5OC4zMTg3NTA1MywxMDQuNDQ4NjMyNCwzNTguOTIwNTg3OCwyLjI1NDk4NjMzMSwyMDU5LjYwMzk1OSwzNy42Mzg5ODYwOCw1Ni40ODk0NDAzNSwxMTQzLjA4Mjk0OCw0MTAuNzU4NTUxNiwxMi42NTQwMjk4NiwxOS44MzMyMjUxNCwxMzA1LjEzNDc5NywyMDE5LjM2MDczNSwxMjg2Ljk4NDc5LDg4OTIuMTgyMTMxLDUuODE0NTE4NzQ5LDI5Ni4xNTUxMjk1LDg2Ljc1MzA4MTYxLDQ4Ni43ODUxNDA1LDcuNDkxMzg5Nzk4LDE4MC4zMjU1MjgxLDE0MTQuMjk3NzQ4LDUyNC40NjI4MjA4LDEwNDIuNjkwMzM0LDEyOTEuNDgxNDc0LDExNS40OTUwOTk4LDM2MC42MzEwNzM3LDMyMzMuNzE2ODM4LDE0OS41MTkxMDM5LDguODQ1ODM3NDczLDgzLjg3Mjk2MzI0LDQyLjk5NjE0NTE3LDYyMy45NzA0ODUzLDQ1Ljc0OTkwMDc0LDE0NC4yNDQ5NzkzLDM2OC41NzU2NDIsODY2LjkyNzI1NDUsNTcuNjE1OTI5MjEsMTgxMi4yMzEzMTUsMjIyOS45OTg3NTQsMzQ0OC4zMzI4ODgsMTEzMTMuMzQ3MjEsMTQ5Mi40OTg4NTYsMTk2LjcyNjI1NzEsNzEuMTE4MTc2MDEsNDI1LjA2MTQ0ODMsMzguMjg2NTMwNDgsNDQuNTA5MDAxNiwzMDguODc4MTY1NywxOTA4MC41MTc0OSw4Mi4wNzYxMzkzLDI1MC4wODM1MjMsNzkuMDc0OTIwNDIsMTgzLjg2OTc2ODYsMzMuODMxNjAzOTEsMjIuNzgyMTgyOTksNjk4Ljk1NDE2NDgsMzIuNzU0MjcwMDMsNDU3LjAxMDQ5MTksMTEyLjE3MTU1NjcsMzk2LjcxNTUyMzQsMTk1LjAyNDA3ODEsMTg2My4xODUzODUsMTgxLjY0NDExMjEsNTkuMDg3MzM2NTUsOTYuMzkwMDQxOTEsODI0LjczMDE4NCwxNTUuODIxNTE2MiwxMS44NTUxMDY2MSw4NzAuODY3OTUwMiw0MjUuMzEzMzA0NSw4NTQuNzI5NjQ3NCwyNTQuMzEwODg5Miw2NjQuMzMyMDEwNyw1Ni4yNjEyMDc1MiwzNzguMjQ0MDE2LDIwNjkuNDMxNDk1LDMxMjEuMDkwMSw4NDQuNDMzNzU5NCw3NDYuMzg1MzY3NSwxODUxLjQ2OTYzMyw0MzEuNzA2MDIzMiwzMzMuMzI1NDgxLDIyLjIzOTcwMTAyLDY2Mi4zODE2ODg4LDExNy43NTkwMDU3LDU3MC40NDEyODI5LDExMjcuMDM1MzA2LDI0Ni4yNjg2MTgzLDE0NjcuNTY4ODY3LDM0Ljg5MTg3MTEyLDIzNy41NzYxNjkzLDM0OS40NTAzOTY3LDIyOS4zMzYyODQ5LDkzNC42OTI2NTYxLDE2Mi45MjU0NDA4LDU4LjI4NDk3MTcyLDEyODAzLjA0NzI2LDE1Ljk0OTA0MTg5LDk1OS45NTQzNDAyLDU4NTMuODc4OTc5LDUzNy4zOTc0MjUzLDc1LjMwNTcyODgzLDcxOC42NTk3NTIxLDYzMy44MjE0NDM4LDM2My4wMzM4MDc2LDk1Ljg0NzYyNjYsODAuMzE3ODY1MywyODYuNzEyMTc2Myw2MzY3LjQ1MzQwOCwzMjEuNTY3NzExLDIxLjUxODM4MDIyLDU5OS40NzEyOTU4LDI0Ni43MDA3MDczLDEzODYzLjc4MTgxLDIxNC43MzQyNTk3LDIzNC4zMjEyOTUyLDk1OC45MTYxNzksMTY1LjI1MjEzODUpXG5kYXQgPC0gZGF0YS5mcmFtZShjbGFpbXMgPSBkYXQpIiwic2FtcGxlIjoiIyBOb3RlIHRoYXQgdGhlIG9iamVjdCBcImRhdFwiIGlzIGRhdGEgZnJhbWUuIFRvIGFjY2VzcyB0aGUgY2xhaW1zIGRhdGEgd2UgdXNlIGRhdCRjbGFpbXMuICMgRmlsbCB5b3VyIGNvZGUgYmVsb3cuIFxuY2xhc3MoZGF0KSIsInNvbHV0aW9uIjoiZ2dwbG90KGRhdCkgKyBcbiAgZ2VvbV9oaXN0b2dyYW0oYWVzKHggPSBjbGFpbXMsIHkgPSAuLmRlbnNpdHkuLiksIGJpbnMgPSA5MCAsIGZpbGwgPSBcImdyZXlcIiwgY29sb3IgPSBcImJsYWNrXCIpICsgXG4gIHN0YXRfZnVuY3Rpb24oZnVuPWRleHAsIGdlb20gPVwibGluZVwiLCBhcmdzID0gKHJhdGUgPSAxL21lYW4oZGF0JGNsYWltcykpLCBhZXMoY29sb3VyID0gXCJFeHBcIikpICtcbiAgc2NhbGVfY29sb3JfZGlzY3JldGUobmFtZT1cIkZpdHRlZCBEaXN0cmlidXRpb25zXCIpIn0=

The following code can be used to obtain the expected number of claims for the fitted exponential distribution and perform goodness-of-fit test.

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

\hypertarget{deductibles-and-reinsurance}{%
\chapter{Deductibles and reinsurance}\label{deductibles-and-reinsurance}}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

In this chapter, we will introduce the concept of risk-sharing. We will
consider two types of risk-sharing including deductibles and
reinsurance. The purpose of risk sharing is to spread the risk among the
parties involved. For example,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A policyholder purchases automobile insurance with a deductible. The
  policyholder is responsible for some of the risk , and transfer the
  larger portion of the risk to the insurer. The policyholder will
  submit a claim when the loss exceeds the deductible.
\item
  A direct insurer can pass on some of the risks to another insurance
  company known as a reinsurer by purchasing insurance from the
  reinsurer. It will protect the insurer from paying large claims.
\end{enumerate}

The main goals of the chapter include the derivation of the distribution
and corresponding moments of the claim amounts paid by the policyholder,
direct insurer and the reinsurer in the presence of risk-sharing
arrangements. In addition, the effects of risk-sharing arrangements will
reduce the mean and variability of the amount paid by the direct
insurer, and also the probability that the insurer will be involved on
very large claims.

\hypertarget{deductibles}{%
\section{Deductibles}\label{deductibles}}

The insurer can modify the policy so that the policyholder is
responsible for some of the risk by including a deductible (also known
as policy excess).

Given a financial loss of \(X\) and a deductible of \(d\),

\begin{itemize}
\item
  the insured agrees to bear the first amount of \(d\) of any loss \(X\),
  and only submits a claim when \(X\) exceeds \(d\).
\item
  the insurer will pay the remaining of \(X - d\) if the loss \(X\)
  exceeds \(d\).
\end{itemize}

For example, suppose a policy has a deductible of 1000, and you incur a loss
of 3000 in a car accident. You pay the deductible of 1000 and the car insurance
company pays the remaining of 2000.

Let \(X\) be the claim amount, \(V\) and \(Y\) the amounts of the claim paid
by the policyholder, the (direct) insurer, respectively, i.e.
\[X = V + Y.\] So the amount paid by the policyholder and the insurer
are given by

\[\begin{aligned}
    V = 
    \begin{cases}
        X &\text{if }  X \le d\\   
        d &\text{if }  X > d,
    \end{cases} \\
    Y = 
    \begin{cases}
        0 &\text{if }  X \le d\\   
        X - d &\text{if }  X > d.
    \end{cases}\end{aligned}\] The amounts \(V\) and \(Y\) can also be
expressed as \[V = \min(X,d), \quad Y = \max(0,X-d).\]

The relationship between the policyholder and insurer is similar to that
between the insurer and reinsurer. Therefore, the detailed analysis of a
policy with a deductible is analogous to reinsurance, which will be
discussed in the following section.

\hypertarget{reinsurance}{%
\section{Reinsurance}\label{reinsurance}}

Reinsurance is insurance purchased by an insurance company in order to
protect itself from large claims. There are two main types of
reinsurance arrangement:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  excess of loss reinsurance; and
\item
  proportional reinsurance.
\end{enumerate}

\hypertarget{excess-of-loss-reinsurance}{%
\section{Excess of loss reinsurance}\label{excess-of-loss-reinsurance}}

Under excess of loss reinsurance arrangement, the direct insurer sets a
certain limit called a retention level \(M >0\). For a claim \(X\),

\begin{itemize}
\item
  the insurance company pays any claim in full if \(X \le M\); and
\item
  the reinsurer (or reinsurance company) pays the remaining amount of
  \(X - M\) if \(X > M\).
\end{itemize}

The position of the reinsurer under excess of loss reinsurance is the
same as that of the insurer for a policy with a deductible.

Let \(X\) be the claim amount, \(V, Y\) and \(Z\) the amounts of the claim
paid by the policyholder, (direct) insurer and reinsurer, respectively,
i.e.~\[X = V + Y + Z.\] In what follows, without stated otherwise, we
consider the case in which there is no deductible in place, i.e.~\(V = 0\)
and \[X = Y + Z.\] So the amount paid by the direct insurer and the
reinsurer are given by

\[\begin{aligned}
    Y = 
    \begin{cases}
        X &\text{if }  X \le M\\   
        M &\text{if }  X > M,
    \end{cases} \\
    Z = 
    \begin{cases}
        0 &\text{if }  X \le M\\   
        X - M &\text{if }  X > M.
    \end{cases}\end{aligned}\] The amounts \(Y\) and \(Z\) can also be
expressed as \[Y = \min(X,M), \quad Z = \max(0,X-M).\]

\begin{example}
\protect\hypertarget{exm:examplePayouts}{}\label{exm:examplePayouts}

Suppose a policy has a deductible of 1000 and the
insurer arrange excess of loss reinsurance with retention level of 10000. A
sample of loss amounts in one year consists of the following values, in
unit of Thai baht: \[3000, 800, 25000, 5000, 20000 .\] Calculate the
total amount paid by:*

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{the policyholder;}
\item
  \emph{the insurer; and}
\item
  \emph{the reinsurer.}
\end{enumerate}

\end{example}

\textbf{Solution:}

The total amounts paid by

\begin{itemize}
\item
  the policyholders : \[1000 + 800 + 1000 + 1000 + 1000 = 4800.\]
\item
  The insurer : \[2000 + 0 + 10000 + 4000 + 10000 = 26000.\]
\item
  The reinsurer : \[0 + 0 + 14000 + 0 + 9000 = 23000.\]
\end{itemize}

\hypertarget{mixed-distributions}{%
\section{Mixed distributions}\label{mixed-distributions}}

In the subsequent sections, we will derive the probability distribution
of the random variables \(Y\) and \(Z\), which are the insurer's and
reinsurer's payouts on claims. Their distributions are neither purely
continuous, nor purely discrete. First we start with some important
properties of such random variables.

A random variable \(U\) which is partly discrete and partly continuous is
said to be a mixed distribution. The distribution function of \(U\),
denoted by \(F_U(x)\) is continuous and differentiable except for some
values of \(x\) in a countable set \(S\). For a mixed distribution \(U\),
there exists a function \(f_U(x)\) such that
\[F_U(x) = \Pr(U \le x) = \int_{-\infty}^x f_U(x) dx + \sum_{x_i \in S, x_i \le x } \Pr(U = x_i).\]
The expected value of \(g(U)\) for some function \(g\) is given by

\begin{equation} 
\label{eq:eqnExpectationMixed} \mathrm{E}[g(U)] = \int_{-\infty}^\infty g(x) f_U(x) \mathop{}\!d{x} + \sum_{x_i \in S } g(x_i) \Pr(U = x_i).
\end{equation}

It is the sum of the integral over the intervals at which \(f_U(x)\) is
continuous and the summation over the points in \(S\).

The function \(f_U(x)\) is not the probability density function of \(U\)
because \(\int_{-\infty}^\infty f_U(x) dx \neq 1\). In particular, it is
the derivative of \(F_U(x)\) at the points where \(F_U(x)\) is continuous
and differentiable.

Recall that \(X\) denotes the claim amount and \(Y\) and \(Z\) be the amounts
of the claim paid by the insurer and reinsurer. The distribution
function and the density function of the claim amount \(X\) are denoted by
\(F_{X}\) and \(f_X(x)\), where we assume that \(X\) is continuous. In the
following examples, we will derive the distribution, mean and variance
of the random variables \(Y\) and \(Z\). Furthermore, both random variables
\(Y\) and \(Z\) are examples of mixed distributions.

\begin{example}
\protect\hypertarget{exm:unlabeled-div-30}{}\label{exm:unlabeled-div-30}

\emph{Let \(F_Y\) denote the distribution function of
\(Y = \min(X,M)\). It follows that \[F_Y(x) = 
    \begin{cases}
        F_X(x) &\text{if }  x < M\\   
        1 &\text{if }  x \ge M
    \end{cases}.\] Hence, the distribution function of \(Y\) is said to be
a mixed distribution.}

\end{example}

\textbf{Solution:}
From \(Y = \min(X,M)\), if \(y < M\), then
\[F_Y(y) = \Pr(Y \le y) = \Pr(X \le y) = F_X(y).\] If \(y \ge M\), then
\[F_Y(y) = \Pr(Y \le y) = 1,\] which follows because \(\min(X,M) \le M\).

Hence, \(Y\) is mixed with a density function \(f_X(x)\), for \(0 \le x < M\)
and a mass of probability at \(M\), with \(Pr(Y = M) = 1 - F_X(M)\). The
last equality follows from \[\begin{aligned}
    \Pr(Y = M) &= \Pr(X > M) \\
        &=   1 - \Pr(X \le M) = 1 - F_X(M). \end{aligned}\]

\begin{example}
\protect\hypertarget{exm:unlabeled-div-31}{}\label{exm:unlabeled-div-31}

\emph{Show that
\[\mathrm{E}[Y] = \mathrm{E}[\min(X,M)] = \mathrm{E}[X] - \int_0^\infty y f_X(y+M) \mathop{}\!dy.\]}

\end{example}

\(\mathrm{E}[Y]\) is the expected payout by the insurer.

\[\begin{aligned}
    \mathrm{E}[Y] &= \mathrm{E}[\min(X,M)] \\
        &= \int_0^\infty \min(X,M) \cdot f_X(x) \, dx \\
        &= \int_0^M x \cdot f_X(x) \, dx + \int_M^\infty M \cdot f_X(x) \, dx \\
        &= \int_0^M x \cdot f_X(x) \, dx + \int_M^\infty x \cdot f_X(x) \, dx + \int_M^\infty (M - x) \cdot f_X(x) \, dx \\
        &= \mathrm{E}[X] + \int_M^\infty (M - x) \cdot f_X(x) \, dx \\
    &= \mathrm{E}[X] + \int_0^\infty (-y) \cdot f_X(y+M) \, dy \\
    &=  \mathrm{E}[X] - \int_0^\infty y \cdot f_X(y+M) \, dy 
\end{aligned}\]

\textbf{Note}
Under excess of loss reinsurance arrangement, the mean amount paid by
the insurer is reduced by the amount equal to
\(\int_0^\infty y f_X(y+M) \mathop{}\!dy.\)

\begin{example}
\protect\hypertarget{exm:unlabeled-div-32}{}\label{exm:unlabeled-div-32}

\emph{Let \(X\) be an exponential distribution with parameter
\(\lambda\) and \(Y = \min(X,M)\). Then \[F_Y(x) = 
    \begin{cases}
        1 - e^{-\lambda x} &\text{if }  x < M\\   
        1 &\text{if }  x \ge M
    \end{cases}.\] A plot of the distribution function \(F_Y\) is given in
Figure~\protect\hyperlink{figMixedDist}{1}. Hence, \(Y\) is a mixed distribution with a
density function \(f_Y(x) = f_X(x)\) for \(0 < x < M\) and a probability
mass at \(M\) is \(\Pr(Y = M) = 1 - F_X(M)\).}

Using
\eqref{eq:eqnExpectationMixed}, the expected value of \(Y\),
\(\mathrm{E}[Y]\) is given by

\[\begin{aligned}
    \mathrm{E}[Y] &= \int_{0}^M x f_X(x) \mathop{}\!d{x}  + M(1 - F_X(M)).  \end{aligned}\]

\end{example}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-33}{}\label{exm:unlabeled-div-33}

\emph{Let \(F_Z\) denote the distribution function of
\(Z = \max(0,X-M)\). It follows that \[F_Z(x) = 
    \begin{cases}
        F_{X}(M) &\text{if }  x = 0\\   
        F_{X}(x + M) &\text{if }  x > 0
    \end{cases}.\] Hence, the distribution function of \(Z\) is a mixed
distribution with a mass of probability at \(0\).}

\end{example}

\textbf{Solution:}
The random variable \(Z\) is the \textbf{reinsurer's payout} which also include
\textbf{zero claims}. Later we will consider only \textbf{reinsurance claims},
which involve the reinsurer, i.e.~claims such that \(X > M\).

The distribution of \(Z\) can be derived as follows:

\begin{itemize}
\item
  For \(x =0\), \[F_Z(0) = \Pr(Z = 0) = \Pr(X \le M) = F_X(M).\]
\item
  For \(x > 0\), \[\begin{aligned}
      F_Z(x) &= \Pr(Z \le x) = \Pr(\max(0,X-M) \le x) \\
      &= \Pr(X- M \le x) = \Pr(X \le x + M) = F_X(x + M).\end{aligned}\]
\end{itemize}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-34}{}\label{exm:unlabeled-div-34}

\emph{Let \(X\) be an exponential distribution with parameter
\(\lambda\) and \(Z = \max(0,X-M)\). Derive and plot the probability
distribution \(F_Z\) for \(\lambda = 1\) and \(M = 2\).}

\end{example}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-35}{}\label{exm:unlabeled-div-35}

\emph{Show that
\[\mathrm{E}[Z] = \mathrm{E}[\max(0,X-M)] = \int_M^\infty (x- M) f_X(x) \mathop{}\!dx = \int_0^\infty y f_X(y+M) \mathop{}\!dy.\]
Comment on the result.}

\end{example}

\textbf{Solution:}
The expected payout on the claim by the reinsurer, \(\mathrm{E}[Z]\), and
can also be found directly as follows: \[\begin{aligned}
\mathrm{E}[Z] &= \mathrm{E}[\max(0,X-M)] \\
    &= \int_0^M 0 \cdot f_X(x) \, dx + \int_M^\infty (X-M) \cdot f_X(x) \, dx \\
    &= 0 +  \int_0^\infty y \cdot f_X(y + M) \, dy.\end{aligned}\] It
follows from the previous results that
\[\mathrm{E}[X] = \mathrm{E}[Y + Z] =  \mathrm{E}[Y]+ \mathrm{E}[Z].\]

\begin{example}
\protect\hypertarget{exm:unlabeled-div-36}{}\label{exm:unlabeled-div-36}

\emph{Let the claim amount \(X\) have exponential distribution
with mean \(\mu = 1/\lambda\).}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Find the proportion of claims which involve the reinsurer.}
\item
  \emph{Find the insurer's expected payout on a claim.}
\item
  \emph{Find the reinsurer's expected payout on a claim.}
\end{enumerate}

\end{example}

\textbf{Solution:}
1. The proportion of claims which involve the reinsurer is
\[\Pr(X > M) = 1 - F_X(M) = e^{-\lambda M} = e^{-M/\mu}.\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  The insurer's expected payout on a claim can be calculated by
  \[\begin{aligned}
      \mathrm{E}[Y] &= \mathrm{E}[X] -  \int_0^\infty y \cdot \lambda e^{-\lambda(y+M)} \, dy \\
          &= \mathrm{E}[X] - e^{-\lambda M} \int_0^\infty y \cdot \lambda e^{-\lambda \cdot y} \, dy \\
          &= \mathrm{E}[X] - e^{-\lambda M}  \mathrm{E}[X] \\
          &= (1 - e^{-\lambda M})  \mathrm{E}[X].\end{aligned}\]
\item
  It follows from the above result that the reinsurer's expected
  payout on a claim is \(e^{-\lambda M} \mathrm{E}[X].\)
\end{enumerate}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-37}{}\label{exm:unlabeled-div-37}

\emph{An insurer covers an individual loss \(X\) with excess of
loss reinsurance with retention level \(M\). Let \(f_X(x)\) and \(F_X(x)\)
denote the pdf and cdf of \(X\), respectively.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Show that the variance of the amount paid by the insurer on a
  single claim satisfies:
  \[\mathrm{Var}[\min(X,M)] = \int_0^M x^2 f_X(x) \mathop{}\!dx + M^2 (1 - F_X(M)) - (\mathrm{E}[\min(X,M)])^2.\]}
\item
  \emph{Show that the variance of the amount paid by the reinsurer on a
  single claim satisfies:
  \[\mathrm{Var}[\max(0,X-M)] = \int_M^\infty (x-M)^2 f_X(x) \mathop{}\!dx  - (\mathrm{E}[\max(0,X-M)])^2.\]}
\end{enumerate}

\end{example}

\hypertarget{the-distribution-of-reinsurance-claims}{%
\section{The distribution of reinsurance claims}\label{the-distribution-of-reinsurance-claims}}

In practice, the reinsurer involves only claims which exceed the
retention limit, i.e.~\(X > M\). Information of claims which are less or
equal to \(M\) may not be available to the reinsurer. The claim amount \(Z\)
paid by the reinsurer can be modified accordingly to take into account
of non-zero claim sizes.

Recall from
Example \ref{exm:examplePayouts}, there are only three claims whose amounts
exceed the retention level of . Such claims, consisting of , 9000 and
23000 which involves the reinsurer are known as \textbf{reinsurance claims}.

Let \(W = Z|Z>0\) be a random variable representing the amount of a
non-zero payment by the reinsurer on a reinsurance claim. The
distribution and density of \(W\) can be calculated as follows: for
\(x > 0\), \[\begin{aligned}
     \Pr[W \le x ] &= \Pr[Z \le x | Z >0] \\
            &= \Pr[X - M \le x | X > M] \\
            &= \frac{\Pr[M < X \le x + M]}{\Pr[X > M]}\\
            &= \frac{F_X(x+M) - F_X(M)}{1-F_X(M)}.\end{aligned}\]
Differentiating with respect to \(x\), we obtain the density function of
\(W\) as \[f_W(x) = \frac{f_X(x+M)}{1 - F_X(M)}.\] Hence, the mean and
variance can be directly obtained from the density function of \(W\).

\hypertarget{proportional-reinsurance}{%
\section{Proportional reinsurance}\label{proportional-reinsurance}}

Under excess of loss reinsurance arrangement, the direct insurer pays a
fixed proportion \(\alpha\), called the proportion of the risk retained by
the insurer, and the reinsurer pays the remainder of the claim.

Let \(X\) be the claim amount, \(Y\) and \(Z\) the amounts of the claim paid
by the policyholder, (direct) insurer and reinsurer, respectively, i.e.
\[X = Y + Z.\] So the amount paid by the direct insurer and the
reinsurer are given by \[Y = \alpha X, \quad Z = (1 - \alpha) X.\] Both
of the random variables are scaled by the factor of \(\alpha\) and
\(1- \alpha\), respectively.

\begin{example}
\protect\hypertarget{exm:unlabeled-div-38}{}\label{exm:unlabeled-div-38}

\emph{Derive the distribution function and density function
of \(Y\).}

\end{example}

\textbf{Solution:}
Let \(X\) has a distribution function \(F\) with density function \(f\). The
distribution function of \(Y\) is given by \[\Pr(Y \le x) = F(x/a).\]
Hence, the density function is \[f_Y(x) = \frac{1}{a}f(x/a).\]

You can get more examples from Tutorials.

\hypertarget{collective-risk-model}{%
\chapter{Collective Risk Model}\label{collective-risk-model}}

Mathematical models of the total amount of claims from a portfolio of
policies over a short period of time will be presented in this chapter.
The models are referred to as short term risk models. Two main sources
of uncertainty including the claim numbers and claim sizes will be taken
into consideration. We will begin with the model for aggregate (total)
claims or collective risk models.

We define the following random variables:

\begin{itemize}
\item
  \(S\) denotes total amount of claims from a portfolio of policies in a
  fixed time interval, for e.g.~one year,
\item
  \(N\) represents the number of claims, and
\item
  \(X_i\) denotes the amount of the \(i\)th claim.
\end{itemize}

Then the total claims \(S\) is given by \[S = X_1 + \ldots + X_N.\]

The following assumptions are made for deriving the collective risk
model:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\{X_i \}_{i=1}^\infty\) are independent and identically distributed
  with distribution function \(F_X\).
\item
  \(N\) is independent of \(\{X_i \}_{i=1}^\infty\).
\end{enumerate}

The distribution of the total claim \(S\) is said to be a compound
distribution. The properties of the compound distribution will be given
in the Section \protect\hyperlink{sectionCompoundDistribution}{2}.

\textbf{Note} The distribution of \(S\) can be derived by using convolution
technique. In general, the closed form expressions for the compound
distribution do not exist so we will mainly concern with the moments of
\(S\). For more details about convolution, see Gray and Pitts (2012).

\hypertarget{conditional-expectation-and-variance-formulas}{%
\section{Conditional expectation and variance formulas}\label{conditional-expectation-and-variance-formulas}}

Some useful properties of conditional expectation and conditional
variance are given. The conditional expectaion formula is

\[E[ E[X|Y ]] = E[X].\] The conditional variance of \(X\) given \(Y\) is
defined to be
\[\begin{split}
    Var[X|Y]   &= Var[Z] \text{ where } Z = X|Y  \\
            &= E[(Z - E[Z])^2] = E[Z^2] - (E[Z])^2 \\
            &= E[(X - E[X|Y])^2  | Y] \\
            &= E[X^2| Y] - (E[X|Y])^2. \\
\end{split}\]
The conditional variance formula is
\begin{equation} 
\label{eq:exampleVariance}
    Var[X] = E[ Var[X|Y ]] + Var[E[X|Y ]].
\end{equation}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-39}{}\label{exm:unlabeled-div-39}

Show that \[Var[X] = E[ Var[X|Y ]] + Var[E[X|Y ]].\]

\end{example}

\textbf{Solution:}

Consider the terms on the right-hand side of \eqref{eq:exampleVariance}. We have

\[\begin{aligned}
    E[Var[X|Y]] &= E\left[  E[X^2|Y] -  (E[X|Y])^2   \right] \\
        &=  E[X^2] - E\left[(E[X|Y])^2   \right],
    \end{aligned}\] and
\[\begin{aligned}
    Var[E[X|Y ]]  &= Var[Z] \text{ where } Z = E[X|Y ]  \\
                &= E[(E[X|Y ])^2] - (E[E[X|Y ]])^2 \\
                &= E[(E[X|Y ])^2] - (E[X])^2 \\
                \end{aligned}\] Adding
both terms gives the required result.

\begin{example}
\protect\hypertarget{exm:unlabeled-div-40}{}\label{exm:unlabeled-div-40}

In three coloured boxes - Red, Green and Blue, each box has two bags.
The bags of Red box contain 1 and 2 (in units of THB) respectively, those of Green box contain
1 and 5, and those of Blue contain 1 and 10 . A box is chosen at random in such
a way that
\(\Pr(\text{Red}) = \Pr(\text{Green}) = \Pr(\text{Blue}) = 1/3\). A fair
coin is tossed to determined which bag to be chosen from the chosen box.
Let \(X\) be the value of the contents of the chosen bag.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Find the distribution of \(X\).
\item
  Find \(E[X]\) and \(Var[X]\).
\item
  Use the conditional expectation and conditional variance formulas to
  verify your results.
\end{enumerate}

\end{example}

\textbf{Solution:}
1. The distribution of \(X\) can be obtained by using the law of total
probability: for example \[\begin{aligned}
        P(X= 1) &= P(X = 1 , R) + P(X = 1 , G) + P(X = 1 , B) \\ 
        &= P(X = 1 | R) \cdot P(R) + P(X = 1 | G) \cdot P(G) + P(X = 1 | B) \cdot P(B) \\
        &= \frac{1}{2} \cdot  \frac{1}{3} + \frac{1}{2} \cdot  \frac{1}{3} + \frac{1}{2} \cdot  \frac{1}{3} = \frac{1}{2}.
        \end{aligned}\]
Similarly, we have
\[P(X = 1 ) = \frac{1}{2}, \quad P(X = 2 ) =  P(X = 5 ) =  P(X = 10 ) =  \frac{1}{6}.\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  It follows that
  \[E[X] = \frac{10}{3}, \quad Var[X] = \frac{98}{9}.\]
\item
  We first calculate \[\begin{aligned}
      E[X|R] &= \frac{1}{2}\cdot(1 + 2) = \frac{3}{2} \\
      E[X|G] &= \frac{1}{2}\cdot(1 + 5) = 3 \\
      E[X|B] &= \frac{1}{2}\cdot(1 + 10) = \frac{11}{2}. \\  \end{aligned}\]
  We have \[\begin{aligned}
      E[X] &= E[X | R] \cdot P(R) + E[X | G] \cdot P(G)  + E[X | B] \cdot P(B)  \\
      &= \frac{1}{3}\cdot(\frac{3}{2}  + 3 + \frac{11}{2}) = \frac{10}{3}.  \end{aligned}\]
\end{enumerate}

\hypertarget{sectionCompoundDistribution}{%
\section{\texorpdfstring{The moments of a compound distribution \(S\)}{The moments of a compound distribution S}}\label{sectionCompoundDistribution}}

The moments and moment generating function of \(S\) can be easily derived
from the conditional expectation formula.

\hypertarget{the-mean-of-s}{%
\subsection{\texorpdfstring{The mean of \(S\)}{The mean of S}}\label{the-mean-of-s}}

Let \(m_k\) be the \(k\)th moment of \(X_1\), i.e.~\(E[X_1^k] = m_k\).
Conditional on \(N = n\), we have
\[E[S | N = n] = E[ \sum_{i=1}^n X_i] = \sum_{i=1}^n E[ X_i] = n E[ X_i] = n \cdot m_1.\]
Hence, \(E[S | N] = N m_1\) and
\[E[S] =   E[E[S | N]] = E[N m_1] = E[N] m_1 = E[N] \cdot E[X_1].\]
It is no surprise that the mean of the total claims is the product of
the means of the number of claims and the mean of claim sizes.

\hypertarget{the-variance-of-s}{%
\subsection{\texorpdfstring{The variance of \(S\)}{The variance of S}}\label{the-variance-of-s}}

Using the fact that \(\{X_i \}_{i=1}^\infty\) are independent, we have
\[Var[S | N = n] = Var[ \sum_{i=1}^n X_i] = \sum_{i=1}^n Var[ X_i] = n Var[ X_i]  =n (m_2 - m_1^2),\]
and \(Var[S | N] = N (m_2 - m_1^2).\) It follows that \[\begin{aligned}
    Var[S] &= E[ Var[S | N] ] + Var[ E[S | N] ] \\
           &= E[ N (m_2 - m_1^2) ] + Var[ N m_1 ] \\
           &= E[ N ]  (m_2 - m_1^2)  +  Var[ N ] m_1  ^2. \end{aligned}\]

\begin{example}
\protect\hypertarget{exm:unlabeled-div-41}{}\label{exm:unlabeled-div-41}

Show that \(M_S(t) = M_N(\log(M_X(t)))\).

\end{example}

\textbf{Solution:}

First, consider the following conditional expectation: \[\begin{aligned}
    E\left [e^{t S} | N = n \right] &= E\left[e^{t (X_1 + X_2 + \cdots X_n)}\right] \\
                 &= E\left[e^{t X_1}\right]  \cdot E\left[e^{t X_2}\right]  \cdots E\left[e^{t X_n}\right]  \text{, since } X_1, X_2 \ldots, X_n \text{ are independent} \\ 
                 &= (M_X(t))^n.\end{aligned}\] Hence
\(E \left [e^{t S} | N \right] = (M_X(t))^N.\)

From the definition of the moment generating function, \[\begin{aligned}
    M_S(t) &= E[e^{t S}] \\
        &= E \left[  E[e^{t S} | N] \right ] \\
        &= E \left[ (M_X(t))^N  \right ]\\
        &= E \left[  Exp( N \cdot \log (M_X(t) )    \right] \\
        &= M_N(\log(M_X(t)))   (\text{ since } M_X(t) = E[e^{tX}] ).\end{aligned}\]

\hypertarget{special-compound-distributions}{%
\section{Special compound distributions}\label{special-compound-distributions}}

\hypertarget{compound-poisson-distributions}{%
\subsection{Compound Poisson distributions}\label{compound-poisson-distributions}}

Let \(N\) be a Poisson distribution with the parameter \(\lambda\), i.e.
\(N \sim Poisson(\lambda)\) and \(\{X_i \}_{i=1}^\infty\) are independent and
identically distributed with distribution function \(F_X\). Then
\(S = X_1 + \ldots + X_N\) is said to have a compound Poisson distribution
and denote by \(\mathcal{CP}(\lambda,F_X)\).

\textbf{Note} The same terminology can be defined similarly for other
distributions, for e.g.~if \(N\) has a negative binomial distribution,
then \(S\) is said to have a compound negative binomial distribution.

\begin{example}
\protect\hypertarget{exm:unlabeled-div-42}{}\label{exm:unlabeled-div-42}

Let \(S \sim \mathcal{CP}(\lambda,F_X)\). Show that

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(E[S] = \lambda m_1\),
\item
  \(Var[S] = \lambda m_2\),
\item
  \(M_S(t) = Exp{(\lambda(M_X(t) - 1))}.\)
\item
  The third central moment \(E[(S- E[S])^3] = \lambda m_3\), and hence
  \[Sk[S] = \frac{\lambda m_3}{(\lambda m_2)^{3/2}},\]
\end{enumerate}

where \(m_k\) be the \(k\)th moment of \(X_1\)

\end{example}

\textbf{Solution:}
1. \(E[S] = E[N] \cdot E[X] = \lambda m_1\),

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \(Var[S] = E[ N ] (m_2 - m_1^2) + Var[ N ] m_1 ^2 =  \lambda(m_2 - m_1^2) + \lambda m_1^2 = \lambda m_2\),
\item
  From \[\begin{aligned}
          M_S(t) &=  M_N(\log(M_X(t))) \\
              &= Exp\left( \lambda  \left( e^{\log(M_X(t))} - 1   \right)  \right), \text{ since } M_N(t) = Exp(\lambda(e^t - 1))  \\
              &= Exp{(\lambda(M_X(t) - 1))}.
      \end{aligned}\]
\item
  The third central moment \(E[(S- E[S])^3] = \lambda m_3\), and hence
  \[Sk[S] = \frac{\lambda m_3}{(\lambda m_2)^{3/2}}.\] In particular,
  we have \[\begin{aligned}
      E[(N- E[N])^3] &= E\left [  N^3 - 3 N^2  \cdot E[N] + 3 N \cdot  (E[N])^2 - (E[N])^3       \right]  \\
          &= E[N^3] - 3 E[N^2]  \cdot E[N] + 2 (E[N])^3 \\
          &= M_N'''(0) - 3  M_N''(0) \cdot  M_N'(0) + 2 (M_N'(0))^3\end{aligned}\]

  For \(N \sim Poisson(\lambda)\), \(M_N(t) = Exp(\lambda(e^t - 1)).\) By
  differentiating \(M_N(t)\) and evaluating at \(t = 0\), we can show that
  \[M'(0) = \lambda, \quad  M''(0) = \lambda (1 + \lambda), \quad M'''(0) = \lambda (1 + 3\lambda + \lambda^2).\]
  Hence, \(E[(N- E[N])^3] = \lambda.\)

  Similarly,

  \[\begin{aligned}
      E[(S- E[S])^3] &=  E[S^3] - 3 E[S^2]  \cdot E[S] + 2 (E[S])^3 \\
    \end{aligned}\]
  In addition, \(M_S(t) = Exp{(\lambda(M_X(t) - 1))}.\) By
  differentiating \(M_S(t)\) we can show that \[\begin{aligned}
      M'''_S(t) &= \lambda M'''_X(t) M_S(t)   + 2 \lambda M''_X(t) M'_S(t)  + \lambda M'_X(t) M''_S(t).\\ \end{aligned}\]
  Evaluating \(M'''_S(t)\) at \(t = 0\) results in \[\begin{aligned}
      M'''_S(0) &= E[S^3] = \lambda m_3 + 3 E[S] \cdot E[S^2] - 2( E[S])^3,\end{aligned}\]
  which gives \[\begin{aligned}
      E[(S- E[S])^3] &=  E[S^3] - 3 E[S^2]  \cdot E[S] + 2 (E[S])^3 \\
          &= \lambda m_3.\end{aligned}\]
\end{enumerate}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-43}{}\label{exm:unlabeled-div-43}

Let \(S\) be the aggregate annual claims for a risk where
\(S \sim \mathcal{CP}(10,F_X)\) and the individual claim amounts have a
\(Pa(4,1)\) distribution. Calculate \(E[S], Var[S]\) and \(Sk[S]\).

\end{example}

\textbf{Solution:}
Since \(X \sim Pa(4,1)\) with \(\alpha = 4\) and \(\lambda = 1\), we
have \[\begin{aligned}
E[X^r] &= \frac{\Gamma(\alpha - r) \cdot \Gamma(1 + r) \cdot \lambda^r  }{\Gamma(\alpha)}\\
E[X] &= \frac{\lambda}{\alpha - 1} = \frac{1}{4-1} = \frac{1}{3}\\
E[X^2] &=  \frac{\Gamma(2) \cdot \Gamma(3) \cdot \lambda^2  }{\Gamma(4)} = \frac{1}{3}\\ 
E[X^3] &=  \frac{\Gamma(1) \cdot \Gamma(4) \cdot \lambda^3  }{\Gamma(4)} = 1.\\ \end{aligned}\]
We have \[\begin{aligned}
E[S]  &= \lambda E[X] = \frac{10}{3} \\
Var[S] &= \lambda E[X^2] = \frac{10}{3} \\
Sk[S] &= \frac{\lambda E[X^3]}{\left(\lambda E[X^2]\right)^{3/2}} = \frac{10}{(10/3)^{3/2}} = 1.6432.\\ \end{aligned}\]\\

In what follows, we will use R to simulate \(n\) observations from a compound Poisson distribution, where the Poisson parameter is \(\lambda\) and where the claims are exponentially distributed with mean \(\mu\), i.e.~
\(CP(\lambda, Exp(1/\mu))\)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulation n observations from a  CP(lambda,FX) distribution}
\CommentTok{\# Assumptions:}
\CommentTok{\# N \textasciitilde{} Poisson(lambad)}
\CommentTok{\# X \textasciitilde{} Pa(alpha,beta)}
\FunctionTok{library}\NormalTok{(actuar)}

\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{10000}
\NormalTok{lambda }\OtherTok{\textless{}{-}}  \DecValTok{10}
\NormalTok{alpha }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{beta }\OtherTok{\textless{}{-}} \DecValTok{1}

\NormalTok{totalClaims }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,n)}
\NormalTok{numclaims }\OtherTok{\textless{}{-}} \FunctionTok{rpois}\NormalTok{(n,lambda)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n)}
\NormalTok{  totalClaims[i] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{rpareto}\NormalTok{(numclaims[i], }\AttributeTok{shape =}\NormalTok{alpha, }\AttributeTok{scale =}\NormalTok{ beta))}
\FunctionTok{hist}\NormalTok{(totalClaims)}
\end{Highlighting}
\end{Shaded}

\includegraphics{SCMA470Bookdownproj_files/figure-latex/simulationCP-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(totalClaims)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.338976
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(totalClaims)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.29011
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(moments)}
\FunctionTok{skewness}\NormalTok{(totalClaims)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.345385
\end{verbatim}

\textbf{Note}
An important property of independent, but not necessarily identically
distributed, compound Poisson random variables is that the sum of a
fixed number of them is also a compound Poisson random variable.

\begin{example}
\protect\hypertarget{exm:Additivity}{}\label{exm:Additivity}

Let \(S_1, \ldots, S_n\)
be independent compound Poisson random variables, with parameters
\(\lambda_i\) and \(F_i\). Then \(S = \sum_{i=1}^n S_i\) has a compound
distribution with parameter \[\lambda =  \sum_{i=1}^n \lambda_i,\] and
\[F = \frac{1}{\lambda}\sum_{i=1}^n \lambda_i F_i.\]

\end{example}

\textbf{Solution:}
Exercise.

\textbf{Note} The compound Poisson distribution is the most often used in
practice. It possesses the additivity of independent compound Poisson
distributions (as shown in
Example \ref{exm:Additivity}, and the expressions of the first three moments
are very simple.

\hypertarget{compound-negative-binomial-distributions}{%
\subsection{Compound negative binomial distributions}\label{compound-negative-binomial-distributions}}

A useful discrete random variable that can be used for modelling the
distributions of claim numbers is a negative binomial distribution. A
random variable \(N\) has a negative distribution with parameters \(k\) and
\(p\), denoted by \(N \sim NB(k,p)\) if its probability mass function is given
by
\[f_N(n) = \Pr(N = n) = \frac{\Gamma(k+n)}{\Gamma(n+1)\Gamma(k)} p^k (1- p)^n \quad n = 0,1,2,\ldots.\]
It can be interpreted as the probability of getting \(n\) failures before
the \(k\)th success occurs in a sequence of independent Bernoulli trials
with probability of success \(p\).

\begin{example}
\protect\hypertarget{exm:unlabeled-div-44}{}\label{exm:unlabeled-div-44}

Let \(N \sim NB(k,p)\). Show that the mean, variance and moment generating
function of the compound negative binomial distribution, denoted by
\(\mathcal{CNB}(k,p,F_X)\), are as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(E[S] = \frac{k q}{p} m_1\),
\item
  \(Var[S] = \frac{k q}{p^2} (p m_2 + q m_1^2)\),
\item
  \(M_S(t) = \left( \frac{ p }{ 1 - q M_X(t) } \right)^k,\)
\end{enumerate}

where \(m_k\) be the \(k\)th moment of \(X_1\) and \(q = 1-p\).

\end{example}

\textbf{Solution:}
The results follows from the properties of the negative binomial
distribution \(N \sim NB(k,p)\):
\[E[N] = \frac{kq}{p}, \quad Var[N] = \frac{kq}{p^2},\] and the
moments of a compound distribution \(S\) derived in Section
\ref{sectionCompoundDistribution}.

\textbf{Notes}
1. The negative binomial distribution is an alternative to the Poisson distribution for \(N\), in the sense that it allows for any value of \(N = 0, 1, 2, \ldots\), unlike the binomial
distribution which has an upper limit.

One advantage that the negative binomial distribution has over the Poisson distribution is that its variance exceeds its mean. These two quantities are equal for the Poisson distribution.

Thus, the negative binomial distribution may give a better fit to a data set which has a sample variance in excess of the sample mean.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The compound negative binomial distribution is an appropriate to model the heterogeneity of the numbers of claims occurring for
  different risks. In particular, suppose that for each policy, the number
  of claims in a year has a Poisson distribution
  \(N | \lambda \sim Poisson(\lambda)\), and that the variation in \(\lambda\) across
  the portfolio can be modelled using a Gamma distribution \(\mathcal{G}(\alpha, \lambda)\). Then
  the number of claims in the year for a policy chosen at random from the
  portfolio has a negative binomial distribution.
\end{enumerate}

\hypertarget{misture-distributions}{%
\subsubsection{Misture distributions}\label{misture-distributions}}

Suppose we model a policyholder's claim number \(N\) using a conditional distribution \(N | \lambda\), where \(\lambda\) can be thought of as a ``risk parameter'' for that policyholder.

Policyholders represent a variety of risks and have different risk parameters, and we model the variation across policyholders by regarding the various \(\lambda\)s as being independent realisations of a random variable with known probability distribution. This gives the joint density, which we can write as
\(f_{N,\lambda}(k, \lambda) = f_\lambda(\lambda) f_{N|\lambda}(k | \lambda)\).

This enables us to allow for variability in the risks across a portfolio; that is, to model the heterogeneity of the numbers of claims occurring for different risks.

\begin{example}
\protect\hypertarget{exm:unlabeled-div-45}{}\label{exm:unlabeled-div-45}

A portfolio consists of a large number of individual policies. For each policy, the number of claims in a year has a poisson distribution \(N | \lambda \sim Poisson(\lambda)\). Let us suppose that the variation in \(\lambda\) across the portfolio of risks can be modelled using a gamma \(\mathcal{G}(\alpha,\beta)\) distribution with known parameters, and let us use this to average across the risks.

We are considering a \textbf{mixture} of Poissons where the mixing distribution if gamma. This is also known as a mixture \textbf{distribution}. Derive the probability mass function of the mixture distribution.

\end{example}

\textbf{Solution:}

For \(k = 0,1,2,\ldots\), we have

\[
\begin{aligned}
\Pr(N = k) &= \int f_\lambda(\lambda) \Pr(N = k | \lambda) \, d\lambda \\
&= \int_{0}^\infty \frac{\beta^\alpha}{\Gamma(\alpha)} \lambda^{\alpha -1} e^{\beta \lambda} e^{-\lambda} \frac{\lambda^k}{k!} \, d\lambda \\
&= \frac{\Gamma(\alpha + k)}{\Gamma(\alpha) \Gamma(1 + k)} \frac{\beta^\alpha}{(\beta+1)^{\alpha+k}} \times \int_0^\infty h(\lambda) \, d\lambda 
\end{aligned}
\]
where \(h(\lambda)\) is the probability density function of \(\lambda \sim \mathcal{G}(\alpha + k, \beta + 1)\).

Hence,

\[ \Pr(N =k) = \frac{\Gamma(\alpha + k)}{\Gamma(\alpha) \Gamma(1 + k)} \left(\frac{\beta}{\beta+1}\right)^\alpha \left(\frac{1}{\beta+1}\right)^k, k = 0,1,2,\ldots,\]

which is the probability mass function of a \(\mathcal{NB}(\alpha, \beta/(\beta + 1))\) distribution.

This provides an illuminating view of the negative binomial distribution -- it arises as a mixture of Poissons where the mixing distribution is gamma.

\hypertarget{an-example-in-r}{%
\subsubsection{an Example in R}\label{an-example-in-r}}

This R Markdown introduces the concept of mixture distributions which applies to models for claim numbers.

Suppose we model a policyholder's claim numbers \(N\) using a conditional distribution \(N | \lambda\), where \(\lambda\) can be thought of as a \textbf{risk parameter} for that policyholder. Policyholders represent a variety of risks and have different risk parameters, and we model the variation across policyholders by regarding the various \(\lambda\)s as being independent realisations of a random variable with known probability distribution.

The following R code produces the required \(n\) simulated values from this mixture distribution, where \(N | \lambda \sim Poisson(\lambda)\) with mixing distribution \(\mathcal{G}(\alpha, \beta)\), i.e.~\(\lambda \sim \mathcal{G}(\alpha, \beta)\).

eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJzZXQuc2VlZCg1MzUzKVxubiA8LSA1MDAwXG5hbHBoYSA8LSA0XG5iZXRhIDwtIDEvM1xubGFtYmRhIDwtIHJnYW1tYShuLCBzaGFwZSA9IGFscGhhLCByYXRlID0gYmV0YSlcbm51bWNsYWltcyA8LSBzYXBwbHkobGFtYmRhLHJwb2lzLG4gPTEpXG5oaXN0KG51bWNsYWltcylcbnByaW50KG1lYW4obnVtY2xhaW1zKSlcbnByaW50KHZhcihudW1jbGFpbXMpKVxuXG4jTWl4dHVyZSB+IG5iKGFscGhhLGJldGEvKGJldGErMSkpXG5hbHBoYU1peHR1cmUgPC0gYWxwaGFcbmJldGFNaXh0dXJlIDwtIGJldGEvKGJldGErMSlcbm1lYW5NaXh0dXJlIDwtIGFscGhhTWl4dHVyZSooMS1iZXRhTWl4dHVyZSkvYmV0YU1peHR1cmVcbnZhck1peHR1cmUgPC0gbWVhbk1peHR1cmUvYmV0YU1peHR1cmUifQ==

\hypertarget{compound-binomial-distributions}{%
\subsection{Compound binomial distributions}\label{compound-binomial-distributions}}

A compound binomial distribution can be used to model a portfolio of
policies, each of which can give rise to at most one claim.

\begin{example}
\protect\hypertarget{exm:unlabeled-div-46}{}\label{exm:unlabeled-div-46}

Consider a portfolio of \(n\) independent and identical policies where
there is at most one claim on each policy in a year (for e.g.~life
insurance). Let \(p\) be the probability that a claim occurs. Explain that
the aggregate sum \(S\) in this portfolio has a compound binomial
distribution, denoted by \(\mathcal{CB}(n,p,F_X)\). Derive the mean,
variance and moment generating function of \(S\).

\end{example}

\textbf{Solution:}
Since \(n\) policies (lives) are independent with the probability \(p\) that
a claim occurs, the number \(N\) of claims on the portfolio in one year
has a binomial distribution i.e.~\(N \sim \text{bi}(n,p)\). If the sizes
of the claims are i.i.d. random variables, independent of \(N\), then the
total amount \(S\) claimed on this policy in one year has a compound
binomial distribution.

The mean, variance and the moment generating function of \(S\) are as
follows: \[\begin{aligned}
E[S] &= n p m_1, \\
Var[S] &= np m_2 - n p^2 m_1^2, \\
M_S(t) &= \left( q + p  M_X(t)      \right)^n,\end{aligned}\] where
\(m_k\) be the \(k\)th moment of \(X_1\) and \(q = 1-p\).

\hypertarget{the-effect-of-reinsurance}{%
\section{The effect of reinsurance}\label{the-effect-of-reinsurance}}

The effect of reinsurance arrangements on an aggregate claims
distribution will be presented. Let \(S\) denotes the total aggregate
claims from a risk in a given time, \(S_I\) and \(S_R\) denote the insurance
and reinsurance aggregate claims, respectively. It follows that
\[S = S_I + S_R.\]

\hypertarget{proportional-reinsurance-1}{%
\subsection{Proportional reinsurance}\label{proportional-reinsurance-1}}

Recall that under proportional reinsurance arrangement, a fixed
proportion \(\alpha\) is paid by the direct insurer and the remainder of
the claim is paid by the reinsurer. It follows that
\[S_I =  \sum_{i= 1}^N  \alpha X_i = \alpha S\] and
\[S_R =  \sum_{i= 1}^N (1- \alpha) X_i = (1- \alpha) S,\] where \(X_i\) is
the amount of the \(i\)th claim.

\textbf{Notes}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Both direct insurer and the reinsurer are involved in paying each
  claim.
\item
  Both have unlimited liability unless a cap on the claim amount is
  arranged.
\end{enumerate}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-47}{}\label{exm:unlabeled-div-47}

Aggregate claims from a risk in a given time have a compound Poisson
distribution with Poisson parameter \(\lambda = 10\) and an individual
claim amount distribution that is a Pareto distribution,
\(Pa(4,1)\). The insurer has effected proportional reinsurance with
proportion retained \(\alpha = 0.8\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Find the distribution of \(S_I\) and \(S_R\) and their means and
  variances.
\item
  Compare the variances \(Var[S_I] +Var[S_R]\) and \(Var[S]\). Comment
  on the results obtained.
\end{enumerate}

\end{example}

\textbf{Solution:}
1. We have \[\begin{aligned}
    S_I &= \sum_{i=1}^N \left( \alpha X_i \right) = \alpha \sum_{i=1}^N X_i = \alpha \cdot S, \\
    S_R &= \sum_{i=1}^N \left( (1- \alpha) X_i \right) = (1- \alpha) \sum_{i=1}^N X_i = (1- \alpha) \cdot S,\end{aligned}\]
since both insurer and reinsurer are involved in paying each claim,
i.e.~\(Y_i = \alpha X_i\) and \(Z_i = (1- \alpha) X_i\). It follows that
\(S_I \sim \mathcal{CP}(10,F_Y)\) and \(S_R \sim \mathcal{CP}(10,F_Z)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  As we can show that if \(X \sim Pa(\beta,\lambda)\), then
  \(W = k X \sim Pa(\beta,k \lambda)\). For
  \(X \sim Pa(4,1)\) with \(\beta = 4\) and \(\lambda = 1\), we have
  \(Y_i \sim Pa(\beta, \alpha \cdot \lambda) = Pa(4, 0.8)\)
  and \[\begin{aligned}
  E[S_I] &= 10 \cdot E[Y_i] = 10   \cdot \frac{\alpha \cdot \lambda}{\beta - 1} \\
  & = \frac{8}{3}, \\
  Var[S_I] &=10 \cdot E[Y_i^2]  =   10 \cdot \frac{\Gamma(\beta - 2) \cdot \Gamma(1 + 2) \cdot (\alpha \cdot \lambda)^2  }{\Gamma(\beta)} \\
   &= 10 \cdot   \frac{\Gamma(2) \cdot \Gamma(3) \cdot (\alpha \cdot \lambda)^2  }{\Gamma(4)} = 10 \cdot \frac{2!}{3!} \cdot  (0.8)^2 \\
   &= \frac{32}{15} \end{aligned}\]

  Alternatively, we can calculate by using the properties of the
  expectation and variance as follows: \[\begin{aligned}
  E[S_I] &= E[\alpha S] = \alpha\cdot E[S] = \alpha\cdot \lambda \cdot E[X]  = 10 \cdot 0.8 \cdot \frac{1}{3} = \frac{8}{3}, \\
  Var[S_I] &= Var[\alpha S]  =  \alpha^2 \cdot Var[S] \\
         &= \alpha^2 \cdot \lambda \cdot E[X^2] = \frac{32}{15} .\end{aligned}\]
\end{enumerate}

Similarly, \[\begin{aligned}
E[S_R] &= E[(1 - \alpha) S] = (1 - \alpha)\cdot E[S] = \frac{2}{3}, \\
Var[S_R] &= Var[(1 - \alpha) S]  =  (1 - \alpha)^2 \cdot Var[S] =  \frac{2}{15} .\end{aligned}\]
Note that \(E[S_I] + E[S_R] = E[S]\), while
\(Var[S_I] + Var[S_R] = \frac{34}{15} < Var[S] = \frac{10}{3}.\)

\hypertarget{excess-of-loss-reinsurance-1}{%
\subsection{Excess of loss reinsurance}\label{excess-of-loss-reinsurance-1}}

Recall that under excess of loss reinsurance arrangement, the direct
insurer has effected excess of loss reinsurance with retention level
\(M >0\). For a claim \(X\),

\begin{itemize}
\item
  the insurance company pays any claim in full if \(X \le M\); and
\item
  the reinsurer (or reinsurance company) pays the remaining amount of
  \(X - M\) if \(X > M\).
\end{itemize}

It follows that

\begin{equation} 
\label{eq:eqnSI} S_I =  \sum_{i= 1}^N  Y_1 + Y_2 + \ldots + Y_N =  \sum_{i= 1}^N  \min(X_i,M)
\end{equation}
and
\begin{equation} 
\label{eq:eqnSR} S_R = \sum_{i= 1}^N  Z_1 + Z_2 + \ldots + Z_N  = \sum_{i= 1}^N \max(0,X_i - M), 
\end{equation}
where \(X_i\) is the amount of the \(i\)th claim.
When \(N = 0\), we set \(S_I = 0\) and \(S_R = 0\).

\textbf{Note} \(S_R\) can equal 0 even if \(N > 0\). This occurs when all claims
do not exceed \(M\) and hence the insurer pays the full amounts of claims.

As discussed in the previous section, the reinsurer is involved only
claims which exceed the retention limit (a claim such that \(X > M\)).
Such claims are called \textbf{reinsurance claims}. Taking in account of
counting only non-zero claims, we can rewrite \(S_R\) as follows. Let
\(N_R\) be the number of insurance (non-zero) claims for the reinsurer and
\(W_i\) be the amount of the \(i\)th non-zero payment by the reinsurer. The
aggregate claim amount paid by the reinsurer can be written as
\[S_R   =  \sum_{i= 1}^{N_R} W_i.\]

\begin{example}
\protect\hypertarget{exm:unlabeled-div-48}{}\label{exm:unlabeled-div-48}

By using the probability generating function, show that if
\(N \sim Poisson(\lambda)\), then the distribution
\(N_R \sim Poisson(\lambda \pi_M)\) where \(\pi_M = \Pr(X_j > M)\).

\end{example}

\textbf{Solution:}
Define the indicator random variable \(\{I_j\}_{j=1}^\infty\), where
\[\begin{aligned}
        I_j = 
    \begin{cases}
        1 &\text{if }  X_j > M\\   
        0 &\text{if }  X_j \le M.
    \end{cases}\end{aligned}\] Therefore, \[N_R = \sum_{j= 1}^{N} I_j.\]
The variable \(N_R\) has a compound distribution with its probability
generating function \[P_{N_R}(r) = P_N[P_I(r)],\] where \(P_I\) is the
probability generating function of the indicator random variable. It can
be shown that \[P_I(r) = 1 - \pi_M + \pi_M r,\] where
\(\pi_M = \Pr(I_j = 1) = \Pr(X_j > M) = 1 - F(M)\).

\textbf{Note} In the above example, one can derive the distribution of \(N_R\)
by using the moment generating function:
\[M_{N_R}(t) = M_N(\log M_I(t)),\] where \(M_N\) and \(M_I\) are the moment
generating functions of \(N\) and \(I\). Note also that
\[M_I(t) = 1 - \pi_M + \pi_M Exp(t).\]

\hypertarget{compound-poisson-distributions-under-excess-of-loss-reinsurance}{%
\subsection{Compound Poisson distributions under excess of loss reinsurance}\label{compound-poisson-distributions-under-excess-of-loss-reinsurance}}

Assume that aggregate claim amount \(S \sim \mathcal{CP}(\lambda,F_X)\)
has a compound Poisson distribution. Under excess of loss reinsurance
with retention level \(M\), it follows
from \eqref{eq:eqnSI} and
\eqref{eq:eqnSR} that

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(S_I \sim \mathcal{CP}(\lambda,F_Y),\)

  where \(f_Y(x) = f_X(x)\) for \(0 < x < M\) and
  \(\Pr(Y = M) = 1 - F_X(M)\).
\item
  \(S_R \sim \mathcal{CP}(\lambda,F_Z),\)

  where \(F_Z(0) = F_X(M)\) and \(f_Z(x) = f_X(x+M), x > 0\).
\item
  Excluding zero claims,
  \(S_R \sim \mathcal{CP}(\lambda \,( 1 - F_X(M)) , F_W),\)

  where \(f_W(x) = \displaystyle{\frac{f_X(x+M)}{1- F_X(M)}}, x > 0\).
\end{enumerate}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-49}{}\label{exm:unlabeled-div-49}

Suppose that \(S\) has a compound Poisson distribution with Poisson
parameters \(\lambda = 10\) and the claim sizes have the following
distribution

\begin{longtable}[]{@{}lllll@{}}
\toprule
\(x\) & 1 & 2 & 5 & 10 \\
\midrule
\endhead
\(\Pr(X = x)\) & 0.4 & 0.3 & 0.2 & 0.1 \\
\bottomrule
\end{longtable}

The insurer enters into an excess of loss reinsurance contract with
retention level \(M = 4\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Show that \(S_I \sim\mathcal{CP}(\lambda,F_Y)\).
\item
  Show that \(S_R \sim\mathcal{CP}(\lambda,F_Z)\).
\item
  By excluding zero claims, show that the \(S_R\) can also be expressed
  as \(S_R \sim \mathcal{CP}(\lambda \, p,F_W)\) where \(p = \Pr(X > M)\).
\item
  Find the mean and variance of the aggregate claim amount for both
  insurer and reinsurer.
\end{enumerate}

\end{example}

\textbf{Solution:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Recall that \(S_I = \sum_{i=1}^N \min\{X_i,4\}.\) The number of claim remains the same, and hence \(N \sim Poisson(10)\). The distribution of claim amount paid by the insurer, \(F_Y(x)\) is given by
\end{enumerate}

\begin{longtable}[]{@{}llll@{}}
\toprule
\(x\) & 1 & 2 & 4 \\
\midrule
\endhead
\(\Pr(Y = x)\) & 0.4 & 0.3 & 0.3 \\
\bottomrule
\end{longtable}

Therefore, \(S_I \sim \mathcal{CP}(10,F_Y)\) and

\[\begin{aligned}
  \mathrm{E}[S_I] &= 10 E[Y] = 10(1(0.4) + 2(0.3) + 4(0.3)) = 22, \\
  \mathrm{Var}[S_I] &= 10 E[Y] = 10(1^2(0.4) + 2^2(0.3) + 4^2(0.3)) = 64. 
\end{aligned}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  We have \(S_R = \sum_{i=1}^N \max\{0, X_i - 4\}.\) When zero claims are included, \(N_R = N \sim Poisson(10)\). The distribution of claim amount paid by the reinsurer, \(F_Z(x)\) is given by
\end{enumerate}

\begin{longtable}[]{@{}llll@{}}
\toprule
\(x\) & 0 & 1 & 6 \\
\midrule
\endhead
\(\Pr(Z = x)\) & 0.7 & 0.2 & 0.1 \\
\bottomrule
\end{longtable}

Therefore, \(S_R \sim \mathcal{CP}(10,F_Z)\) and

\[\begin{aligned}
  \mathrm{E}[S_R] &= 10 E[Z] = 8, \\
  \mathrm{Var}[S_R] &= 10 E[Z^2] = 38. 
\end{aligned}\]

\textbf{Notes}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \(\mathrm{E}[S] = 10 \mathrm{E}[X] = 30\) and
  \(\mathrm{Var}[S]= 10 \mathrm{E}[X^2] = 166.\)
\item
  \(\mathrm{E}[S_I + S_R] = \mathrm{E}[S]\), and
  \[\mathrm{Var}[S_I + S_R] = 64 + 38 < 166 = \mathrm{Var}[S].\]
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Consider the reinsurer's position when zero claims are excluded. We define
  \[ W = Z | Z >0 = X - 4 | X > 4.\]
  We first compute \(\pi_M\), the proportion of claims which involve the reinsurer, from
  \[ \pi_M = \mathrm{Pr}(X>4) = \mathrm{Pr}(X = 5) + \mathrm{Pr}(X = 10) = 0.3.\]
  Recall that \(S_R = \sum_{i=1}^{N_R} W_i.\) We have \(S_R \sim \mathcal{CP}(0.3 \times 10, F_W)\) and the distribution of \(W, F_W(x)\) is given by
\end{enumerate}

\[
\begin{aligned}
\mathrm{Pr}(W = 1) &= \mathrm{Pr}(X = 5 | X > 4) = \frac{ \mathrm{Pr}(X = 5 , X > 4)  }{\mathrm{Pr}(X > 4)} = \frac{ \mathrm{Pr}(X = 5)  }{\mathrm{Pr}(X > 4)} = \frac{2}{3} \\
\mathrm{Pr}(W = 6) &= 1- \mathrm{Pr}(W = 1) = \frac{1}{3}.
\end{aligned}
\]
Hence,
\[
\begin{aligned}
  \mathrm{E}[S_R] &= (10 \times 0.3)(1(2/3) + 6(1/3)) = 8, \\
  \mathrm{Var}[S_R] &= (10 \times 0.3)(1^2(2/3) + 6^2(1/3)) = 38. 
\end{aligned}
\]

\begin{example}
\protect\hypertarget{exm:unlabeled-div-50}{}\label{exm:unlabeled-div-50}

Suppose that \(S\) has a compound Poisson distribution with Poisson
parameters \(\lambda = 40\) and the claim sizes have a Pareto distribution
\(Pa(3,4)\). The insurer has an excess of loss reinsurance contract
in place with retention level \(M = 2\). Find the mean and variance of the
aggregate claim amount for both insurer and reinsurer.

\end{example}

\textbf{Solution:}
1. \textbf{Zero claims included}. Recall that that for \(X \sim \mathcal{Pa}(\alpha,\lambda)\), its density function is
\[ f_X(x) = \frac{\alpha \lambda^\alpha}{ (x + \lambda)^{\alpha + 1}}.\]
We know that \(S_R \sim \mathcal{CP}(40,F_Z)\). Moreover,

\[
\begin{aligned}
\mathrm{E}[Z] &= 0 F_Z(0) + \int_0^\infty x f_Z(x)\, dx \\
&= \int_0^\infty x f_X(x + M)\, dx \\
&= \int_0^\infty \frac{x \cdot 3 \cdot 4^3}{(x + 2 + 4)^{3+1}} \, dx\\
&= \frac{4^3}{6^3} \int_0^\infty \frac{x \cdot 3 \cdot 6^3}{(x + 6)^{3+1}} \, dx \\
&= \frac{4^3}{6^3} \frac{6}{3-1} = 0.88\ldots .\\
\end{aligned}
\]
Note that the last integral above is the mean of \(\mathcal{Pa}(3,6)\), which is equal to \(6/(3-1)\).

For \(\mathrm{E}[Z^2]\), we proceed as follows:
\[
\begin{aligned}
\mathrm{E}[Z^2] &= 0^2 F_Z(0) + \int_0^\infty x^2 f_Z(x)\, dx \\
&= \int_0^\infty x^2 f_X(x + M)\, dx \\
&= \int_0^\infty \frac{x^2 \cdot 3 \cdot 4^3}{(x + 2 + 4)^{3+1}} \, dx\\
&= \frac{4^3}{6^3} \int_0^\infty \frac{x^2 \cdot 3 \cdot 6^3}{(x + 6)^{3+1}} \, dx \\
&= \frac{4^3}{6^3} 6^2 = 10.66\ldots .\\
\end{aligned}
\]
Note that the last integral above is the second moment about the origin of \(\mathcal{Pa}(3,6)\), which is equal to \([6^2 \cdot\Gamma(3-2)\Gamma(1+2)] /\Gamma(3) = 6^2\).

Therefore,
\[\begin{aligned}
  \mathrm{E}[S_R] &= \lambda E[Z] = 320/9, \\
  \mathrm{Var}[S_R] &= \lambda E[Z^2] = 1280/3. 
\end{aligned}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Zero claims excluded} We define
  \[ W = Z | Z >0 = X - M | X > M.\]
\end{enumerate}

\[
\begin{aligned}
\mathrm{E}[W] &=   \int_0^\infty x f_W(x)\, dx \\
&= \int_0^\infty \frac{x f_X(x + 2)}{(1 - F_X(2))} \, dx \\
&= \frac{1}{(1 - F_X(2))} \int_0^\infty x f_X(x + 2) \, dx \\
&= \frac{1}{(1 - F_X(2))}\cdot \mathrm{E}[Z].
\end{aligned}
\]
It follows that
\[ \mathrm{E}[S_R] = \lambda\cdot \mathrm{Pr}(X > M) \cdot \mathrm{E}[W] = 40 ( 1 - F_X(2)) \mathrm{E}[W] = 40\mathrm{E}[Z] = 320/9.\]
Similarly, one can show that
\[
\begin{aligned}
\mathrm{E}[W^2] &=   \int_0^\infty x^2 f_W(x)\, dx \\
&= \frac{1}{(1 - F_X(2))}\cdot \mathrm{E}[Z^2].
\end{aligned}
\]
This results in
\[\mathrm{Var}[S_R] = \lambda \cdot \mathrm{Pr}(X > M) \cdot \mathrm{E}[W^2] = 40 ( 1 - F_X(2)) \mathrm{E}[W^2] = 40\mathrm{E}[Z^2] = 1280/3.\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Note that \(S = S_I + S_R\) and
  \[ \mathrm{E}[S] = \lambda \mathrm{E}[X] = 40 \frac{4}{3-1} = 80. \]
  Therefore,\\
  \[ \mathrm{E}[S_I] =  80 - \frac{320}{9} = \frac{400}{9}. \]
\end{enumerate}

\hypertarget{approximation-of-the-collective-risk-model}{%
\section{Approximation of the collective risk model}\label{approximation-of-the-collective-risk-model}}

\hypertarget{the-normal-approximation}{%
\subsection{The normal approximation}\label{the-normal-approximation}}

According to the Central Limit Theorem, if the mean number of claims is
large, then the distribution of aggregate claims \(S\) can be approximated
by a normal distribution, i.e.~\(S \sim \mathcal{N}(\mathrm{E}[S], \mathrm{Var}[S])\).

\textbf{Notes}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The normal approximation may not provide a good approximation to the
  distribution of \(S\) because the true distribution of \(S\) is skew.
  However, the normal approximation is symmetric.
\item
  The normal approximation is likely to underestimate tail
  probabilities which are the most interest quantities of insurers.
\end{enumerate}

\begin{example}
\protect\hypertarget{exm:approximation}{}\label{exm:approximation}

Aggregate claims from a risk in a given
time have a compound Poisson distribution with Poisson parameter
\(\lambda\) and an individual claim amount distribution that is a
lognormal distribution with mean 1 and variance 2.5.

\end{example}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Approximate the distribution of \(S\) using the normal distribution
  when (a) \(\lambda = 10\) and (b) \(\lambda = 100\).
\item
  Find \(x\) such that \(\Pr(S \le x) = 0.95\) in both cases.
\item
  Comment on the obtained results.
\end{enumerate}

\hypertarget{the-translated-gamma-approximation}{%
\subsection{The translated gamma approximation}\label{the-translated-gamma-approximation}}

The translated gamma approximation makes use of the first three moments
of \(S\) and provides an improvement of the approximation over the normal
approximation. We assume that \(S\) can be approximated by \(Y + k\) where
\(Y \sim \mathcal{G}(\alpha, \lambda)\) and \(k\) is a constant. This distribution \(Y + k\) is
said to have a translated gamma distribution. By matching the moments of
the two distribution, the parameters \(\alpha, \lambda\) and \(k\) can be
found from \[\begin{aligned}
Sk[S] &= \frac{2}{\sqrt{\alpha}},  \\
Var[S] &= \frac{\alpha}{\lambda^2},\\
E[S] &= \frac{\alpha}{\lambda} + k.\end{aligned}\]

\begin{example}
\protect\hypertarget{exm:unlabeled-div-51}{}\label{exm:unlabeled-div-51}

Show that the parameters \(\alpha, \lambda\) and \(k\) satisfy
\[\begin{aligned}
\alpha &=  \frac{4}{Sk[S]^2}, \\
\lambda &= \sqrt{\frac{\alpha}{Var[S]}} \\
k &= E[S] -  \frac{\alpha}{\lambda}.\end{aligned}\]

\end{example}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-52}{}\label{exm:unlabeled-div-52}

The aggregate claims \(S\) have the compound Poisson distribution as given
in Example \ref{exm:approximation}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Use the translated gamma approximation to find \(x\) such that
  \(\Pr(S \le x) = 0.95\) when (a) \(\lambda = 10\) and (b)
  \(\lambda = 100\).
\item
  Comment on the obtained results.
\end{enumerate}

\end{example}

\hypertarget{recursive-calculation-of-the-collective-risk-model}{%
\section{Recursive calculation of the collective risk model}\label{recursive-calculation-of-the-collective-risk-model}}

The Panjer recursion formula provides recursive calculation of the
collective risk model. The algorithm can be numerically computed on a
computer provided that distribution of claim numbers \(N\) satisfy
Panjer's recursion formula,
\[p_n = \left( a + \frac{b}{n} \right) p_{n-1}, \quad n = 1,2, \ldots,\]
where \(a\) and \(b\) are constants.

\begin{example}
\protect\hypertarget{exm:unlabeled-div-53}{}\label{exm:unlabeled-div-53}

Show that a Poisson distribution \(N \sim Poisson(\lambda)\) satisfies Panjer's
recursion formula, i.e.~find the constants \(a\) and \(b\).

\end{example}

Assume that the claim size variable \(X\) takes only \textbf{positive integers}
and the distribution of claim numbers satisfies the Panjer's recursion
formula. We define

\begin{itemize}
\item
  \(f_k = \Pr(X = k), \quad k = 1,2, \ldots,\)
\item
  \(g_r = \Pr(S = r), \quad r = 0,1,2, \ldots.\)
\end{itemize}

Then the unknown \(g_r\) can be recursively calculated by

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(g_0 = p_0\),
\item
  \(g_r = \sum_{j=1}^r \left( a + \frac{bj}{r} \right) f_j g_{r-j}, \quad r = 1,2 \ldots.\)
\end{enumerate}

\textbf{Note} If \(X\) is not a discrete random variable, then we first
approximate it by a discrete distribution and then apply the Panjer's
recursion algorithm.

\begin{example}
\protect\hypertarget{exm:unlabeled-div-54}{}\label{exm:unlabeled-div-54}

Aggregate claims \(S\) have a compound Poisson distribution
\(\mathcal{CP}(\lambda,F_X)\) where \(\lambda = 1\) and an individual claim
amount \(X\) is either 1 or 2 with probability 3/4 and 1/4, respectively.
Calculate \(g_r\) for \(r = 0,1,2,3,4,5\).

\end{example}

\hypertarget{premium-calculation}{%
\section{Premium calculation}\label{premium-calculation}}

In this section, rules for setting premium to be charged to cover a risk
\(S\) (aggregate claims) are presented. The expected (mean) risk \(E[S]\)
is referred to as the \textbf{pure premium}. In practice, the premium must be
set to cover the expected risk, i.e.~\(P > E[S]\). Some premium
calculation rules are as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{The expected value principle (EVP)} The premium is given by a
  simple formula: \[P = E[S] + \theta\, E[S] = ( 1 + \theta)E[S],\]
  for some \(\theta > 0\), which is called the \textbf{relative security
  loading} on the pure premium \(E[S]\). The premium is increased by a
  percentage of the mean of the risk.
\item
  \textbf{The standard deviation principle (SVP)} The premium is increased
  by a percentage of the standard deviation of the risk.
  \[P = E[S] + \theta\, \text{SD}[S].\]
\item
  \textbf{The variance principle (VP)} The premium is increased by a
  percentage of the variance of the risk.
  \[P = E[S] + \theta\, Var[S].\]
\end{enumerate}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-55}{}\label{exm:unlabeled-div-55}

Suppose that \(S\) has a compound Poisson distribution with Poisson
parameters \(\lambda = 10\) and the claim sizes have a Pareto distribution
\(Pa(4,3)\).

\end{example}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Use the normal approximation and the translated gamma approximation
  to calculate the relative security loading such that the probability
  of a profit in the year is 0.95.
\item
  Repeat the same question as above assumed that the SVP is applied.
\end{enumerate}

\textbf{Solution:}

The loss distribution has Pareto distribution \(X \sim Pa(4,3)\). Therefore, \(\mathrm{E}[X] = 1\) and \(\mathrm{E}[X^2] = 3\).

The mean and variance of the aggregate claim amounts are \(\mathrm{E}[S] = \lambda \mathrm{E}[X] = 10\)
and \(\mathrm{Var}[S] = \lambda \mathrm{E}[X^2] = 30\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use the normal approximation \(S \sim \mathcal{N}(10, 30)\).
  Let \(P\) denote the premium charged. We need to find the security loading \(\theta\) such that
  \[\Pr( P - S > 0) = 0.95.\]
  Assume that the premium charged to cover the risk follows the expected value principle (EVP). So we set
  \[P = E[S] + \theta\, E[S] = ( 1 + \theta)E[S] = ( 1 + \theta)(10).\]
  \begin{align}
  0.95 &= \Pr( P - S > 0)  \\
  &= \Pr( ( 1 + \theta)(10) - S > 0)  \\
  &= \Pr( S < ( 1 + \theta)(10) ) \\
  &= \Pr( Z < \frac{( 1 + \theta)(10) - 10 }{\sqrt{30}} ) \\
  &= \Pr( Z < \frac{( \theta)(10) }{\sqrt{30}} ).
  \end{align}
  This gives \(\frac{( \theta)(10) }{\sqrt{30}} = 1.6448536\) and
  \[\theta = 0.9009234, \quad  P = 19.009.\]
  Instead of using the normal approximation to aggregate claims \(S\), we now assume that \(S\) is approximated by \(Y + k\) where
  \(Y \sim \mathcal{G}(1.4814815, 0.2222222)\) and \(k = 3.3333333\) is a constant. It follows that
  \begin{align}
  0.95 &= \Pr( P - S > 0)  \\
  &= \Pr( ( 1 + \theta)(10) - S > 0)  \\
  &= \Pr( S < ( 1 + \theta)(10) ) \\
  &= \Pr( Y < ( 1 + \theta)(10) - 3.3333333 ) \\
  \end{align}
\end{enumerate}

Therefore, \((1 + \theta)\)(10) - 3.3333333 = qgamma(0.95,shape = 1.481481, rate = 0.222222) = 17.43845, which results in
\[\theta = 1.0771784, \quad  P = 20.772.\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Using the standard deviation principle (SVP), we set
  \[P = E[S] + \theta\, \text{SD}[S] = 10 + \theta \cdot \sqrt{30}\]
  For the normal approximation of the aggregate claims, we obtain
  \begin{align}
  0.95 &= \Pr( P - S > 0)  \\
  &= \Pr( 10 + \theta \cdot \sqrt{30} - S > 0)  \\
  &= \Pr( S < 10 + \theta \cdot \sqrt{30} ) \\
  &= \Pr( Z < \frac{10 + \theta \cdot \sqrt{30} - 10 }{\sqrt{30}} ) \\
  &= \Pr( Z < \theta).
  \end{align}
\end{enumerate}

Hence, \(\theta = 1.644854\) and \(P = 19.009\).

\textbf{Comment} The loading factors (for normal approximation) in both two cases are different because they are applied to different quantities (i.e.~\(\mathrm{E}[S]\) and \(\mathrm{Var}[S]\)). But they give the same premium.

\hypertarget{ruin-theory}{%
\chapter{Ruin Theory}\label{ruin-theory}}

\hypertarget{the-classical-risk-process}{%
\section{The classical risk process}\label{the-classical-risk-process}}

Short term risk models for a fixed time period have been studied in the
previous sections. In this section, risk models that evolve over time
will be presented. Suppose that an insurer

\begin{itemize}
\item
  begins with an initial capital \(u\), called an initial surplus,
\item
  collects premiums at a constant rate \(c\) per unit time,
\item
  and pays claims when losses occur.
\end{itemize}

The insurer is in ruin if the insurer's capital becomes negative at some
point in time, i.e.~the insurer's surplus falls to zero or below.

\textbf{Note} A surplus is an excess of income or assets over expenditure or
liabilities in a given period, typically a financial year:

\begin{example}
\protect\hypertarget{exm:ExampleSurplus}{}\label{exm:ExampleSurplus}

\emph{An insurer has initial surplus \(u\) of 1 (in suitable
units) and receives premium payments at a rate of 1 per year. Suppose
claims from a portfolio of insurance over the first two years are as
follows:}

\begin{longtable}[]{@{}llll@{}}
\toprule
\emph{Time (years)} & \emph{0.4} & \emph{0.9} & \emph{1.5} \\
\midrule
\endhead
\emph{Amount} & \emph{0.8} & \emph{0.7} & \emph{1.2} \\
\bottomrule
\end{longtable}

\emph{Plot a surplus process and determine whether ruin occurs within the
first three years.}

\end{example}

\textbf{Solution:}
The insurer's surplus (or cash flow) at any future time \(t\) (\textgreater{} 0) is a random variable, since its value depends on the claims experience up to time \(t\). The insurer's surplus at time \(t\) is a random variable. The insurer's surplus at time \(t\) is denoted \(U(t)\). The following formula for \(U(t)\) can be written as

\begin{equation}
U(t) = u + ct - S(t),
\end{equation}
where the \textbf{aggregate claim amount up to time}
\(t\), \(S(t)\) is
\begin{equation}
S(t) = \sum_{i = 1}^{N(t)} X_i .
\end{equation}

The following table summarises the values of the surplus function at the time when claims occurs.

\begin{longtable}[]{@{}ccc@{}}
\toprule
Time & Surplus (before claim) & Surplus (after claim) \\
\midrule
\endhead
0 & 1 & 1 \\
0.4 & 1.4 & 0.6 \\
0.9 & 1.1 & 0.4 \\
1.5 & 1 & -0.2 \\
\bottomrule
\end{longtable}

The surplus function increases at a constant rate \(c\) until there is a claim and the surplus drops by the amount of the claim. The surplus then increases again at the same rate \(c\) and drops are repeated when claims occur. In this example,
ruin occurs at time 1.5.
The plot of the surplus process is given in the following figure.

\begin{figure}
\centering
\includegraphics{SCMA470Bookdownproj_files/figure-latex/unnamed-chunk-19-1.pdf}
\caption{\label{fig:unnamed-chunk-19}The surplus process befor reinsurance arrangment.}
\end{figure}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-56}{}\label{exm:unlabeled-div-56}

\emph{As given in Example
\ref{exm:ExampleSurplus}, suppose that the insurer has effected
proportional reinsurance with retained proportion of 0.7. The
reinsurance premium is 0.4 per year to be paid continuously. Plot a
surplus process and determine whether ruin occurs within the first three
years. Comment on the results.}

\end{example}

\textbf{Solution:}
The insurer's net premium income is 0.6 per year. The insurer's cash flow or surplus process is now given by
\begin{equation}
U_I(t) = u + (c - c_r)t - \alpha \cdot S(t),
\end{equation}
where \(c_r\) is the reinsurance premium rate and \(\alpha\) is the retained proportion.

The following table summarises the values of the surplus function at the time when claims occurs.

\begin{longtable}[]{@{}ccc@{}}
\toprule
Time & Surplus (before claim) & Surplus (after claim) \\
\midrule
\endhead
0 & 1 & 1 \\
0.4 & 1.24 & 0.68 \\
0.9 & 0.98 & 0.49 \\
1.5 & 0.85 & 0.01 \\
\bottomrule
\end{longtable}

\begin{figure}
\centering
\includegraphics{SCMA470Bookdownproj_files/figure-latex/unnamed-chunk-21-1.pdf}
\caption{\label{fig:unnamed-chunk-21}The surplus process under a proportional reinsurance arrangement.}
\end{figure}

It should be emphasised that under this proportional reinsurance arrangement, ruin does not occur within 2 years.

\hypertarget{classical-risk-process}{%
\subsection{Classical risk process}\label{classical-risk-process}}

The following assumptions are assumed for the study of the evolution of
insurer's surplus over time.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The insurer's initial capital is \(u\).
\item
  The premium rate per unit of time received continuously is \(c\), i.e.
  the total amount of premiums received by time \(t\) is \(ct\).
\item
  The counting process \(\{N(t) \}_{t \ge 0}\) for the number of claims
  occurred in the time interval \([0,t]\) is a Poisson process with
  parameter \(\lambda\).
\item
  The claim sizes (or individual claim amounts) \(X_1, X_2, \ldots\) are
  independent and identically distributed random variables.
\item
  The claim sizes \(X_1, X_2, \ldots\) are independent of the counting
  process \(N(t)\).
\end{enumerate}

The \textbf{surplus process} \(\{U(t) \}_{t \ge 0}\) is then given by
\begin{equation}
\label{eq:surplus}
U(t) = u + ct - S(t),
\end{equation}
where the \textbf{aggregate claim amount up to time}
\(t\), \(S(t)\) is
\begin{equation}
\label{eq:St}
S(t) = \sum_{i = 1}^{N(t)} X_i .
\end{equation}

The evolution of insurer's surplus defined in \eqref{eq:surplus}
is also known as the \textbf{classical risk process}.
The only random and uncertain quantity in
\eqref{eq:surplus}
is the aggregate claims \(S(t)\).

\textbf{Notes} The classical risk model contains many simplification.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The claim-arrival rate \(\lambda\) remains constant over time.
\item
  No interest is pain on the surplus.
\item
  There is no inflation.
\item
  The premium income is received continuously in time.
\item
  Claims are paid out \textbf{immediately}.
\item
  there are assumptions of independence.
\end{enumerate}

\hypertarget{poisson-processes}{%
\subsection{Poisson processes}\label{poisson-processes}}

A \textbf{Poisson process} is a special type of counting process. It can be
represented by a continuous time stochastic process \(\{N(t)\}_{t \ge 0}\)
which takes values in the non-negative integers. It can be used to model
the occurrence or arrival of events over a continuous time interval. The
state space is discrete but the time set is continuous. Here \(N(t)\)
represents the number of events in the interval \((0,t]\).

The following examples can also be modelled by a Poisson process:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Claims arrivals at an insurance company,
\item
  Accidents occurring on the highway, and
\item
  Telephone calls to a call centre.
\end{enumerate}

\hypertarget{counting-process}{%
\subsubsection*{Counting Process}\label{counting-process}}
\addcontentsline{toc}{subsubsection}{Counting Process}

A counting process \(\{N_t \}_{t \ge 0}\) is a collection of non-negative,
integer-valued random variables such that if \(0 \le s \le t\), then
\(N(s) \le N(t)\).

The following figure illustrates a trajectory of the Poisson process.
The sample path of a Poisson process is a right-continuous step
function. There are jumps occurring at time \(t_1, t_2, t_3, \ldots\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda }\OtherTok{\textless{}{-}} \DecValTok{17}
\CommentTok{\# the length of time horizon for the simulation T\_length \textless{}{-} 31}
\NormalTok{last\_arrival }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{arrival\_time }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{inter\_arrival }\OtherTok{\textless{}{-}} \FunctionTok{rexp}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{rate =}\NormalTok{ lambda)}
\NormalTok{T\_length }\OtherTok{\textless{}{-}} \DecValTok{1}
\ControlFlowTok{while}\NormalTok{ (inter\_arrival }\SpecialCharTok{+}\NormalTok{ last\_arrival }\SpecialCharTok{\textless{}}\NormalTok{ T\_length) \{ }
\NormalTok{  last\_arrival }\OtherTok{\textless{}{-}}\NormalTok{ inter\_arrival }\SpecialCharTok{+}\NormalTok{ last\_arrival }
\NormalTok{  arrival\_time }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(arrival\_time,last\_arrival) }
\NormalTok{  inter\_arrival }\OtherTok{\textless{}{-}} \FunctionTok{rexp}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{rate =}\NormalTok{ lambda)}
\NormalTok{\}}


\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(arrival\_time)}
\NormalTok{counts }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n}

\FunctionTok{plot}\NormalTok{(arrival\_time, counts, }\AttributeTok{pch=}\DecValTok{16}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, n))}
\FunctionTok{points}\NormalTok{(arrival\_time, }\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, counts[}\SpecialCharTok{{-}}\NormalTok{n]))}
\FunctionTok{segments}\NormalTok{(}
  \AttributeTok{x0 =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, arrival\_time[}\SpecialCharTok{{-}}\NormalTok{n]),}
  \AttributeTok{y0 =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, counts[}\SpecialCharTok{{-}}\NormalTok{n]),}
  \AttributeTok{x1 =}\NormalTok{ arrival\_time,}
  \AttributeTok{y1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, counts[}\SpecialCharTok{{-}}\NormalTok{n])}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{SCMA470Bookdownproj_files/figure-latex/PlotPoissonProcess-1.pdf}

Recall that a stochastic process \(\{N(t) \}_{t \ge 0}\) is a Poisson
process with parameter \(\lambda\) if the process satisfies the three
properties:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(N(0) = 0\).
\item
  \textbf{Independent increments} For \(0 < s < t \le u < v\), the increment
  \(N(t) - N(s)\) is independent of the increment \(N(v) - N(u)\), i.e.
  the number of events in \((s,t]\) is independent of the number of
  events in \((u,v]\).
\item
  \textbf{Stationary increments} For
  \(0 < s <t\), the distribution \(N(t) - N(s)\) depends only on \(t -s\)
  and not on the values \(s\) and \(t\), i.e.~the increments of the
  process over time has a distribution that only depend on the time
  difference \(t - s\), the lenght of the time interval.
\item
  \textbf{Poisson distribution} For
  \(t \ge 0\), the random variable \(N(t)\) has a Poisson distribution
  with mean \(\lambda t\).
\end{enumerate}

It follows from conditions the \textbf{Stationary Increments} and \textbf{Poisson Distribution} properties that
\[\Pr(N(t) - N(s) = n) = \Pr(N(t-s) - N(0) = n) =  \frac{ ( \lambda(t-s))^n e^{-\lambda(t-s)} }{n!},  \quad \quad s < t, \, n = 0,1,2, \ldots\]

\textbf{Notes}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The sample paths of \(\{N(t) \}_{t \ge 0}\) are non-decreasing step
  functions, or the process is referred to be as a counting process.
\item
  A process with stationary and independent increments can be thought
  of as \textbf{starting over} at any point in time in a probabilistic
  sense. The `starting over' property follows from the fact that

  \begin{itemize}
  \item
    the exponential distribution has the memoryless property, and
  \item
    the times between successive events (or interarrival times) are
    independent and identically distributed exponential random
    variables with mean \(1/\lambda\).
  \end{itemize}
\item
  For more details about Poisson processes, please refer to the
  contents of the course ``SCMA 469 Actuarial Statistics''
\end{enumerate}

\hypertarget{compound-poisson-processes}{%
\subsection{Compound Poisson processes}\label{compound-poisson-processes}}

The aggregate claims process \(S(t)\) defined in \eqref{eq:St}
of the classical
risk process is said to be a \textbf{compound Poisson process} with Poisson
parameter \(\lambda\). The compound Poisson process has the following
important properties:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  For each \(t\), the random variable \(S(t)\) has a compound Poisson
  distribution with parameter \(\lambda t\), i.e.
  \[S(t) \sim \mathcal{CP}(\lambda t, F_X(x)).\] Thus, the mean and
  variance of the compound Poisson distribution are
  \[\mathrm{E}[S(t)] = \lambda t \mathrm{E}[X], \quad \mathrm{Var}[S(t)] =\lambda t \mathrm{E}[X^2].\]
  The moment generating function of \(S(t)\) is
  \[M_{S(t)}(r) = \exp(\lambda t(M_X(r) - 1)).\]
\item
  It has stationary and independent increments, i.e.~for disjoint time
  intervals \(0 < s < t \le u < v\), the random variables \(N(t) - N(s)\)
  and \(N(v) - N(u)\) are independent and \(N(t) - N(s)\) depends only on \(t -s\) and not on the values \(s\) and \(t\). Hence, the random variables \(S(t) - S(s)\) and \(S(v) - S(u)\)
  are \textbf{independent} and have
  \(\mathcal{CP}(\lambda (t -s), F_X(x))\) and
  \(\mathcal{CP}(\lambda (v - u), F_X(x))\) distributions, respectively.
\end{enumerate}

\textbf{Notes} Various properties of the aggregate claims process \(S(t)\) can
be summarised as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(S(1) \sim \mathcal{CP}(\lambda, F_X(x))\) is the aggregate claims in
  the first year.
\item
  \(S(n) - S(n-1) \sim \mathcal{CP}(\lambda, F_X(x))\) is the aggregate
  claims in the \(n\)th year, for \(n = 1,2, \ldots\).
\item
  The process \(\{ S(n) - S(n-1) \}_{n=1}^\infty\) is a sequence of
  \textbf{independent and identically distributed} random variables
  representing the aggregate claims in successive years.
\end{enumerate}

\hypertarget{the-relative-safety-loading}{%
\subsection{The relative safety loading}\label{the-relative-safety-loading}}

According to the expected value principle, the premium rate \(c\) per
unit time is defined by
\[c = (1 + \theta) \mathrm{E}[S(1)] = (1 + \theta) \lambda \mu_X.\]
Hence the \textbf{relative safety loading} (or \textbf{premium loading factor} or
\textbf{relative security loading}) \(\theta\) is given by
\[\theta = \frac{c - \lambda \mu_X}{\lambda \mu_X}.\]
In addition, the insurer should load the premium for profit so that \(c > \lambda \mu_X\). This finding follows from the following example.

Let \(\mu_X\) and \(\sigma^2_X\) denote the mean and the variance of claim sizes \(X_i\) (in one period).

\begin{example}
\protect\hypertarget{exm:unlabeled-div-57}{}\label{exm:unlabeled-div-57}

Consider the following questions.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Calculate the expected surplus and the variance surplus at time \(t\).
\item
  Calculate the expected profit per unit time in \((0, t]\).
\end{enumerate}

\end{example}

\textbf{Solution:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  From \(U(t) = u + ct - S(t),\) the expected surplus at time \(t\) is
  \begin{align}
  \mathrm{E}[U(t)] &= u + ct - \mathrm{E}[S(t)] \\
  &= u + ct - (\lambda t)\mathrm{E}[X] \\
  &= u + ct - (\lambda t)\mu_X \\
  &= u + (c - \lambda \mu_X)\cdot t, 
  \end{align}
  and \[ \mathrm{Var}[U(t)] = \mathrm{Var}[S(t)] = (\lambda t)\mathrm{E}[X^2].\]
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The expected profit per unit time in \((0, t]\) can be calculated from
  \[\frac{\mathrm{E}[U(t) - U(0)]}{t} = c - \lambda \mu_X.\]
  This motivates the \textbf{net profit condition}:
  \[c > \lambda \mu_X.  \]
  Given \(\lambda\) and \(\mu_X\), we aim to set the premium rate \(c\) that satisfies the net profit condition.
\end{enumerate}

\textbf{Notes}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The insurer can make a profit provided that \(c > \lambda \mu_X\) or
  the relative safety loading \(\theta\) is positive. In this case, the
  surplus will drift to \(\infty\), but ruin could still occur. The rate
  at which premium income comes in is greater than the rate at which
  claims are paid out.
\item
  On the other hand, if \(c < \lambda \mu_X\), then the surplus will
  drift to \(-\infty\), but ruin is certain.
\item
  If \(c = \lambda \mu_X\), the surplus will drift to \(\infty\) and \(-\infty\), but ruin is certain (eventually).
\end{enumerate}

\hypertarget{ruin-probabilities}{%
\subsection{Ruin probabilities}\label{ruin-probabilities}}

Various definitions of ruin probabilities are given.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The \textbf{probability of ruin in infinite time} (or the \textbf{ultimate ruin
  probability}) is defined by
  \[\psi(u) = \Pr(U(t) < 0 \quad \text{ for some } t > 0).\]
\item
  The \textbf{finite-time ruin probability} (or the \textbf{probability of ruin
  by time \(t\)}) is defined by
  \[\psi(u,t) = \Pr(U(s) < 0 \quad \text{ for some } s \in (0,t]).\]
\item
  The \textbf{discrete time ultimate ruin probability} is defined by
  \[\psi_h(u) = \Pr(U(t) < 0 \quad \text{ for some } t \in \{h, 2h, 3h, \ldots \}).\]
\item
  The \textbf{discrete time ruin probability in finite time} is defined by
  \[\psi_h(u,t) = \Pr(U(s) < 0 \quad \text{ for some } s \in \{h, 2h, 3h, \ldots, t\}).\]
\end{enumerate}

\textbf{Notes}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  For \(0 \le u_1 \le u_2\), \[\psi(u_1) \ge \psi(u_2),\] and
  \[\psi(u_1,t) \ge \psi(u_2,t),\]
  i.e.~the
  ultimate ruin probability and finite-time ruin probability are non-increasing in \(u\).
  Intuitively, the larger the initial surplus, the less likely it is that ruin will occur either in a finite time period or an unlimited time
  period.
\item
  If ruin occurs under the discrete time, it must occur under the
  continuous time, i.e.~\[\psi_h(u) < \psi(u).\] Similarly,
  \[\psi_h(u,t) < \psi(u,t).\]
\item
  For a given initial surplus \(u\) and \(0 < t_1 < t_2\),
  \[\psi(u,t_1) < \psi(u,t_2).\]
  Intuitively, the longer the period considered when checking for ruin, the more likely it is that ruin will
  occur.
\item
  The discrete time ultimate ruin probability \(\psi_h(u)\) could be
  used as an approximation of \(\psi(u)\) provided \(h\) is sufficiently
  small.
\item
  The discrete time ruin probability in finite time \(\psi_h(u,t)\)
  could be used as an approximation of \(\psi(u,t)\) provided \(h\) is
  sufficiently small.
\end{enumerate}

\begin{example}
\protect\hypertarget{exm:unlabeled-div-58}{}\label{exm:unlabeled-div-58}

\emph{Suppose the annual aggregate claims for a portfolio of
policies is approximately normal.}

\begin{itemize}
\item
  \emph{The insurer's initial surplus is 1000 (in suitable units) and the
  premium rate is 1500 per year.}
\item
  \emph{The number of claims per year has a Poisson distribution with
  parameter 50.}
\item
  \emph{The distribution of claim sizes is lognormal with parameters
  \(\mu = 3\) and \(\sigma^2 = 0.9\).}
\end{itemize}

\emph{Calculate the probability that the insurer's surplus at time 2 will be
negative.}

\end{example}

\textbf{Solution:} Using the normal approximation, the total claims \(S\) can be approximated by \(S \sim \mathcal{N}(\mathrm{E}[S], \mathrm{Var}[S])\). We have
\begin{align}
\mathrm{E}[X] &= e^{\mu + \sigma^2/2} = 31.500392 \\
\mathrm{E}[X^2] &= e^{2\mu + 2\sigma^2} = 2440.601978. 
\end{align}

Therefore,
\begin{align}
\mathrm{E}[S(2)] &= 2(50)\mathrm{E}[X] = 3150.039231 \\
\mathrm{Var}[S(2)] &= 2(50)\mathrm{E}[X2] = \ensuremath{2.440602\times 10^{5}} . 
\end{align}

Hence, ruin will occur if \(S(2)\) is greater than the initial surplus plus premiums received. Therefore, the probability of ruin is
\begin{align}
\Pr(S(2) > u + 2c) &= \Pr(S(2) > 1000 + 2(1500)) \\
&= \Pr(Z > \frac{1000 + 2(1500)  - 3150.0392309}{\sqrt{\ensuremath{2.440602\times 10^{5}}}}) \\
&= \Pr(Z > 1.720483)  = 0.04267.
\end{align}
the probability of ruin is approximately 4.267\%.

\hypertarget{simulation-of-ruin-probabilities}{%
\section{Simulation of ruin probabilities}\label{simulation-of-ruin-probabilities}}

In this section, we will use simulation to numerically estimate the probability of ruin. First, we introduce the \textbf{inverse transform method}, which is a method for generating random numbers from any probability distribution by using its inverse cumulative distribution.

\begin{example}
\protect\hypertarget{exm:unlabeled-div-59}{}\label{exm:unlabeled-div-59}

\emph{Let \(F(x)\) be a continuous cumulative density
function. Let \(Y\) be a random variable with a \(U(0,1)\) distribution.
Define the random variable \(X\) by \[X = F^{-1}(Y).\] Show that the
cumulative density function of \(X\), \(F_X(x)\) is \(F(x)\).}

\end{example}

\textbf{Solution:}
We need to show that \(Pr(X \le x) = F(x)\) for all \(x\), i.e.~\(F_X(x)= F(x)\) as defined above.

It follows from the monotonicity of \(F\) and the definition

\begin{align}
F_X(x) &= \Pr(X \le x)\\ 
&= \Pr(F^{-1}(Y) \le x)\\
&= \Pr(F(F^{-1}(Y)) \le F(x)\\
&= \Pr(Y \le F(x))\\
\end{align}

Since \(Y \sim U(0,1)\), we have \(\Pr(Y \le t) = t\) for any \$t \in [0,1]. Therefore,
\[ F_X(x) = \Pr(Y \le F(x)) = F(x).\]
\textbf{Note} We can use this result to generate values from the required probability distribution (which will be useful in Excel). In order to generate \(X_1, X_2, X_3, \ldots, X_n\) from \(\mathcal{G}(\alpha,\lambda)\) (or any other distributions) in Excel, we use \texttt{GAMMAINV(RAND(),\ alpha,\ 1/lambda)}. However, in R, we can simply use \texttt{rgamma(n,\ alpha,\ lambda)} to generate \(n\) random numbers from the \(\mathcal{G}(\alpha,\lambda)\) distribution.

\begin{example}
\protect\hypertarget{exm:unlabeled-div-60}{}\label{exm:unlabeled-div-60}

\emph{The aggregate claims process for a risk is compound
Poisson with Poisson parameter \(\lambda = 100\) per year. Individual
claim amounts have \(\text{Pa}(4,3)\). The premium income per year is
\(c = 110\) (in suitable units), received continuously.}

\emph{Using either Excel or R to simulate 1000 values of aggregate claims
\(S\), assuming that \(S\) is approximated by a translated gamma
approximation,}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Estimate
  \(\hat{\psi}_1(50, 5)\), an estimate of \(\psi_1(50,5)\).}
\item
  \emph{Estimate the standard error of \(\hat{\psi}_1(50, 5)\).}
\item
  \emph{Calculate a 95\% confidence interval for your estimate in 1.}
\item
  \emph{Estimate \(\psi_{0.5}(50, 5)\).}
\end{enumerate}

\end{example}

\textbf{Solution:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  An estimate of \(\psi_1(u,5)\) with \(u = 50\) and \(c =110\) can be obtained as follows:
\end{enumerate}

From the properties of \(S(t)\),

\begin{itemize}
\item
  The aggregate claims in
  the first year have \(S(1) \sim \mathcal{CP}(\lambda, F_X(x))\) distribution with \(\lambda = 100\) and \(X \sim \text{Pa}(4,3)\)
\item
  The aggregate
  claims in the \(j\)th year, for \(j = 1,2, \ldots, 5\) have \(S(j) - S(j-1) \sim \mathcal{CP}(\lambda, F_X(x))\) distribution.
\end{itemize}

It follows that
\begin{align}
\psi_1(u,5) &= \Pr(U(j) < 0 \quad \text{ for at least one of } j \in \{1,2, \ldots, 5\}) \\
&= \Pr(u + cj - S(j) < 0 ), \text{ for at least one of } j = 1,2, \ldots, 5.
\end{align}
When

\begin{itemize}
\item
  \(j = 1, U(1) = 50 + 110 - S(1)\)
\item
  \(j = 2, U(2) = 50 + 2 - S(2) = U(1) + c - (S(2) - S(1))\)
\item
  \(j = 3, U(3) = 50 + 3 - S(3) = U(2) + c - (S(3) - S(2))\)
\item
  \(j = 4, U(4) = 50 + 4 - S(4) = U(3) + c - (S(4) - S(3))\)
\item
  \(j = 5, U(5) = 50 + 5 - S(5) = U(4) + c - (S(5) - S(4))\)
\end{itemize}

The algorithm to estimate the finite time ruin in discrete time can be described as follows:

Step 1. Simulate values of \(S(1), S(2) - S(1), \ldots, , S(5) - S(4)\) from \(\mathcal{CP}(\lambda, F_X(x))\) distribution. Then compute \(U(1), U(2), \ldots U(5)\).

Step 2. Check if one of \(U(1), U(2), \ldots U(5)\) are negative.

Step 3. Repeat the simulations (1 and 2) 1000 times.

Step 4. Le \(M\) be the number of simulations out of 1000 where ruin occurs. Then \(\hat{\psi}_1(50, 5) = \frac{M}{1000}.\)

From the results, there are \(M = 21\) simulations that ruin occurs, and hence
\[\hat{\psi}_1(50, 5) = \frac{M}{1000} = \frac{21}{1000}.\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  The estimation of the standard error of \(\hat{\psi}_1(50, 5)\) can be obtained as follows. We know that \(M \sim \mathcal{B}(1000,p)\) where \(p = \hat{\psi}_1(50, 5)\). Then,
  \[\textrm{Var}\left[\frac{M}{1000}\right] = \frac{1}{1000^2}\textrm{Var}[M] = \frac{1000 (p) (1-p)}{1000^2}\] and
  \[ \textrm{SD}[\hat{\psi}_1(50, 5)] = \frac{1000 (0.021) (1-0.021)}{1000^2} = 0.004534 \]
\item
  The 95\% confidence interval of the estimate is
  \[ (\hat{\psi}_1(50, 5) - z_{\alpha/2}\textrm{SD}[\hat{\psi}_1(50, 5)], \hat{\psi}_1(50, 5) + z_{\alpha/2} \textrm{SD}[\hat{\psi}_1(50, 5)]) = (0.012113,0.029887).\]
\item
  For the estimation of discrete time probability of ruin where the surplus process is checked at time intervals of length 0.5, we proceed as follows. First we note that
\end{enumerate}

\(S(1/2), S(1) - S(1/2), S(3/2) - S(1), \ldots, S(5) - S(9/2) \sim \mathcal{CP}((1/2)\lambda, F_X(x))\) distribution.

In addition,

\begin{itemize}
\item
  U(1/2) = U(0) + c (1/2) - S(1/2)\$
\item
  U(1) = U(1/2) + c (1/2) - ( S(1) - S(1/2) )\$
\item
  U(3/2) = U(1) + c (1/2) - (S(3/2) - S(1))\$ , \(\ldots\),
\item
  U(5) = U(9/2) + `c (1/2) - ( S(5) - S(9/2) )\$.
\end{itemize}

It follows that

\begin{align}
\mathrm{E}[S(1/2)] &= (1/2)(100)\mathrm{E}[X] = (1/2)\mathrm{E}[S(1)] = 50 \\
\mathrm{Var}[S(1/2)] &= (1/2)(100)\mathrm{E}[X^2] =  (1/2)\mathrm{Var}[S(1)]  = 150 \\
\mathrm{Sk}[S(1/2)] &= \sqrt{2} \mathrm{Sk}[S(1)] = 0.734847 . 
\end{align}

Now we assume that \(S(j) - S(j-1)\) for \(j = 1/2, 1, 3/2, \ldots, 5\) can be approximated by \(Y + k\) where
\(Y \sim \mathcal{G}(\alpha, \lambda)\) and \(k\) is a constant. It follows that
\[ \hat{\alpha} = 7.407407, \quad \hat{\beta} = 0.222222, \quad \hat{k} = 16.666667.  \]
The simulations can be obtained in the same way.

\hypertarget{interactive-lecture}{%
\chapter{Interactive Lecture}\label{interactive-lecture}}

Some \emph{significant} applications are demonstrated in this chapter.

\hypertarget{datacamp-light}{%
\section{DataCamp Light}\label{datacamp-light}}

By default, \texttt{tutorial} will convert all R chunks.

eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJhIDwtIDJcbmIgPC0gM1xuYSArIGIifQ==

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

\begin{table}[h]    
\begin{center}
\caption{Comparision of Bayesian and empirical Bayesian models}
\begin{tabular}{| l | l | l | c | }
    \hline
           &  Normal $-$ normal &  Poisson $-$ gamma  & EBCT\\ \hline   
  Prior   & $\theta \sim \vnormal{\mu_0,\sigma^2_0}$ & $\lambda \sim \vgamma{\alpha,\beta}$ & none  \\
  Conditional mean of $X_i$ & $\theta$  & $\lambda$ &  $m(\theta)$   \\
    Conditional variance of $X_i$ & $\sigma^2$  & $\lambda$ &  $s^2(\theta)$  \\ \hline
\end{tabular}
\end{center}    
\end{table}

\hypertarget{tutorials}{%
\chapter{Tutorials}\label{tutorials}}

\hypertarget{tutorial-1}{%
\section{Tutorial 1}\label{tutorial-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Using the method of moments, calculate the parameter values for the
  gamma, lognormal and Pareto distributions for which
  \[\mathrm{E}[X] = 500 \quad  \text{and} \quad  \mathrm{Var}[X] = 100^2.\]
  \textbf{Answer:}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  gamma: \(\tilde{\alpha} = 25\), \(\tilde{\lambda} = 0.05.\)
\item
  lognormal: \(\tilde{\mu} = 6.194998\), \(\tilde{\sigma} = 0.1980422.\)
\item
  the MME cannot apply for the Pareto distribution. For the given values of \[\mathrm{E}[X] = 500 \quad  \text{and} \quad  \mathrm{Var}[X] = 100^2\], the obtained values of \(\tilde{\alpha}\) and \(\tilde{\lambda}\) from the method of moments are negative. Note that if we fix \(s = 100^2\) and vary \(\bar{x}\) within the interval \([90,110]\), the plot of \(\bar{x}\) against \(\tilde{\alpha}\) is shown below. Notice that when \(\bar{x} = 100\), \(\tilde{\alpha}\) tends to infinity.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xbar }\OtherTok{\textless{}{-}}\DecValTok{90}\SpecialCharTok{:}\DecValTok{110}
\NormalTok{s }\OtherTok{\textless{}{-}} \DecValTok{100}
\CommentTok{\# MME}
\NormalTok{alpha\_tilde }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{*}\NormalTok{s}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{/}\NormalTok{xbar}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(s}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{/}\NormalTok{xbar}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\NormalTok{lambda\_tilde }\OtherTok{\textless{}{-}}\NormalTok{ xbar}\SpecialCharTok{*}\NormalTok{(alpha\_tilde }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(xbar,alpha\_tilde, }\AttributeTok{xlab =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{bar}\NormalTok{(x)), }\AttributeTok{ylab =} \FunctionTok{expression}\NormalTok{(alpha))}
\end{Highlighting}
\end{Shaded}

\includegraphics{SCMA470Bookdownproj_files/figure-latex/unnamed-chunk-29-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Show that if \(X \sim \text{Exp}(\lambda)\), then the random variable
  \(X-w\) conditional on \(X > w\) has the same distribution as \(X\), i.e.
  \[X \sim \text{Exp}(\lambda)\Rightarrow  X - w | X > w \sim \text{Exp}(\lambda).\]
\end{enumerate}

\textbf{Solution:}
Let \(W = Z|Z>0\) be a random variable representing the amount of a
non-zero payment by the reinsurer on a reinsurance claim. The
distribution and density of \(W\) can be calculated as follows: for
\(x > 0\), \[\begin{aligned}
     \Pr[W \le x ] &= \Pr[Z \le x | Z >0] \\
            &= \Pr[X - M \le x | X > M] \\
            &= \frac{\Pr[M < X \le x + M]}{\Pr[X > M]}\\
            &= \frac{F_X(x+M) - F_X(M)}{1-F_X(M)}.\end{aligned}\]

Given \(X \sim \textrm{Exp}(\lambda)\), \(F_X(x) = 1 - e^{-\lambda x}.\) Moreover,

\[\begin{aligned}
\Pr[W \le x ]  &= \frac{F_X(x+M) - F_X(M)}{1-F_X(M)}  \\
&= \frac{  e^{-\lambda (M)} - e^{-\lambda (x+M)}}{e^{-\lambda (M)}} \\
&=  1 - e^{-\lambda x}.
\end{aligned}
\]
Hence, \(W \sim \textrm{Exp}(\lambda)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Derive an expression for the variance of the
  \(\text{Pa}(\alpha, \lambda)\) distribution. (Hint: using the pdf)
\end{enumerate}

\textbf{Solution:}
Recall that that for \(X \sim \mathcal{Pa}(\alpha,\lambda)\), its density function is
\[ f_X(x) = \frac{\alpha \lambda^\alpha}{ (x + \lambda)^{\alpha + 1}}.\]
\[
\begin{aligned}
\mathrm{E}[X] &= \int_0^\infty x \frac{\alpha \lambda^\alpha}{ (x + \lambda)^{\alpha + 1}}\, dx  \quad \text{(using integration by part:} \quad u = x \text{ and } (\lambda + x)^{-(\alpha + 1)}dx =  dv)  \\
&= -\alpha \lambda^\alpha \left( \frac{x}{\alpha} (\lambda + x)^{-\alpha} \right)\bigg|_0^\infty + (\alpha \lambda^\alpha)(\frac{1}{\alpha})\int_0^\infty \frac{1}{(\lambda + x)^\alpha} \, dx
\end{aligned}
\]
Using the fact that for \(X \sim \mathcal{Pa}(\alpha,\lambda)\), \(\textrm{E}[X]\) exists when \(\alpha > 1\), which will be assumed on the first term above. This assumption simplifies the above results as follows:

\[
\begin{aligned}
\mathrm{E}[X] &= 
 0 + \int_0^\infty \frac{\lambda^\alpha}{(\lambda + x)^\alpha} \, dx \\
 &= 
 \frac{\lambda}{\alpha - 1} \int_0^\infty \frac{(\alpha - 1)\lambda^{\alpha - 1}}{(\lambda + x)^\alpha} \, dx \\ 
 &= 
 \frac{\lambda}{\alpha - 1} \cdot 1.
\end{aligned}
\]
Note that the last integral integrate to 1 because the integrand is the density function of a Pareto distribution.

One can also show that
\[ \mathrm{E}[X^2]  = \frac{2 \lambda^2}{(\alpha - 1)(\alpha - 2)}.\] Therefore,
\[ \mathrm{Var}[X] = \mathrm{E}[X^2] - (\mathrm{E}[X])^2 = \frac{\alpha \lambda^2}{(\alpha - 1)^2(\alpha - 2)}.\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\item
  Show that the MLE (the maximum likelihood estimation) of \(\lambda\)
  for an \(\text{Exp}(\lambda)\) distribution is the reciprocal of the
  sample mean, i.e.~\(\hat\lambda = 1/ \bar x\).
  \textbf{Solution:}
  Suppose we have a random sample \(x = (x_1, x_2, \ldots, x_n)\) of \(X \sim \text{Exp}(\lambda).\) We have
  \[
  \begin{aligned}
    L(\lambda) &= \Pi_{i=1}^n f(x_i, \lambda) = \Pi_{i=1}^n  \lambda e^{-\lambda x_i} = \lambda^n e^{-\lambda \sum x_i}. \\
    l(\lambda) &= \log( L(\lambda)) = n \log(\lambda) - \lambda \sum x_i
  \end{aligned}
  \]
  The MLE can be obtained by maximise \(l(\lambda)\) with respect to \(\lambda\).
  \[ \frac{d\, l(\lambda)}{d \lambda }  = \frac{n}{\lambda} - \sum x_i = 0. \]
  Therefore, the MLE of \(\lambda\) is \(\hat{\lambda} = 1/\bar{x}.\)
\item
  Claims last year on a portfolio of policies of a risk had a
  lognormal distribution with parameter \(\mu = 5\) and
  \(\sigma^2 = 0.4\). It is estimated that all claims will increase by
  15\% next year. Find the probability that a claim next year will
  exceed 1000.
  \textbf{Solution:}
  From \(X \sim \mathcal{LN}(5,0.4)\), \(\log X \sim \mathcal{N}(5,0.4)\). Claims in next year will increase by 15\%. We define \(Y = (1+15\%) X = 1.15 X\). We also have
  \[
  \begin{aligned}
  \Pr(Y > 1000) &=\Pr(1.15 X > 1000)  \\
  &=\Pr(\log X > \log (1000/1.15)) \\
  &=\Pr\left(Z > \frac{\log (1000/1.15)) - 5 }{\sqrt{0.4}}\right) \\
  &=\Pr\left(Z > 2.7954\right) \\
  &=1 - \Pr\left(Z \le 2.7954\right) \\
  &= 1 -  0.9974082 = 0.002591777. \\
  \end{aligned}
  \]
  I used \texttt{R} to obtain the required probability.
\end{enumerate}

\hypertarget{tutorial-2}{%
\section{Tutorial 2}\label{tutorial-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Claims occur on a general insurance portfolio independently and at
  random. Each claim is classified as being of ``Type A'' or ``Type B''.
  Type A claim amounts are distributed \(\text{Pa}(3,400)\) and Type B
  claim amounts are distributed \(\text{Pa}(4,1000)\). It is known that
  90\% of all claims are of Type A.

  Let \(X\) denote a claim chosen at random from the portfolio.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Calculate \(\Pr(X > 1000).\)
  \item
    Calculate \(\mathrm{E}[X]\) and \(\mathrm{Var}[X]\).
  \item
    Let \(Y\) have a Pareto distribution
    with the same mean and variance as \(X\). Calculate
    \(\Pr(Y > 1000).\)
  \item
    Comment on the difference in the answers found in 1.1 and 1.2.
  \end{enumerate}
\item
  An insurer covers an individual loss \(X\) with excess of loss
  reinsurance with retention level \(M\). Let \(Y\) and \(Z\) be random
  variables representing the amounts paid by the insurer and
  reinsurer, respectively, i.e.~\(X = Y + Z\). Show that
  \(\mathrm{Cov}[Y,Z] \ge 0\) and deduce that
  \[\mathrm{Var}[X] \ge \mathrm{Var}[Y] +  \mathrm{Var}[Z].\] Comment
  on the results obtained.
\item
  Claim amounts from a general insurance portfolio are lognormally
  distributed with mean 200 and variance 2916. Excess of loss
  reinsurance with retenton level 250 is arranged. Calculate the
  probability that the reinsurer is involved in a claim.
\item
  Show that if \(X \sim \text{Pa}(\alpha, \lambda)\), then the random
  variable \(X-d\) conditional on \(X > d\) has a pareto distribution with
  parameters \(\alpha\) and \(\lambda + d\), i.e.
  \[X \sim \text{Pa}(\alpha, \lambda)\Rightarrow  X - d | X > d \sim \text{Pa}(\alpha,\lambda + d).\]
\item
  Consider a portfolio of motor insurance policies. In the event of an
  accident, the cost of the repairs to a car has a Pareto distribution
  with parameters \(\alpha\) and \(\lambda\). A deductible of 100 is
  applied to all claims and a claim is always made if the cost of the
  repairs exceeds this amount. A sample of 100 claims has mean 200 and
  standard deviation 250.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Using the method of moments, estimate \(\alpha\) and \(\lambda\).
  \item
    Estimate the proportion of accidents that do not result in a
    claim being made.
  \item
    The insurance company arranges excess of loss reinsurance with
    another insurance company to reduce the mean amount it pays on a
    claim to 160. Calculate the retention limit needed to achieve
    this.
  \end{enumerate}
\end{enumerate}

\hypertarget{solutions-to-tutorial-2}{%
\section{Solutions to Tutorial 2}\label{solutions-to-tutorial-2}}

\textbf{Solution:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    \[\begin{aligned}
    \Pr(X > 1000) &= \Pr(X > 1000 | A) \Pr(A) + \Pr(X > 1000 | B) \Pr(B) \\
    &= \left(  \frac{ 400 }{ 1000 + 400} \right)^{3} (0.9) +  \left(  \frac{ 1000 }{ 1000 + 1000} \right)^{4} (0.1) \\
    &= 0.0272413.
    \end{aligned}\]
  \item
    Using the conditional expectation and conditional variance formulas, we have
  \end{enumerate}
\end{enumerate}

\[\begin{aligned} 
\mathrm{E}[X|A] &= \frac{400 }{3 - 1} = 200, \\
\mathrm{E}[X|B] &= \frac{1000 }{4 - 1} = 333.3333333.
\end{aligned} \]
Hence,
\[\begin{aligned} 
\mathrm{E}[X] &= \mathrm{E}[\mathrm{E}[X|\text{type}]] \\
&=  \Pr(A) \, \mathrm{E}[X|A]   + \Pr(B) \, \mathrm{E}[X|B]   \\
&= (0.9)(200) + (0.1)(333.3333333) \\
&= 213.3333333.
\end{aligned}
\]

\begin{verbatim}
We also have
\end{verbatim}

\[\begin{aligned} 
\mathrm{E}[X^2|A] &= \mathrm{Var}[X|A] + (\mathrm{E}[X|A])^2 = \frac{(3) (400)^2}{(3 - 1)^2 (3 - 2)} + (200)^2   =   \ensuremath{1.6\times 10^{5}},\\
\mathrm{E}[X^2|B] &= \mathrm{Var}[X|B] + (\mathrm{E}[X|B])^2 = \frac{(4) (1000)^2}{(4 - 1)^2 (4 - 2)} + (333.3333333)^2   =   \ensuremath{3.3333333\times 10^{5}}. 
\end{aligned}
\]
Therefore,
\(\mathrm{E}[X^2] = (0.9)(\ensuremath{1.6\times 10^{5}}) + (0.1)(\ensuremath{3.3333333\times 10^{5}}) = \ensuremath{1.7733333\times 10^{5}}\),
and
\(\mathrm{Var}[X] = \ensuremath{1.3182222\times 10^{5}}\), \quad 
\(\mathrm{SD}[X] = 363.0733014\).

\begin{verbatim}
3. Using moment matching estimation, we have
\end{verbatim}

\(\tilde{\alpha} = 3.0545829\) and \(\tilde{\beta} = 438.3110196\). Therefore, \(\Pr[Y > 1000] = 0.0265228 < 0.0272413\).

\begin{verbatim}
4. Failure to separate two types of claims leads to an underestimation of tail probability. This affects the determination of premiums, reinsurance, and security.  
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    From \(X = Y + Z\), where \(Y = \min(X,M)\) and \(Z = \max(0,X -M)\).
    \[\begin{aligned}
    \mathrm{Cov}(Y,Z) &= \mathrm{E}[YZ] - \mathrm{E}[Y]\mathrm{E}[Z] \\
    &= \int_0^\infty \min(X,M) \max(0,X -M) f_X(x) \, dx - \mathrm{E}[Y]\mathrm{E}[Z] \\
    &= M \int_M^\infty \max(0,X -M) f_X(x) \, dx - \mathrm{E}[Y]\mathrm{E}[Z] \\
    &= M \mathrm{E}[Z] - \mathrm{E}[Y]\mathrm{E}[Z] \\
    &= \mathrm{E}[Z](M  - \mathrm{E}[Y])  \ge 0. \\
    \end{aligned}\]
  \end{enumerate}
\end{enumerate}

Therefore,

\[\mathrm{Var}[X] = \mathrm{Var}[Y + Z] = \mathrm{Var}[Y] + \mathrm{Var}[Z] + 2Cov(X,Y)   \ge \mathrm{Var}[Y] + \mathrm{Var}[Z].\]

Consequently, there is a reduction in the variability of the amount paid out by the direct insurer on claims.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  By the method of moments, the MMEs of the parameter \(\mu\) and \(\sigma\) can be found by matching \(\mathrm{E}[X]\) to the sample mean and \(\mathrm{Var}[X]\) to the sample variance:
\end{enumerate}

\[\mathrm{E}[X] = \exp\left(\mu + \frac{1}{2} \sigma^2 \right) = 200 \text{ and } \mathrm{Var}[X] =\exp\left(2\mu +  \sigma^2 \right) (\exp(\sigma^2) - 1) = 2916.\]
We find that \(\tilde{\mu} = 5.2631347\) and \(\tilde{\sigma} = 0.2652645\). Moreover,
\[ \Pr(X > 250) = P( Z > \frac{\ln(250) - \tilde{\mu}}{\tilde{\sigma}}) = 0.1650671,\]
where \(Z \sim \mathcal{N}(0,1)\). We find that the reinsurer is involved in about 16.51\% of claims.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Given \(X \sim \mathcal{Pa}(\alpha,\lambda)\), define \(W = X- d | X > d\).\\
  \[\begin{aligned}
    \Pr[W \le x ] &= \Pr[Z \le x | Z >0] \\
           &= \Pr[X - d \le x | X > d] \\
           &= \frac{\Pr[d < X \le x + d]}{\Pr[X > d]}\\
           &= \frac{F_X(x+d) - F_X(d)}{1-F_X(d)} \\
           &= 1 - \left(  \frac{\lambda + d}{\lambda + x +  d} \right)^\alpha. \end{aligned}\]
\end{enumerate}

Hence, \(W \sim \mathcal{Pa}(\alpha, \lambda + d).\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Let \(X\) be the cost of repair and \(Y\) be the cost of claims. Suppose that \(X \sim \mathcal{Pa}(\alpha, \lambda)\). It follows that
    \[ Y = X - d | X > d, \]
    where \(d = 100\). Moreover, \(Y \sim \mathcal{Pa}(\alpha, \lambda + d).\) It should be emphasised that the given information implies that
    \[ \mathrm{E}[Y] = 200, \quad \mathrm{Var}[Y] = 250^2.\]
    Letting \(\lambda + d = \phi\) results in \(Y \sim \mathcal{Pa}(\alpha, \phi).\)
  \end{enumerate}
\end{enumerate}

By the mothod of moments, the MMEs of \(\alpha\) and \(\phi\) (and hence \(\lambda\)) are
\(\tilde{\alpha} = 5.5555556\), \(\tilde{\phi} = 911.1111111\) and
\(\tilde{\lambda} = \tilde{\phi} - d = 811.1111111\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The proportion of accidents that do not result in a claim being made is
\end{enumerate}

\[\Pr(X < d) = 1 - \left(\frac{\tilde{\lambda}}{\tilde{\lambda} + d}\right)^\alpha = 0.4392931.\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  We know that claims before excess of loss reinsurance is \(Y \sim \mathcal{Pa}(\alpha, \phi).\) With excess of loss reinsurance contract, the expected value of the amount paid out by the insurer is \(\mathrm{E}[\min(Y,M)],\) which can be calculated as follows:
\end{enumerate}

\[\begin{aligned}
    \mathrm{E}[Y_I] &= \mathrm{E}[\min(Y,M)] \\
    &=  \mathrm{E}[Y] - \int_0^\infty y \cdot f_Y(y+M) \, dy  \\
    &=  \mathrm{E}[Y] - \int_0^\infty y \cdot \frac{\alpha \phi^\alpha}{(\phi + y + M)^{\alpha + 1}} \, dy \\
    &=  \mathrm{E}[Y] - \left(\frac{\phi}{\phi+M} \right)^\alpha\int_0^\infty y \cdot \frac{\alpha (\phi + M)^\alpha}{(\phi + y + M)^{\alpha + 1}} \, dy.
\end{aligned}\]

The last integral defines the mean of the Pareto random variable with parameters \(\alpha\) and \(\phi + M\) and so equals to \(\frac{\phi + M}{\alpha - 1}\). After simplifying, we have
\[\begin{aligned}
    \mathrm{E}[Y_I] 
    &=  \mathrm{E}[Y] - \left(\frac{\phi}{\phi+M} \right)^\alpha \left(\frac{\phi + M}{\alpha - 1}\right) = \left(\frac{\lambda + d}{\alpha - 1} \right)\left(1 - \left( \frac{\lambda + d}{\lambda + d + M} \right)^{\alpha - 1}  \right).
\end{aligned}\]

Substituting all the parameter values and \(\mathrm{E}[Y_I] = 160\), we solve for \(M\) which results in
\[M = \frac{\tilde{\lambda} + d}{\left(1- \frac{(\tilde{\alpha} -1)\mathrm{E}[Y_I]}{(\tilde{\lambda} + d)}  \right)^{ \frac{1}{\tilde{\alpha} - 1}   }} - (\tilde{\lambda} + d )  =  386.0795.\]

\hypertarget{tutorial-3}{%
\section{Tutorial 3}\label{tutorial-3}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The aggregate claims \(S\) have a compound Poisson random variable
  with Poisson parameter \(\lambda = 20\) and claim amounts have a
  \(\mathcal{G}(2,1)\) distribution. Find the coefficient of skewness of the
  aggregate claim amount \(Sk[S]\).
\item
  Suppose that \(S_1\) and \(S_2\) are independent compound Poisson random
  variables with Poisson parameters \(\lambda_1 = 10\) and
  \(\lambda_2 = 30\) and the claim sizes for \(S_i\) are exponentially
  distributed with mean \(\mu_i\) where \(\mu_1 = 1\) and \(\mu_2 = 2\),
  respectively. Find the distribution of the random sum
  \(S = S_1 + S_2\).
\item
  The number of claims in one time period has a negative binomial
  distribution \(\mathcal{NB}(k, p)\) with \(k = 1\) and claim sizes have an
  exponential distribution with mean \(\mu\).

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Use the moment generating formula to obtain the distribution of
    the aggregate claim amount \(S\).
  \item
    Find the mean and variance of the aggregate claims for this time
    period.
  \end{enumerate}
\item
  A portfolio consists of 100 car insurance policies. 60\% of the
  policies have a deductible of 10 and the remaining have a deductible
  of 0. The insurance policy pays the amount of damage in excess of
  the deductible subject to a maximum of 125 per accident. Assume that

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    The number of accident per year \textbf{per policy} has a Poisson
    distribution with mean 0.02; and
  \item
    The amount of damage has the distribution:
    \[Pr(X = 50) = 1/3, Pr(X = 150) = 1/3, Pr(X = 200) = 1/3.\]
  \end{enumerate}

  Find the expected insurer's payout.
\item
  The number of claims \(N\) per a fixed time period has the following
  distribution:
  \[Pr(N = 0) = 0.5, Pr(N = 1) = 0.3, Pr(N = 2) = 0.1, \text{ and } Pr(N = 3) = 0.1.\]
  The loss distribution is uniformly distributed on the interval
  \((0,100)\). Assume that the number of claims and the amount of losses
  are mutually independent.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Find the mean and variance of the aggregate claims for this
    fixed time period.
  \item
    Suppose that a policy deductible of 20 is in place. Find the
    expected insurer's payout.
  \end{enumerate}
\end{enumerate}

\hypertarget{solutions-to-tutorial-3}{%
\section{Solutions to Tutorial 3}\label{solutions-to-tutorial-3}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    The aggregate claims \(S\) have a compound Poisson random variable, \(S \sim \mathcal{CP}(\lambda, F_X)\) with \(\lambda = 20\) and \(X \sim \mathcal{G}(\alpha,\beta) = \mathcal{G}(2,1)\) distribution.
    From \(\mathrm{Sk}[S] = \frac{\lambda m_3}{(\lambda m_2)^{3/2}}\) with \(m_r = \mathrm{E}[X^r]\), we also have
  \end{enumerate}
\end{enumerate}

\[\mathrm{E}[X^r] = \frac{1}{\beta^r} \frac{\Gamma(\alpha + r)}{\Gamma(\alpha )}, \quad r > 0.\]

Note that if \(\alpha\) is an integer, then \(\Gamma(\alpha) = (\alpha-1)!\).

Substituting all the parameter values, we have
\(\mathrm{E}[X^2] = 6\), \(\mathrm{E}[X^3] = 24\) and \(\mathrm{Sk}[S] = 0.3651484\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \(S_1 \sim \mathcal{CP}(\lambda, F_1)\) and \(S_2 \sim \mathcal{CP}(\lambda, F_2)\) are independent compound Poisson random variables with claim sizes exponential distributions for \(S_i\), \(\text{Exp}(1/\mu_i)\) where \(\mu_1 = 1\) and \(\mu_2 = 2\).

  By the additivity of independent compound Poisson
  distributions, the distribution of \(S = S_1 + S_2\) is \(\mathcal{CP}(\lambda, F_X)\), where
  \[ F_X(x) = \frac{10}{40} F_1(x) + \frac{30}{40} F_2(x) = \frac{1}{4}(1 - e^{-x}) + \frac{3}{4} (1 - e^{-x/2}).\]
  It is the mixture of exponential distribution with mean 1 and 2.
\item
  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    From \(N \sim \mathcal{NB}(1, p)\) and \(X \sim \text{Exp}(\mu)\), the moment generating functions of
    \(N\) and \(X\) are
    \[ M_N(t) = \frac{p}{1-q e^t}, \quad M_X(t) = \frac{1}{1 - \mu t},\]
    where \(q = 1- p\).
  \end{enumerate}

  Therefore,
  \[\begin{aligned}
  M_S(t) &= M_N(\log(M_X(t))) \\
  &=  \frac{p}{1-q M_X(t)} \\
  &= p + q\frac{1}{1- \frac{\mu}{p}t}
  \end{aligned}.\]

  This distribution can be regarded as a mixture of a distribution with moment generating function 1 and a mixture of a distribution with moment generating function \((1- \frac{\mu}{p}t)^{-1}\), i.e.~the moment generating function of an exponential random variable with mean \(\mu/p\).

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \setcounter{enumii}{1}
  \tightlist
  \item
    Applying the properties of the moment generating function, \(M_S^{(k)}(0) = \mathrm{E}[X^k]\).
  \end{enumerate}

  It follows that
  \[ \frac{d}{dt} M_S(t) = \frac{p q \mu}{(p - \mu t)^2}, \quad \mathrm{E}[S] = \frac{q \mu}{p}\]
  and
  \[ \frac{d^2}{dt^2} M_S(t) = \frac{2 p q \mu^2}{(p - \mu t)^3}, \quad \mathrm{E}[S^2] = \frac{2 q \mu^2}{p^2}.\]
  Therefore, \[\mathrm{Var}[S] = \mathrm{E}[S^2] - (\mathrm{E}[S])^2 = \frac{2 q \mu^2}{p^2} - \left(\frac{q \mu}{p}\right)^2  = \frac{q(2-q)\mu^2}{p^2}.\]

  Alternatively, the mean and variance of the aggregate claims for this time period can be calculated from the properties of a compound negative distribution (with k = 1),
  \[\mathrm{E}[S] = \frac{q}{p} \mathrm{E}[X] = \frac{q \mu}{p},\]
  and
  \[\mathrm{Var}[S] = \frac{q}{p^2}(p \mathrm{E}[X^2] + q (\mathrm{E}[X])^2)  = \frac{q}{p^2} (p (2\mu^2) + q \mu^2) = \frac{q(2-q)\mu^2}{p^2}.\]
\item
  Let \(Y\) be the aggregate claims paid by the insurer of 60 policies with a deductible of 10 and policy limit of 125. Then, \(Y \sim \mathcal{CP}(60 \times 0.02, F_X)\), where \(X\) is the individual claim amount paid by the insurer. The distribution of \(X\) is
\end{enumerate}

\begin{longtable}[]{@{}ccc@{}}
\toprule
x & 40 & 125 \\
\midrule
\endhead
\(\Pr(X = x)\) & 1/3 & 2/3 \\
\bottomrule
\end{longtable}

Hence, \(\mathrm{E}[X] = 290/3\) and \(\mathrm{E}[Y] = 116\).

Let \(U\) be the aggregate claims paid by the insurer of 40 policies with a deductible of 0 and policy limit of 125. Then, \(U \sim \mathcal{CP}(40 \times 0.02, F_{X'})\), where \(X'\) is the individual claim amount paid by the insurer. The distribution of \(X'\) is

\begin{longtable}[]{@{}ccc@{}}
\toprule
x & 50 & 125 \\
\midrule
\endhead
\(\Pr(X' = x)\) & 1/3 & 2/3 \\
\bottomrule
\end{longtable}

Hence, \(\mathrm{E}[X] = 100\) and \(\mathrm{E}[U] = 80\). The total expected total claim payout of the insurer is \(116 + 80 = 196\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    The number of claims \(N\) per a fixed time period has the following
    distribution:
    \[\Pr(N = 0) = 0.5, \Pr(N = 1) = 0.3, \Pr(N = 2) = 0.1, \text{ and } \Pr(N = 3) = 0.1.\]
    Then, \(\mathrm{E}[N] = 0.8\) and \(\mathrm{Var}[N] = 0.96\).
  \end{enumerate}
\end{enumerate}

The loss distribution is uniformly distributed \(X \sim \mathcal{U}(0,100)\). Then,
Then, \(\mathrm{E}[X] = 50\) and \(\mathrm{E}[X^2] = 3333.3333333\).

The mean and variance of the aggregate claims for this fixed time period.
\[ \mathrm{E}[S] =  \mathrm{E}[N] \mathrm{E}[X] = 40 \]
and
\[ \mathrm{Var}[S] =  \mathrm{E}[N] (\mathrm{E}[X^2] - (\mathrm{E}[X])^2  ) + \mathrm{Var}[N] (\mathrm{E}[X])^2  = 3066.6666667 .\]

\begin{verbatim}
2.  Suppose that a policy deductible of 20 is in place. Then
\end{verbatim}

\[\begin{aligned}
\mathrm{E}[\max(0, X - 20)] &= \int_{20}^{100} (x - 20) \frac{1}{100} \, dx\\
&= 32.
\end{aligned}\]

Therefore, the expected insurer's payout is
\[ \mathrm{E}[N]\mathrm{E}[\max(0, X - 20)] = (0.8)(32) = 25.6. \]

\hypertarget{tutorial-4}{%
\section{Tutorial 4}\label{tutorial-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Given \(X \sim \mathcal{G}(\alpha, \lambda)\), find the distribution of \(Y = kX\)
  for some positive \(k\). Repeat the same question if

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    \(X \sim \mathcal{G}(\alpha, \lambda)\), and
  \item
    \(X \sim \mathcal{LN}(\mu, \sigma^2)\).
  \item
    \(X \sim \mathcal{Pa}(\alpha, \lambda)\).
  \end{enumerate}
\item
  Aggregate claims from a risk in a given time have a compound Poisson
  distribution with Poisson parameter \(\lambda = 200\) and an
  individual claim amount distribution that is an exponential
  distribution with mean 500. The insurer has effected proportional
  reinsurance with proportion retained \(\alpha = 0.8\).

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Find the distribution of \(S_I\) and \(S_R\) and their means and
    variances.
  \item
    Compare the variances \(Var[S_I] +Var[S_R]\) and \(Var[S]\). Comment
    on the results obtained.
  \end{enumerate}
\item
  Show that if \(N \sim \mathcal{NB}(k,p)\) represents the distribution of claim
  numbers, then the number of non-zero claims for the reinsurer is
  \[N_R \sim \mathcal{NB}(k,p^*),\] where \(p^* = p/(p + (1-p)\pi_M\)) and
  \(\pi_M = Pr(X > M)\) for the claim size random variable \(X\).
\item
  The number of claims \(N\) per a fixed time period has the following
  distribution:
  \[Pr(N = 0) = 0.5, Pr(N = 1) = 0.3, Pr(N = 2) = 0.1, \text{ and } Pr(N = 3) = 0.1.\]
  The loss distribution has Pareto distribution \(Pa(4,1)\). Assume that
  the number of claims and the amount of losses are mutually
  independent. Find the mean and variance of the aggregate claims for
  this fixed time period.
\end{enumerate}

\hypertarget{solutions-to-tutorial-4}{%
\section{Solutions to Tutorial 4}\label{solutions-to-tutorial-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Given \(X \sim \mathcal{G}(\alpha, \lambda)\), the distribution of \(Y = kX\) can be founded by using the moment generating function.
  \end{enumerate}
\end{enumerate}

\[\begin{aligned}
M_Y(t) &= M_{kX}(t) = \mathrm{E}[e^{(tk)X}] = M_X(kt) \\
&= \left(\frac{\lambda}{\lambda - kt}\right)^\alpha \\
&= \left(\frac{\lambda/k}{\lambda/k - t}\right)^\alpha
\end{aligned}.
\]

Therefore, \(Y \sim \mathcal{G}(\alpha, \lambda/k)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Note that for \(X \sim \mathcal{LN}(\mu, \sigma^2)\),
  \[F_X(x) = \Pr(X \le x) = \Pr(\ln(X) \le \ln(x)) = \Pr(Z \le \frac{\ln(X) - \mu}{\sigma}),\]
\end{enumerate}

where \(Z \sim N(0,1)\).

Consider
\[\begin{aligned}
F_Y(x) &= \Pr(Y \le x) = \Pr(kX \le x) \\
&= \Pr(\ln(X) \le \ln(x/k)) \\
&= \Pr(\frac{\ln(X) - \mu}{\sigma} \le   \frac{\ln(x) - \ln(k) - \mu}{\sigma} ) \\
&= \Pr(Z \le   \frac{\ln(x) - \ln(k) - \mu}{\sigma} ). 
\end{aligned}
\]

It follows that \(Y = kX \sim \mathcal{LN}(\mu + \ln(k), \sigma^2)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Given \(X \sim \mathcal{Pa}(\alpha, \lambda)\),
  \(F_X(x) = 1 - \left(\frac{\lambda}{\lambda + x}\right)^\alpha\).
\end{enumerate}

Therefore,

\[\begin{aligned}
F_Y(x) &= \Pr(Y \le x) = \Pr(kX \le x) = \Pr(X \le x/k) \\
&= 1 - \left(\frac{\lambda}{\lambda + (x/k)}\right)^\alpha \\
&= 1 - \left(\frac{\lambda k}{\lambda k + x}\right)^\alpha. 
\end{aligned}\]

Therefore, \(Y = kX \sim \mathcal{Pa}(\alpha, k\lambda)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Given \(X \sim \text{Exp}(\beta)\), \(kX \sim \text{Exp}(\beta/k)\), for \(k > 0\).

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    From \(X \sim \text{Exp}(1/500)\), the aggregate claim amount paid by the direct insurer \(S_I\) is
    \[S_I \sim \mathcal{CP}(200,F_Y), \quad Y= \alpha X \sim \text{Exp}(\frac{1}{ (0.8) (500)  })\] and the aggregate claim amount paid by the direct insurer \(S_R\) is
    \[S_R \sim \mathcal{CP}(200,F_Z), \quad Z= (1-\alpha) X \sim \text{Exp}(\frac{1}{ (0.2) (500)  })\]
  \end{enumerate}
\end{enumerate}

Moreover,
\[ \mathrm{E}[Y] = 400, \quad \mathrm{E}[Y^2] = \ensuremath{3.2\times 10^{5}}, \]
\[ \mathrm{E}[Z] = 100, \quad \mathrm{E}[Z^2] = \ensuremath{2\times 10^{4}}. \]

The total expected total claim payout of the insurer and its variance are
\[ \mathrm{E}[S_I] = \ensuremath{8\times 10^{4}}, \quad \mathrm{Var}[S_I] = \ensuremath{6.4\times 10^{7}}.\]
The total expected total claim payout of the reinsurer and its variance are
\[ \mathrm{E}[S_R] = \ensuremath{2\times 10^{4}}, \quad \mathrm{Var}[S_R] = \ensuremath{4\times 10^{6}}.\]

Alternatively, we know that
\[ \mathrm{E}[S] = (200)\mathrm{E}[X] =  \ensuremath{10^{5}}, \quad \mathrm{Var}[S] = (200)\mathrm{E}[X^2]  = \ensuremath{10^{8}}.\]
Hence,
\[ \mathrm{E}[S_I] =  \mathrm{E}[\alpha S] =  (0.8)\mathrm{E}[S]  =  \ensuremath{8\times 10^{4}}, \quad \mathrm{Var}[S_I] = \mathrm{Var}[\alpha S] =  (0.8)^2\mathrm{Var}[S] = \ensuremath{6.4\times 10^{7}}.\]
\[ \mathrm{E}[S_R] =  \mathrm{E}[(1-\alpha) S] =  (0.2)\mathrm{E}[S]  =  \ensuremath{2\times 10^{4}}, \quad \mathrm{Var}[S_R] = \mathrm{Var}[(1-\alpha) S] =  (0.2)^2\mathrm{Var}[S] = \ensuremath{4\times 10^{6}}.\]

\begin{verbatim}
2. It follows that 
\end{verbatim}

\(\mathrm{Var}[S_I] + \mathrm{Var}[S_R] = \ensuremath{6.8\times 10^{7}} < \ensuremath{10^{8}} = \mathrm{Var}[S]\).

\begin{verbatim}
After effecting proportional reinsurance proportion, there is a reduction in the variability of the amount paid out by the insurer on claims.
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Given \(N \sim \mathcal{NB}(k,p)\), the probability generating function of \(N\) is
  \[P_N(r) = \left(\frac{p}{1- qr}\right)^k,\]
  where \(q = 1 - p\).
\end{enumerate}

Define the indicator random variable \(\{I_j\}_{j=1}^\infty\), where
\[\begin{aligned}
        I_j = 
    \begin{cases}
        1 &\text{if }  X_j > M\\   
        0 &\text{if }  X_j \le M.
    \end{cases}\end{aligned}\] Therefore, the number of non-zero claims for the reinsurer is \[N_R = \sum_{j= 1}^{N} I_j.\]
The variable \(N_R\) has a compound distribution with its probability
generating function \[P_{N_R}(r) = P_N[P_I(r)],\] where \(P_I\) is the probability generating function of the indicator random variable. It can
be shown that \[P_I(r) = 1 - \pi_M + \pi_M r,\] where
\(\pi_M = \Pr(I_j = 1) = \Pr(X_j > M) = 1 - F(M)\). Therefore,
\[P_{N_R}(r) = P_N[P_I(r)] = \left(\frac{p}{1- q(1 - \pi_M + \pi_M r)}\right)^k.\]
Let \(p* = \frac{p}{p + q \pi_M}\). By dividing both the numerator and the denominator above by \(p + q \pi_M\), we have
\[P_{N_R}(r) = \left(\frac{p^*}{1 - q^* r}\right)^k,\] and \(N_R \sim \mathcal{NB}(k,p^*).\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  The number of claims \(N\) per a fixed time period has the following
  distribution:
  \[\Pr(N = 0) = 0.5, \Pr(N = 1) = 0.3, \Pr(N = 2) = 0.1, \text{ and } \Pr(N = 3) = 0.1.\]
  Then, \(\mathrm{E}[N] = 0.8\) and \(\mathrm{Var}[N] = 0.96\).
\end{enumerate}

The loss distribution has Pareto distribution \(X \sim Pa(4,1)\). Therefore, \(\mathrm{E}[X] = 0.3333333\) and \(\mathrm{E}[X^2] = 0.3333333\).

Therefore, the mean and variance of the aggregate claim amount for this fixed time period.
\[ \mathrm{E}[S] =  \mathrm{E}[N] \mathrm{E}[X] = 0.2666667 \]
and
\[ \mathrm{Var}[S] =  \mathrm{E}[N] (\mathrm{E}[X^2] - (\mathrm{E}[X])^2  ) + \mathrm{Var}[N] (\mathrm{E}[X])^2  = 0.2844444 .\]

\hypertarget{tutorial-5}{%
\section{Tutorial 5}\label{tutorial-5}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Aggregate claims from a risk in a given time have a compound Poisson
  distribution with Poisson parameter \(10\) and an individual claim
  amount distribution that is a Pareto distribution \(Pa(3,2000)\). The
  insurer sets a premium using the expected value principle with
  relative security loading of 0.15. The insurer is considering
  effecting excess of loss reinsurance with retention limit \(1200\).
  The reinsurance premium would be calculated using the same principle
  with relative security loading of 0.2.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Calculate the insurer's expected profit before reinsurance.
  \item
    Under excess of loss reinsurance, the insurer's profit is
    defined to be the premium charged by the insurer, less the
    reinsurance premium and less the claim paid by the insurer (also
    called net of reinsurance). Calculate the insurer's expected
    profit after effecting excess of loss reinsurance.
  \item
    Comments on these results.
  \end{enumerate}
\item
  Aggregate claims from a risk in a given time have a compound Poisson
  distribution with Poisson parameter \(80\) and an individual claim
  amount distribution that is an exponential distribution with
  mean 10. The insurer has effected excess of loss reinsurance with
  retention level \(M = 20\).

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Find the distribution of \(S_I\) and \(S_R\) and their means and
    variances.
  \item
    Compare the variances \(Var[S_I] +Var[S_R]\) and \(Var[S]\). Comment
    on the results obtained.
  \end{enumerate}
\item
  Aggregate claims \(S\) have a compound Poisson distribution
  \(\mathcal{CP}(\lambda,F_X)\) where \(\lambda = 0.5\) and an individual
  claim amounts \(X\) are either 1, 2 or 3 with probability 1/2, 1/4 and
  1/4 respectively. Calculate \(g_r\) for \(r = 0,1,\ldots, 10\).
\item
  (Required the use of Excel or R)

  Suppose \(\{ S(t) \}_{t \ge 0}\) is a compound Poisson process with
  Poisson parameter 1 and individual claim distribution that is an
  exponential distribution \(Exp(1)\) so that for each fixed \(t\),
  \(S(t) \sim \mathcal{CP}(t, F_X)\) where \(F_X(x) = 1 - e^{-x}\), for
  \(x > 0\).

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Calculate the mean, variance and coefficient of skewness of
    \(S(1)\).
  \item
    Use (a) the normal approximation and (b) the translated Gamma
    approximation to approximate the values of \(Pr(S(10) > 20)\).
  \item
    Use (a) the normal approximation and (b) the translated Gamma
    approximation to approximate the values of \(Pr(S(100) > 120)\).
  \end{enumerate}
\end{enumerate}

\hypertarget{solutions-to-tutorial-5}{%
\section{Solutions to Tutorial 5}\label{solutions-to-tutorial-5}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Aggregate claims \(S\) from a risk in a given time have a compound Poisson
    distribution \(S \sim \mathcal{CP}(10,F_X)\) where \(X \sim \mathcal{Pa}(\alpha,\beta) = \mathcal{Pa}(3,2000)\). Using the expected value principle, the insurer sets a premium before reinsurance \(P = (1 + \theta)\mathrm{E}[S]\) with relative security loading of \(\theta = 0.15\). The insurer's expected profit before reinsurance can be obtained from
    \[\begin{aligned} 
    \mathrm{E}[\text{Profit}] &=  \mathrm{E}[P-S] \\
    &= P-  \mathrm{E}[S]  \\
    &= (1 + \theta)\mathrm{E}[S] - \mathrm{E}[S] \\
    &= \theta\mathrm{E}[S]
    \end{aligned}\]
  \end{enumerate}
\end{enumerate}

Note that \(\mathrm{E}[S] = \lambda \mathrm{E}[X] = (10)(1000) = \ensuremath{10^{4}}\). Hence \(\mathrm{E}[\text{Profit}] = 1500\).

\begin{verbatim}
2. The insurer is considering effecting excess of loss reinsurance with retention limit $M = 1200$.
\end{verbatim}

The reinsurance premium would be calculated using the same principle with relative security loading of \(\theta_R = 0.2\). The insurer's expected profit after reinsurance can be obtained from (in terms of \(\mathrm{E}[S]\) and \(\mathrm{E}[S_R]\))
\[\begin{aligned} 
\mathrm{E}[\text{Profit (after reinsurance)}] &=  \mathrm{E}[P- P_R - S_I] \\
&= P- P_R - \mathrm{E}[S_I]  \\
&= P- P_R - \mathrm{E}[S - S_R]  \\
&= (1 + \theta)\mathrm{E}[S] - (1 + \theta_R)\mathrm{E}[S_R] - \mathrm{E}[S] +  \mathrm{E}[S_R]\\
&= \theta\mathrm{E}[S] - \theta_R\mathrm{E}[S_R]
\end{aligned},\]\\
where \(P_R\) is the reinsurer premium.

The total claim amount paid by reinsurer \(S_R \sim \mathcal{CP}(10 \pi_M,F_W)\), where \(\pi_M = \Pr(X > M)\) is the proportion of claims involved the reinsurer, \(W \sim X - M|X > M\) and \(F_W \sim \mathcal{Pa}(\alpha,\beta + M) = \mathcal{Pa}(3,3200)\). It follows that
\[\mathrm{E}[S_R] = (10)(0.2441406)\mathrm{E}[W] =  (10)(0.2441406)(1600) = 3906.25.\]
Substituting this into the above equation yields
\[ \mathrm{E}[\text{Profit (after reinsurance)}] = 718.75.\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Consider the variance of the profit, firstly without reinsurance. The insurer's profit is equal to premiums charged less claims paid. Since only the claims are random, the variance of the profit (before reinsurance) is the same as the variance of the total claims.
  \[ \mathrm{Var}[\text{Profit (without reinsurance)}] = \ensuremath{4\times 10^{7}}.\]
  With reinsurance, the insurer's profit is equal to premiums charged less the reinsurance premium less the net claims paid. So if the insurer's aggregate net claims paid are \(S_I\) , then the variance of the profit is equal to the variance of \(S_I\).
\end{enumerate}

\[ \mathrm{Var}[\text{Profit (with reinsurance)}] = \ensuremath{5.625\times 10^{6}}.\]

\begin{itemize}
\item
  The percentage reduction in the expected profit is 52.08\(\%\).
\item
  The percentage reduction in the standard deviation of the profit is 62.5\(\%\).
\end{itemize}

Note that here the reinsurance has a greater effect on the variability of the claim size than on the average, ie the standard deviation is reduced by a greater percentage than the mean. This is very often the case for excess-of-loss reinsurance.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Given \(X \sim \text{Exp}(\beta)\) with \(\beta = 1/10\),

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    The aggregate claim amount paid by the direct insurer \(S_I\) is
    \[S_I \sim \mathcal{CP}(80,F_Y), \quad Y= \min(X,M)\]
    The distribution and its first two moments of \(Y\) can be found as shown in the lecture note (Section 3.4 Excess of Loss Reinsurance) or by using the moment generating function. Here we will use the moment generating function.
  \end{enumerate}
\end{enumerate}

From \(X \sim \mathrm{Exp}(\beta) = \mathrm{Exp}(1/\mu)\) (Note that \(\mu\) is the expected value of \(X\)),
\[ M_Y(t) = \frac{1}{1- \mu t} ( 1 - \mu p t e^{Mt}),\]
where \(p = \Pr(X > M) = e^{-\lambda M} = e^{-\lambda/\mu}\) is the proportion of claims which involve the reinsurer (see the \href{https://math.stackexchange.com/questions/3033272/finding-the-moment-generating-function-of-miny-1}{link} for more helps)

It follows that
\[\begin{aligned}
\mathrm{E}[Y] &= M_Y'(0) = (1 - p)\mu = 8.6466472 \\
\mathrm{E}[Y^2] &= M_Y''(0) = -2 \mu (M p + (-1 + p) \mu) = 118.7988301. 
\end{aligned}
\]

The total expected total claim payout of the insurer and its variance are
\[ \mathrm{E}[S_I] = \lambda \mathrm{E}[Y] = 691.7317734, \quad \mathrm{Var}[S_I] = \lambda \mathrm{E}[Y^2] =  9503.9064046.\]

The aggregate claim amount paid by the reinsurer \(S_R\) is
\[S_R \sim \mathcal{CP}(80,F_Z), \quad Z= \max(0,X-M)\]

It follows that
\[\begin{aligned}
\mathrm{E}[Z] &= p\mu = 1.3533528 \\
\mathrm{E}[Z^2] &= 2 \mu^2 p = 27.0670566. 
\end{aligned}
\]

The total expected total claim payout of the insurer and its variance are
\[ \mathrm{E}[S_R] = \lambda \mathrm{E}[Z] = 108.2682266, \quad \mathrm{Var}[S_R] = \lambda \mathrm{E}[Z^2] =  2165.3645318.\]

\begin{verbatim}
2. It follows that 
\end{verbatim}

\(\mathrm{Var}[S_I] + \mathrm{Var}[S_R] = \ensuremath{1.1669271\times 10^{4}} < \ensuremath{1.6\times 10^{4}} = \mathrm{Var}[S]\).

\begin{verbatim}
After excess of loss reinsurance arrangement, there is a reduction in the variability of the amount paid out by the insurer on claims.
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  From Panjer's recursion formula,
  \[ g_r = \frac{\lambda}{r}\sum_{j=1}^r j f_j g_{r-j}.\]
  Therefore,
  \[\begin{aligned}
  g_0 &= e^{-\lambda} = 0.606531 \\
  g_1 &= \lambda f_1 g_0  = 0.151633 \\
  g_2 &= (\lambda/2)(f_1 g_1 + 2 f_2 g_0)  = 0.09477 \\
  g_3 &= (\lambda/3)(f_1 g_2 + 2 f_2 g_1 + 3 f_3 g_0)  = 0.09635 \\
  g_4 &= (\lambda/4)(f_1 g_3 + 2 f_2 g_2 + 3 f_3 g_1)  = 0.026161 \\
   &\vdots \\
  g_r &=  (\lambda/r)(f_1 g_{r-1} + 2 f_2 g_{r-2} + 3 f_3 g_{r-3}).
  \end{aligned}
  \]
  Also \(g_5 - g_{10} = 0.013233, 0.007663, 0.002148, \ensuremath{9.27\times 10^{-4}}, \ensuremath{4.05\times 10^{-4}}, \ensuremath{1.14\times 10^{-4}}\), respectively.
\end{enumerate}

\hypertarget{tutorial-6}{%
\section{Tutorial 6}\label{tutorial-6}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Suppose \(S \sim \mathcal{CP}(\lambda, F_X)\) where individual claim
  amounts are distributed on the positive integers and
  \(\lambda = 0.5\). An individual claim amounts \(X\) are either 1 or 2
  with probability 2/3 and 1/3 respectively.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    \protect\hypertarget{QuestionPanjer}{}{\[QuestionPanjer\]}
    Write down an expression for \(E[S]\) in terms of \(\lambda\) and
    the mean of \(X\).
  \item
    Use Panjer's recursion to show that
    \[g_r = \frac{1}{3r} (g_{r-1} + g_{r-2}), \quad r = 2,3,\ldots.\]
  \item
    Calculate \(g_r\) for \(r = 0,1,2, 3, 4\).
  \item
    Verify that \(\sum_{r=0}^4 g_r > 0.995\).
  \item
    Compare \(\sum_{r=0}^4 r g_r\) with the exact mean of \(S\) computed
    by using
    \protect\hyperlink{QuestionPanjer}{\[QuestionPanjer\]}.
  \item
    Comment on the results.
  \end{enumerate}
\item
  Consider a portfolio of 1000 life insurance policies over a one-year
  time period. For each policy at most one claim can occur in the
  year. The probability that a claim occurs is 0.04. Claim amounts are
  distributed \(X \sim Exp(1/2)\).

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Calculate the mean and variance of the aggregate claims.
  \item
    Calculate the relative security loading \(\theta_1\) such that the
    probability of a profit on this portfolio is 0.95.
  \item
    Suppose that the insurer imposes a deductible of 1. Calculate
    the mean and the variance of the aggregate claim paid by the
    insurer. Also calculate the relative security loading \(\theta_2\)
    such that the probability of a profit on this portfolio is 0.95.
  \item
    Comment on the difference between \(\theta_1\) and \(\theta_2\).
  \end{enumerate}
\item
  A portfolio of 5000 life insurance policies for one year term with
  the benefit amount as shown in the table

  \begin{longtable}[]{@{}lcc@{}}
  \toprule
  Benefit amount & 1 & 2 \\
  \midrule
  \endhead
  Number of policies & 4000 & 1000 \\
  \bottomrule
  \end{longtable}

  The policyholders can be assumed to be independent and the
  probability that a claim occurs is 0.03.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Calculate the mean and variance of the aggregate claims.
  \item
    Use the normal approximation to compute \(Pr(S > 200)\)
  \item
    The insurer aims to reduce the size of \(Pr(S > 200)\). The
    insurer arranges excess loss reinsurance with retention 1.5. The
    reinsurer calculates the reinsurance premium \(P_R\) by using the
    relative security loading of 20\%. Calculate the reinsurPrance
    premium.
  \item
    After reinsurance, calculate the mean and variance of the
    aggregate claims paid out by the insurer, i.e.~\(E[S_I]\) and
    \(E[S_I]\).
  \item
    Calculate \(Pr(S_I + P_R > 200)\).
  \item
    Comment on the results.
  \end{enumerate}
\item
  An insurance company issues travel insurance policies. There are two
  types of claims with a maximum of one claim per policy.

  Type I claims for delay : Claim amounts follow an Exponential
  distribution with parameter \(\lambda = 0.002\).

  Type II claims for a flight cancellation: Claim amounts follow a
  Uniform distribution \(U(20,000, 50,000)\).

  Suppose that 10\% of policies result in a claim, 80\% of which are
  Type I and the remaining are type II.

  Calculate the premium charged for each policy.
\end{enumerate}

\hypertarget{tutorial-7}{%
\section{Tutorial 7}\label{tutorial-7}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    An insurer has initial surplus \(u\) of 5.5 (in suitable units)
    and receives premium payments at a rate of 3 per year. Suppose
    claims from a portfolio of insurance over the first two years
    are as follows:

    \begin{longtable}[]{@{}lccc@{}}
    \toprule
    Time (years) & 0.3 & 0.8 & 1.5 \\
    \midrule
    \endhead
    Amount & 4 & 6 & 2 \\
    \bottomrule
    \end{longtable}

    Plot a surplus process and determine whether ruin occurs within
    the first two years in each of the following cases:

    \begin{enumerate}
    \def\labelenumiii{\arabic{enumiii}.}
    \item
      Ruin was checked continuously.
    \item
      Ruin was checked only at the end of each year.
    \end{enumerate}
  \item
    Suppose that the insurer has arranged excess loss reinsurance
    with retention limit 3.5. The reinsurance premium is 1 per year
    to be paid continuously. Plot a surplus process and determine
    whether ruin occurs within the first two years n each of the
    following cases:

    \begin{enumerate}
    \def\labelenumiii{\arabic{enumiii}.}
    \item
      Ruin was checked continuously.
    \item
      Ruin was checked only at the end of each year.
    \end{enumerate}
  \item
    Comment on the results.
  \end{enumerate}
\item
  The aggregate claims process for a risk is compound Poisson with
  Poisson parameter 0.1 per year. Individual claim amounts \(X\) have
  the following distribution:

  \begin{longtable}[]{@{}cccc@{}}
  \toprule
  \(x\) & 50 & 75 & 120 \\
  \midrule
  \endhead
  \(Pr(X = x)\) & 0.7 & 0.25 & 0.05 \\
  \bottomrule
  \end{longtable}

  The insurer's initial surplus is 100 (in suitable units) and the
  insurer calculate the premium using a relative security loading of
  10\% on the expected amount of annual aggregate claim at the
  beginning of each year. Calculate the probability that the insurer's
  surplus at time 2 will be negative.
\item
  The aggregate claims process for a risk is compound Poisson with
  Poisson parameter 0.1 per year. Individual claim amounts \(X\) have
  the following distribution:

  \begin{longtable}[]{@{}ccc@{}}
  \toprule
  \(x\) & 1 & 2 \\
  \midrule
  \endhead
  \(Pr(X = x)\) & 0.7 & 0.3 \\
  \bottomrule
  \end{longtable}

  The insurer's initial surplus is 0.3 (in suitable units) and the
  premium rate is 0.4 per year, received continuously. Calculate the
  following probabilities of ruin.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    \(\psi(0.3,1).\)
  \item
    \(\psi(0.3,2).\)
  \end{enumerate}
\end{enumerate}

\hypertarget{tutorial-8}{%
\section{Tutorial 8}\label{tutorial-8}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The table below gives the payments (in 000s THB) in cumulative form
  in successive development years in respect of a motor insurance
  portfolio. All claims are assumed to be fully settled by the end of
  development year 4. Use the chain ladder method to estimate the
  amount the insurer will pay in the calendar years
  \(2018, 2019, 2020 ,2021\).

  \begin{longtable}[]{@{}lllllll@{}}
  \toprule
  \endhead
  & & Development year & & & & \\
  & & 0 & 1 & 2 & 3 & 4 \\
  & 2013 & 750 & 768 & 844 & 929 & 1072 \\
  Accident & 2014 & 820 & 876 & 946 & 1041 & \\
  Year & 2015 & 960 & 997 & 1096 & & \\
  & 2016 & 1040 & 1087 & & & \\
  & 2017 & 1180 & & & & \\
  \bottomrule
  \end{longtable}
\item
  The table below shows the claims payments (in 000s THB) in
  cumulative form for a portfolio of insurance policies. All claims
  are assumed to be fully settled by the end of development year 4 and
  the payments are made at the middle of each calendar year. The past
  rates of inflation over the 12 months up to the middle of the given
  year are as follows:

  \begin{longtable}[]{@{}cc@{}}
  \toprule
  \endhead
  2014 & 5\% \\
  2015 & 6\% \\
  2016 & 7\% \\
  2017 & 5\% \\
  \bottomrule
  \end{longtable}

  The future rate of inflation from mid-2017 is assumed to be 10\% per
  year.

  \begin{longtable}[]{@{}lllllll@{}}
  \toprule
  \endhead
  & & Development year & & & & \\
  & & 0 & 1 & 2 & 3 & 4 \\
  & 2013 & 880 & 988 & 1046 & 1065 & 1262 \\
  Accident & 2014 & 940 & 1034 & 1091 & 1095 & \\
  Year & 2015 & 1060 & 1161 & 1229 & & \\
  & 2016 & 1120 & 1221 & & & \\
  & 2017 & 1240 & & & & \\
  \bottomrule
  \end{longtable}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Use the inflation-adjusted chain ladder method to calculate the
    outstanding claims payments in future years.
  \item
    Using an interest rate of 7\% per year, calculate the outstanding
    claims reserve the insurer should have hold on 1 January 2018.
  \end{enumerate}
\item
  The table below shows the cumulative claims payments and the
  cumulative number of claims (amounts appear above claim numbers) for
  a portfolio of insurance policies. All claims are assumed to be
  fully settled by the end of development year 5 and that the effects
  of claims-cost inflation have been removed from these data. Use the
  average cost per claim method to estimate the outstanding claims
  reserve which should be held at the end of 2017.

  \begin{longtable}[]{@{}llllllll@{}}
  \toprule
  \endhead
  & & Development year & & & & & \\
  & & 0 & 1 & 2 & 3 & 4 & 5 \\
  & 2012 & 2800 & 2954 & 3005 & 3275 & 3624 & 3895 \\
  & & 420 & 440 & 453 & 493 & 551 & 591 \\
  & 2013 & 3200 & 3379 & 3449 & 3760 & 4184 & \\
  & & 460 & 478 & 490 & 533 & 591 & \\
  Accident & 2014 & 3800 & 4004 & 4078 & 4454 & & \\
  Year & & 500 & 525 & 531 & 580 & & \\
  & 2015 & 4520 & 4749 & 4842 & & & \\
  & & 520 & 549 & 558 & & & \\
  & 2016 & 5340 & 5587 & & & & \\
  & & 560 & 589 & & & & \\
  & 2017 & 5840 & & & & & \\
  & & 570 & & & & & \\
  \bottomrule
  \end{longtable}
\item
  The table below shows the cumulative claims payments and the premium
  income \(P\) for a portfolio of insurance policies. All claims are
  assumed to be fully settled by the end of development year 4 and
  that the effects of claims-cost inflation have been removed from
  these data. Use the Bornhuetter-Ferguson method to estimate the
  total reserve required to meet the outstanding claims. You may
  assume that the ultimate loss ratio for accident years 2014-2017
  will be 95\%.

  \begin{longtable}[]{@{}llllllll@{}}
  \toprule
  \endhead
  & & Development year & & & & & \\
  & & 0 & 1 & 2 & 3 & 4 & \(P\) \\
  & 2013 & 3597 & 4226 & 4547 & 4807 & 4989 & 5937 \\
  Accident & 2014 & 4174 & 4697 & 5317 & 5497 & & 6122 \\
  Year & 2015 & 4578 & 5082 & 5753 & & & 6221 \\
  & 2016 & 4634 & 5343 & & & & 6365 \\
  & 2017 & 5203 & & & & & 6510 \\
  \bottomrule
  \end{longtable}
\end{enumerate}

\hypertarget{tutorial-9}{%
\section{Tutorial 9}\label{tutorial-9}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  (Taken from Gray and Pitts) Suppose the number of claims which arise
  in a year on a group of policies is modelled as
  \(X|\lambda \sim Poisson(\lambda)\) and that we observe a total of 14
  claims over a six year period. Suppose also we adopt a \(\mathcal{G}(6, 3)\)
  distribution as a prior distribution for \(\lambda\).

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    State the maximum likelihood estimate of \(\lambda\) and the prior
    mean.
  \item
    State the posterior distribution of \(\lambda\), find the mode of
    this distribution, and hence state the Bayesian estimate of
    \(\lambda\) under all or nothing loss.
  \item
    Note that if \(Y \sim \mathcal{G}(\alpha,\beta)\) and \(2\alpha\) is an
    integer, then \(2\beta Y \sim \mathcal{G}(\alpha,1/2)\); that is
    \(2\beta Y \sim \chi^2\) with \(2 \alpha\) degrees of freedom.

    \begin{enumerate}
    \def\labelenumiii{\arabic{enumiii}.}
    \item
      Using this fact, find the Bayesian estimate of \(\lambda\)
      under absolute error loss.
    \item
      Find an equal-tailed 95\% Bayesian interval estimate of
      \(\lambda\), that is an interval \((\lambda_L, \lambda_U)\),
      such that
      \(Pr( \lambda > \lambda_U | \underline{x}) = Pr( \lambda < \lambda_L | \underline{x}) = 0.025\).
    \end{enumerate}
  \item
    Find the credibility estimate (the Bayesian estimate under
    squared-error loss) of \(\lambda\).
  \end{enumerate}
\item
  Recall that the data \(x_1, x_2, \ldots, x_n\) are available on
  \(X | \lambda\). Suppose we observe \(\sum x_i = 13\) when \(n = 50\).
  Based on the Poisson\(-\)Gamma model, the number of claims which arise
  in a year on a group of policies is modelled as
  \(X|\lambda \sim Poisson(\lambda)\) and the prior distribution on the
  claim rate \(\lambda\) is a \(\mathcal{G}(\alpha,\beta)\) distribution.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Calculate the value of the maximum likelihood estimate of
    \(\lambda\)
  \item
    Calculate the values of prior means and the prior variance in
    two cases (i) the prior is \(\mathcal{G}(6,30)\) and (ii) the prior is
    \(\mathcal{G}(2,10)\). Comment on the results.
  \item
    For those two prior distributions, calculate the posterior mean
    of \(\lambda\) given such data.
  \end{enumerate}
\item
  Suppose the annual claims which arise under a risk, \(X\), in units of
  1000THB, as \(X | \theta \sim \mathcal{N}(\theta,0.36)\). From experience with
  other business, an insurer adopt a \(\mathcal{N}(2, 0.04)\) prior for \(\theta\).
  The insurer observe claim amounts for the past seven years :
  \(2369, 2341, 2284, 2347, 2332, 2300, 2267\) THB. Using the
  normal\(-\)normal model:

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Find the credibility factor and the credibility premium for the
    risk.
  \item
    Find an equal-tailed 95\% Bayesian interval estimate of \(\theta\).
  \end{enumerate}
\item
  Consider a collective of five separate risks from portfolios of
  general insurance policies, each of which has been in existence for
  at least ten years. The mean and variance of the aggregate claims
  adjusted for inflation over the past ten years are given in the
  table. Use EBCT Model 1 to calculate the credibility premiums for
  all five risks.

  \begin{longtable}[]{@{}ccc@{}}
  \toprule
  Risk & Within risk mean & Within risk variance \\
  \midrule
  \endhead
  1 & 138 & 259 \\
  2 & 98 & 179 \\
  3 & 120 & 239 \\
  4 & 104 & 168 \\
  5 & 119 & 185 \\
  \bottomrule
  \end{longtable}
\item
  Consider the aggregate claims in five successive years from
  comparable insurance policies (in units of 1000 THB).

  \protect\hypertarget{TableRisks}{}{\[TableRisks\]}

  \begin{longtable}[]{@{}llcllll@{}}
  \toprule
  \endhead
  & & Year \(j\) & & & & \\
  & & 1 & 2 & 3 & 4 & 5 \\
  Risk \(i\) & 1 & 68 & 65 & 77 & 76 & 74 \\
  & 2 & 54 & 59 & 56 & 50 & 62 \\
  & 3 & 81 & 95 & 83 & 82 & 89 \\
  & 4 & 64 & 70 & 77 & 66 & 73 \\
  \bottomrule
  \end{longtable}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    Use the EBCT Model 1 to calculate the credibility premium for
    each risk \(i\).
  \item
    Explain why the credibility premiums depend almost entirely on
    the means for the individual risks.
  \end{enumerate}
\end{enumerate}

  \bibliography{book.bib,packages.bib}

\end{document}
